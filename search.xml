<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>CommandLine 解析命令行参数</title>
    <url>/2024/Java/CommandLine%20%E8%A7%A3%E6%9E%90%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%8F%82%E6%95%B0/</url>
    <content><![CDATA[<h2 id="引入依赖"><a href="#引入依赖" class="headerlink" title="引入依赖"></a>引入依赖</h2><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>commons-cli<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>commons-cli<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.7.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="代码示例"><a href="#代码示例" class="headerlink" title="代码示例"></a>代码示例</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.commons.cli.*;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Author</span> ZhouHJ</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Date</span> 2024/4/29 16:23</span></span><br><span class="line"><span class="comment"> **/</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CommandLineDemo</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">Option</span> <span class="variable">HELP_OPT</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Option</span>(<span class="string">&quot;h&quot;</span>, <span class="string">&quot;help&quot;</span>, <span class="literal">false</span>, <span class="string">&quot;使用信息&quot;</span>);</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">Option</span> <span class="variable">TYPE_OPT</span> <span class="operator">=</span> Option.builder(<span class="string">&quot;t&quot;</span>)</span><br><span class="line">            .longOpt(<span class="string">&quot;type&quot;</span>)</span><br><span class="line">            <span class="comment">//.required()</span></span><br><span class="line">            .hasArg()</span><br><span class="line">            .desc(<span class="string">&quot;指定业务类型&quot;</span>)</span><br><span class="line">            .build();</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">Option</span> <span class="variable">DATE_OPT</span> <span class="operator">=</span> Option.builder(<span class="string">&quot;D&quot;</span>)</span><br><span class="line">            .argName(<span class="string">&quot;property=value&quot;</span>)</span><br><span class="line">            .hasArgs()</span><br><span class="line">            .valueSeparator(<span class="string">&#x27;=&#x27;</span>)</span><br><span class="line">            .desc(<span class="string">&quot;指定日期&quot;</span>).build();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Options <span class="title function_">getOptions</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="type">Options</span> <span class="variable">options</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Options</span>();</span><br><span class="line">        options.addOption(TYPE_OPT);</span><br><span class="line">        options.addOption(HELP_OPT);</span><br><span class="line">        options.addOption(DATE_OPT);</span><br><span class="line">        <span class="keyword">return</span> options;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">printUsage</span><span class="params">(Options options)</span> &#123;</span><br><span class="line">        <span class="type">HelpFormatter</span> <span class="variable">helper</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">HelpFormatter</span>();</span><br><span class="line">        helper.printHelp(<span class="string">&quot;demo&quot;</span>, options);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> ParseException &#123;</span><br><span class="line">        <span class="type">CommandLine</span> <span class="variable">cmd</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DefaultParser</span>().parse(getOptions(), args);</span><br><span class="line">        <span class="keyword">if</span> (cmd.hasOption(HELP_OPT)) &#123;</span><br><span class="line">            printUsage(getOptions());</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="type">String</span> <span class="variable">type</span> <span class="operator">=</span> cmd.getOptionValue(TYPE_OPT);</span><br><span class="line">        <span class="type">String</span> <span class="variable">date</span> <span class="operator">=</span> cmd.getOptionProperties(DATE_OPT).getProperty(<span class="string">&quot;date&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;type is:&quot;</span> + type + <span class="string">&quot;,date is:&quot;</span> + date);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="使用示例"><a href="#使用示例" class="headerlink" title="使用示例"></a>使用示例</h2><h3 id="help打印"><a href="#help打印" class="headerlink" title="help打印"></a>help打印</h3><img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20240508104150.png" alt="image-20240508104143210" style="zoom:50%;" />

<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20240508104227.png" alt="image-20240508104227024" style="zoom: 50%;" />

<h3 id="参数获取"><a href="#参数获取" class="headerlink" title="参数获取"></a>参数获取</h3><img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20240508104412.png" alt="image-20240508104412222" style="zoom:50%;" />

<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20240508104446.png" alt="image-20240508104446254" style="zoom:50%;" />

<p>官网使用例子：<a href="https://commons.apache.org/proper/commons-cli/usage.html">https://commons.apache.org/proper/commons-cli/usage.html</a></p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>CommandLine</tag>
      </tags>
  </entry>
  <entry>
    <title>Centos7 Nat模式静态Ip配置</title>
    <url>/2020/Linux/Centos7%20Nat%E6%A8%A1%E5%BC%8F%E9%9D%99%E6%80%81Ip%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<p>虚拟机软件：VMware16</p>
<h3 id="一：修改虚拟网络编辑器"><a href="#一：修改虚拟网络编辑器" class="headerlink" title="一：修改虚拟网络编辑器"></a>一：修改虚拟网络编辑器</h3><p>1.进入虚拟网络编辑器，设置Vmnet8子网IP网段</p>
<img src="https://fastly.jsdelivr.net/gh/ccssbxf/img/blog/20220414201315.png" style="width: 60%;" />





<img src="https://gcore.jsdelivr.net/gh/ccssbxf/img/blog/20220414203443.png" style="width: 60%;" />





<p>2.进入NAT设置，设置网关IP</p>
<img src="https://gcore.jsdelivr.net/gh/ccssbxf/img/blog/20220414203512.png" style="width: 60%;" />

<h3 id="二：修改虚拟机网络配置文件"><a href="#二：修改虚拟机网络配置文件" class="headerlink" title="二：修改虚拟机网络配置文件"></a>二：修改虚拟机网络配置文件</h3><p>1.查看虚拟机使用的网络配置文件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@localhost /]# ip addr</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000</span><br><span class="line">    link/ether 00:0c:29:94:37:5a brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 192.168.182.10/24 brd 192.168.10.255 scope global noprefixroute ens33</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::8982:7848:648f:b491/64 scope link noprefixroute </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure>

<p>说明使用的配置文件是ens33，当前ip为192.168.182.10</p>
<p>2.编辑相应的网络配置文件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@localhost /]# vi /etc/sysconfig/network-scripts/ifcfg-ens33</span><br></pre></td></tr></table></figure>

<p>3.修改文件内容</p>
<p>注意等于号左右两边不能有空格</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">修改配置</span></span><br><span class="line">TYPE=Ethernet</span><br><span class="line">PROXY_METHOD=none</span><br><span class="line">BROWSER_ONLY=no</span><br><span class="line">BOOTPROTO=static   // 1.修改为静态模式</span><br><span class="line">DEFROUTE=yes</span><br><span class="line">IPV4_FAILURE_FATAL=no</span><br><span class="line">IPV6INIT=yes</span><br><span class="line">IPV6_AUTOCONF=yes</span><br><span class="line">IPV6_DEFROUTE=yes</span><br><span class="line">IPV6_FAILURE_FATAL=no</span><br><span class="line">IPV6_ADDR_GEN_MODE=stable-privacy</span><br><span class="line">NAME=ens33</span><br><span class="line">DEVICE=ens33</span><br><span class="line">ONBOOT=yes   // 2.开机自动启动网卡</span><br><span class="line">UUID=434ca492-505e-437f-b12a-6ff774c97f19</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">添加配置</span></span><br><span class="line">IPADDR=192.168.10.10   // static静态ip地址</span><br><span class="line">NETMASK=255.255.255.0    // 子网掩码（固定一致即可）</span><br><span class="line">GATEWAY=192.168.10.2    // 网关，与虚拟机VMnet8中设置的网关一致即可</span><br><span class="line">DNS1=114.114.114.114     // dns地址解析（固定一致即可）</span><br></pre></td></tr></table></figure>

<h3 id="三：重启网卡重新加载配置文件"><a href="#三：重启网卡重新加载配置文件" class="headerlink" title="三：重启网卡重新加载配置文件"></a>三：重启网卡重新加载配置文件</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@localhost /]# systemctl restart network.service</span><br></pre></td></tr></table></figure>

<h3 id="四：验证网络"><a href="#四：验证网络" class="headerlink" title="四：验证网络"></a>四：验证网络</h3><p>1.查看当ip地址</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@localhost /]# ip addr</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000</span><br><span class="line">    link/ether 00:0c:29:94:37:5a brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 192.168.10.10/24 brd 192.168.10.255 scope global noprefixroute ens33</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::8982:7848:648f:b491/64 scope link noprefixroute </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure>

<p>2.验证网络是否通畅</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@localhost /]# ping www.baidu.com</span><br><span class="line">PING www.a.shifen.com (36.152.44.96) 56(84) bytes of data.</span><br><span class="line">64 bytes from 36.152.44.96 (36.152.44.96): icmp_seq=1 ttl=128 time=23.0 ms</span><br><span class="line">64 bytes from 36.152.44.96 (36.152.44.96): icmp_seq=2 ttl=128 time=22.9 ms</span><br><span class="line">64 bytes from 36.152.44.96 (36.152.44.96): icmp_seq=3 ttl=128 time=23.2 ms</span><br><span class="line">64 bytes from 36.152.44.96 (36.152.44.96): icmp_seq=4 ttl=128 time=23.2 ms</span><br></pre></td></tr></table></figure>

<p>静态网络Ip配置完成</p>
<p>安装网络工具包，安装后可使用ifconfig命令</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@localhost /]# yum -y install net-tools</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>静态IP</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>class文件打成jar包</title>
    <url>/2023/Java/class%E6%96%87%E4%BB%B6%E6%89%93%E6%88%90jar%E5%8C%85/</url>
    <content><![CDATA[<p>由于有时候的特殊需要，要将几个class文件单独打成jar包</p>
<p>1.按class文件的package建好相应的目录，比如原有class是</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">package com.zhouhj.tools.phoenix.udf;</span><br></pre></td></tr></table></figure>

<p>则创建从com开始到udf结束的目录</p>
<p>2.将class文件放到对应目录下</p>
<p>3.在com目录同级别的目录执行以下命令</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">jar -cvf phoenix-udf.jar com/</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>打包</tag>
      </tags>
  </entry>
  <entry>
    <title>Shell脚本配置集群免密登录</title>
    <url>/2022/Linux/Shell%E8%84%9A%E6%9C%AC%E9%85%8D%E7%BD%AE%E9%9B%86%E7%BE%A4%E5%85%8D%E5%AF%86%E7%99%BB%E5%BD%95/</url>
    <content><![CDATA[<p>使用时需要修改nodes和passwd</p>
<p>在集群的任意一台主机上，使用需要配置免密登录的用户执行该脚本，即可实现集群内所有主机之间的免密登录</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">安装expect,用于自动交互任务</span></span><br><span class="line">sudo yum install -y expect</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">要设置免密登录的节点，第一台一定要为本机</span></span><br><span class="line">nodes=(hadoop101 hadoop102 hadoop103)</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">登录密码，所有节点一致</span></span><br><span class="line">passwd=123456</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">---本机免密登录其他节点---</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">在所有节点生成秘钥</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">如果(<span class="built_in">yes</span>/no)?则自动选择<span class="built_in">yes</span>继续下一步，有的版本是(<span class="built_in">yes</span>/no/[fingerprint])?</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">如果password:则自动将passwd写在后面继续下一步</span></span><br><span class="line">create_key() &#123;</span><br><span class="line">  expect -c &quot;set timeout -1;</span><br><span class="line">        spawn ssh $USER@$node ssh-keygen -t rsa -P &#x27;&#x27; -f $HOME/.ssh/id_rsa;</span><br><span class="line">        expect &#123;</span><br><span class="line">                *(yes/no* &#123;send -- yes\r;exp_continue;&#125;</span><br><span class="line">                *password:* &#123;send -- $passwd\r;exp_continue;&#125;</span><br><span class="line">                eof\t&#123;exit 0&#125;</span><br><span class="line">        &#125;&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">ssh_create_key() &#123;</span><br><span class="line">  for node in $&#123;nodes[*]&#125;; do</span><br><span class="line">    create_key $node $passwd</span><br><span class="line">  done</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">ssh_create_key</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">将本机公钥复制到所有节点</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">如果（<span class="built_in">yes</span>/no)?则自动选择<span class="built_in">yes</span>继续下一步，有的版本是(<span class="built_in">yes</span>/no/[fingerprint])?</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">如果password:则自动将passwd写在后面继续下一步</span></span><br><span class="line">copy_id() &#123;</span><br><span class="line">  expect -c &quot;set timeout -1;</span><br><span class="line">        spawn ssh-copy-id $USER@$node;</span><br><span class="line">        expect &#123;</span><br><span class="line">                *(yes/no* &#123;send -- yes\r;exp_continue;&#125;</span><br><span class="line">                *password:* &#123;send -- $passwd\r;exp_continue;&#125;</span><br><span class="line">                eof\t&#123;exit 0&#125;</span><br><span class="line">        &#125;&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">ssh_copy_id() &#123;</span><br><span class="line">  for node in $&#123;nodes[*]&#125;; do</span><br><span class="line">    copy_id $node $passwd</span><br><span class="line">  done</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">ssh_copy_id</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">---所有节点相互免密登录---</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">将其他节点公钥追加到本机</span></span><br><span class="line">for node in $&#123;nodes[*]:1&#125;; do</span><br><span class="line">  ssh $USER@$node cat $HOME/.ssh/id_rsa.pub &gt;&gt;$HOME/.ssh/authorized_keys</span><br><span class="line">done</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">将包含所有节点公钥的文件复制到其他节点</span></span><br><span class="line">for node in $&#123;nodes[*]:1&#125;; do</span><br><span class="line">  scp $HOME/.ssh/authorized_keys $USER@$node:$HOME/.ssh/authorized_keys</span><br><span class="line">done</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">将包含有所有节点连接信息的文件复制到其他节点</span></span><br><span class="line">for node in $&#123;nodes[*]:1&#125;; do</span><br><span class="line">  scp $HOME/.ssh/known_hosts $USER@$node:$HOME/.ssh/known_hosts</span><br><span class="line">done</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">end</span></span><br></pre></td></tr></table></figure>

<p>注：配置免密登录的用户需要拥有sudo权限，用来安装expect。或者使用root用户安装expect后，注释掉第4行，再执行脚本。</p>
<p>参考：<a href="https://blog.csdn.net/ynzzxc/article/details/119999682">https://blog.csdn.net/ynzzxc/article/details/119999682</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>免密登录</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>SSH免密登录配置</title>
    <url>/2021/Linux/linux%E5%85%8D%E5%AF%86%E7%99%BB%E5%BD%95%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<p>1.在每台主机上执行以下命令生成公私钥（一路回车即可）</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ssh-keygen -t rsa</span><br></pre></td></tr></table></figure>

<p>2.发送公钥到集群所有主机（包括本机）</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ssh-copy-id -p 22 -i ~/.ssh/id_rsa.pub 用户名@ip或主机名称</span><br><span class="line">简略写法，默认22端口和相同用户名</span><br><span class="line">ssh-copy-id ip或主机名</span><br></pre></td></tr></table></figure>

<p>执行完之后，公钥将会被复制到对端主机的~&#x2F;.ssh&#x2F;authorized_keys文件中</p>
<p>3.当ssh端口非22端口时</p>
<p>需要将步骤2中的端口22更改为目标端口，并且需要执行以下命令</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">echo &quot;Port 目标端口&quot; &gt;&gt;  ~/.ssh/config</span><br></pre></td></tr></table></figure>

<p>4.验证免密登录</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ssh ip或者主机名称</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>免密登录</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop DataNode节点下线速度优化</title>
    <url>/2023/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hadoop%20DataNode%E8%8A%82%E7%82%B9%E4%B8%8B%E7%BA%BF%E9%80%9F%E5%BA%A6%E4%BC%98%E5%8C%96/</url>
    <content><![CDATA[<h2 id="参数介绍"><a href="#参数介绍" class="headerlink" title="参数介绍"></a>参数介绍</h2><p> 一般来说 NameNode检测 DataNode是否掉线的值是 10*3s（DataNode心跳时间，参数是：dfs.heartbeat.interval）+2*5min（namenode 检测时间，参数是：dfs.namenode.heartbeat.recheck-interval）&#x3D;10 分 30s，将该值定义为timeout</p>
<p>当节点下线时间超过timeout的值后，会发生副本迁移。</p>
<p>副本迁移速度主要由以下三个参数控制：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">dfs.namenode.replication.work.multiplier.per.iteration</span><br><span class="line">这个参数决定了当 NN 与 DN 进行心跳（3s）发送任务列表时，告诉每个 DN 可以进行复制的 block 数量。比如集群有 5 个节点，这个值设置为 5，那么一次心跳 NameNode 可以发送 DataNode 复制的数据块数量是 5*5=25 块。默认值为2</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">dfs.namenode.replication.max-streams</span><br><span class="line">这个参数含义是控制 DataNode 节点进行数据复制的最大线程数， block 的复制优先级分成 5 种。这个参数控制不包含最高优先级的块复制。即除最高优先级的复制流限制。默认值为2</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">dfs.namenode.replication.max-streams-hard-limit</span><br><span class="line">这个参数含义是控制 DataNode 所有优先级块复制的流个数，包含最高优先级；一般上面和上面两个参数互相的配合使用。默认值为4</span><br></pre></td></tr></table></figure>

<h2 id="副本迁移时间计算"><a href="#副本迁移时间计算" class="headerlink" title="副本迁移时间计算"></a>副本迁移时间计算</h2><p>计算公式：待复制 block 总数 &#x2F;(存活的DataNode个数 *dfs.namenode.replication.work.multiplier.per.iteration )* 心跳时间(dfs.heartbeat.interval)</p>
<p>比如待复制的block总数10000000，存活DataNode个数为60，dfs.namenode.replication.work.multiplier.per.iteration为10，心跳时间为3s，则 time&#x3D;10000000&#x2F;(60*10)*3&#x3D;50000s≈13.88小时</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>第一个参数控制 DataNode接受任务的频率，后面两个参数进一步限制 DataNode 一次完成的最大并行线程网络传输量。具体上面参数的值设定的多少，取决于集群的规模和集群的配置，不能同一而论。一般来说从入口控制比较简单容易些。比如规模 5 台集群，dfs.namenode.replication.work.multiplier.per.iteration&#x3D;10，5 台 DataNode，那么集群一次心跳分发 50 个 block 的量，假如集群文件存储全部打散在 5 台节点，每个节点同时复制 10 个 block（实际会因为副本搁置策略，机架感知等并不会所有的节点都参与数据复制）, 每个 block 大小 128Mb, 则每个节点的网络负载是 128*10&#x2F;3s&#x3D;546Mb&#x2F;s，那这时候你就要看下结合实际会不会有带宽瓶颈，这么大的网络 IO 会不会影响正常任务的计算，如果有的话，这个值就要调小点。</p>
<p>参考：<a href="https://blog.csdn.net/qq_35995514/article/details/128487543">https://blog.csdn.net/qq_35995514/article/details/128487543</a></p>
]]></content>
      <categories>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop HA集群两个NameNode都是standby状态</title>
    <url>/2022/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hadoop%20HA%E9%9B%86%E7%BE%A4%E4%B8%A4%E4%B8%AANameNode%E9%83%BD%E6%98%AFstandby%E7%8A%B6%E6%80%81/</url>
    <content><![CDATA[<p>1.查看zkfc进程是否正常</p>
<p>HadoopNameNode的主备选举由zkfc进程进行，如果zkfc进程挂了，则会导致两个NameNode都是standby的状态</p>
<p>启动zkfc进程</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hdfs --daemon start zkfc</span><br></pre></td></tr></table></figure>

<p>2.重新初始化zk里Hadoop的数据</p>
<p>在想成为active的那台namenode节点执行</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">初始化zk数据</span><br><span class="line">hdfs zkfc -formatZK</span><br><span class="line"></span><br><span class="line">重启hdfs集群</span><br><span class="line">stop-dfs.sh</span><br><span class="line">start-dfs.sh</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>HBase在线动态新增节点、删除节点</title>
    <url>/2022/%E5%A4%A7%E6%95%B0%E6%8D%AE/HBase%E5%9C%A8%E7%BA%BF%E5%8A%A8%E6%80%81%E6%96%B0%E5%A2%9E%E8%8A%82%E7%82%B9%E3%80%81%E5%88%A0%E9%99%A4%E8%8A%82%E7%82%B9/</url>
    <content><![CDATA[<h2 id="一：新增节点"><a href="#一：新增节点" class="headerlink" title="一：新增节点"></a>一：新增节点</h2><p>注：HBase新增节点需要建立在这个节点已经有Hadoop的情况下</p>
<p>1.拷贝集群原有节点的HBase包到新节点相同路径下</p>
<p>2.修改&#x2F;home&#x2F;zhouhj&#x2F;app&#x2F;hbase-2.3.6&#x2F;conf&#x2F;regionservers配置文件，加入新节点，将该文件分发到所有的HBase节点上</p>
<p>3.在新节点启动HBase</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hbase-daemon.sh start regionserver</span><br></pre></td></tr></table></figure>

<p>4.查看HBase集群状态</p>
<p>进入hbase shell，执行status查看状态，可以看到新节点已加入集群</p>
<p>5.数据平衡</p>
<p>hbase shell里执行</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">（开启负载均衡器，HBase会选择时机执行平衡数据）</span><br><span class="line">balance_switch true</span><br><span class="line">（下面这个是手动触发避免业务高峰期执行）</span><br><span class="line">balancer</span><br></pre></td></tr></table></figure>

<p>等命令执行完成，新加入的节点上已经有region，可以通过HBase管理页面看到</p>
<h2 id="二：删除节点"><a href="#二：删除节点" class="headerlink" title="二：删除节点"></a>二：删除节点</h2><p>1.在要下线的节点（比如我这里下线hadoop104），在hadoop104执行</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graceful_stop.sh hadoop104</span><br></pre></td></tr></table></figure>

<p>该命令会自动关闭 Load Balancer（banlance_switch），然后转移该 regionserver 维护的 region 到其他节点，将该节点关闭。除此之外，你还可以查看 remove 的过程，已经 assigned 了多少个 Region，还剩多少个 Region，每个 Region 的 Assigned 耗时，最终完成之后需要手动打开 load balancer [hbase shell 执行banlance_switch true]</p>
<p>2.删除&#x2F;home&#x2F;zhouhj&#x2F;app&#x2F;hbase-2.3.6&#x2F;conf&#x2F;regionservers配置文件里的相应节点</p>
<p>3.启用负载平衡器</p>
<p>hbase shell里执行</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">（开启负载均衡器，HBase会选择时机执行平衡数据）</span><br><span class="line">balance_switch true</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>HBase</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop在线动态新增节点、删除节点</title>
    <url>/2022/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hadoop%E5%9C%A8%E7%BA%BF%E5%8A%A8%E6%80%81%E6%96%B0%E5%A2%9E%E8%8A%82%E7%82%B9%E3%80%81%E5%88%A0%E9%99%A4%E8%8A%82%E7%82%B9/</url>
    <content><![CDATA[<h2 id="一：新增节点"><a href="#一：新增节点" class="headerlink" title="一：新增节点"></a>一：新增节点</h2><p>1.按原有数据节点配置一台新的数据节点（包括最初搭建集群的系统参数修改、时钟同步等操作）</p>
<p>2.配置节点主机映射，比如新增hadoop104节点，则在原有节点的&#x2F;etc&#x2F;hosts文件里添加映射信息，并将该文件分发到新节点</p>
<p>3.将新节点与集群内原有节点做免密登录</p>
<p>4.拷贝原数据节点上的环境变量配置、JDK、Hadoop安装包等到新节点相同路径下</p>
<p>5.在namenode修改&#x2F;home&#x2F;zhouhj&#x2F;app&#x2F;hadoop-3.2.2&#x2F;etc&#x2F;hadoop&#x2F;workers文件，新增hadoop104节点，并分发到所有节点上</p>
<p>6.查看hdfs-site.xml配置项dfs.datanode.data.dir的值，该值为数据节点存储数据的目录，如果新节点的这些目录有数据，将其清理干净</p>
<p>7.启动新节点上的进程</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hdfs --daemon start datanode</span><br><span class="line">yarn --daemon start nodemanager</span><br></pre></td></tr></table></figure>

<p>8.刷新节点配置，让新节点能被集群感知到</p>
<p>在namenode执行</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hdfs dfsadmin -refreshNodes</span><br></pre></td></tr></table></figure>

<p>9.可以在hadoop管理页面或者使用命令hdfs dfsadmin -report，查看新节点是否加入hdfs集群，使用yarn node -list查看新节点是否加入yarn集群</p>
<p>10.平衡节点数据</p>
<p>在namenode节点执行</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#对hdfs负载设置均衡，因为默认的数据传输带宽比较低，可以设置为64M  </span><br><span class="line">hdfs dfsadmin -setBalancerBandwidth 67108864 </span><br><span class="line"></span><br><span class="line">#默认balancer的threshold为10%，即各个节点与集群总的存储使用率相差不超过10%，我们可将其设置为5%</span><br><span class="line">start-balancer.sh -threshold 5</span><br></pre></td></tr></table></figure>

<p>注意：</p>
<p>1）如果不 balance，那么 cluster 会把新的数据都存放在新的 node 上，这样会降低 mapred 的工作效率<br>2）设置平衡阈值，默认是 10%，值越低各节点越平衡，但消耗时间也更长<br>3）设置 balance 的带宽，默认只有 1M&#x2F;s</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.datanode.balance.bandwidthPerSec&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;64m&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>

<p>11.通过Hadoop管理页面或者hdfs dfsadmin -report命令，查看数据迁移情况</p>
<h2 id="二：删除节点"><a href="#二：删除节点" class="headerlink" title="二：删除节点"></a>二：删除节点</h2><p>注：如果节点想要动态正常下线，除非预先在hdfs-site.xml文件配置了dfs.hosts.exclude，以及yarn-site.xml配置了yarn.resourcemanager.nodes.exclude-path 。否则就只能采用直接在要下线的数据节点进行停止进程，让集群认为这台数据节点进程掉了，自动进行副本转移（采用停进程的方式不能一次性下3台及以上，最好一台台操作）。</p>
<p>1.在dfs.hosts.exclude配置的路径的文件里，添加要下线的机器，一行一个</p>
<p>比如我的配置项</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">　　&lt;!--dfs.hosts.exclude定义的文件内容为,每个需要下线的机器，一行一个--&gt;</span><br><span class="line">　　&lt;name&gt;dfs.hosts.exclude&lt;/name&gt;</span><br><span class="line">　　&lt;value&gt;/home/zhouhj/app/hadoop-3.2.2/etc/hadoop/excludes&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>

<p>2.刷新节点配置</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hdfs dfsadmin -refreshNodes</span><br><span class="line">yarn rmadmin -refreshNodes</span><br></pre></td></tr></table></figure>

<p>3.观察集群情况</p>
<p>此时在Hadoop管理页面可以看到Decommissioning Nodes的数量为刚刚在excludes里添加的数量，等副本迁移完成之后，这些节点状态会变成Decommissioned。或者使用hadoop dfsadmin -report以及yarn node -list查看，也能看到相关信息</p>
<p>4.待观察到节点状态变成Decommissioned之后，就可以停这台节点上的进程了</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hdfs --daemon stop datanode</span><br><span class="line">yarn --daemon stop nodemanager</span><br></pre></td></tr></table></figure>

<p>5.在&#x2F;home&#x2F;zhouhj&#x2F;app&#x2F;hadoop-3.2.2&#x2F;etc&#x2F;hadoop&#x2F;workers中删除对应节点</p>
<h2 id="三：重新加入删除的节点"><a href="#三：重新加入删除的节点" class="headerlink" title="三：重新加入删除的节点"></a>三：重新加入删除的节点</h2><p>1.在excludes文件中删除相关节点</p>
<p>2.在&#x2F;home&#x2F;zhouhj&#x2F;app&#x2F;hadoop-3.2.2&#x2F;etc&#x2F;hadoop&#x2F;workers中加入对应节点</p>
<p>3.在节点上启动进程</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hdfs --daemon start datanode</span><br><span class="line">yarn --daemon start nodemanager</span><br></pre></td></tr></table></figure>

<p>4.刷新节点配置</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hdfs dfsadmin -refreshNodes</span><br><span class="line">yarn rmadmin -refreshNodes</span><br></pre></td></tr></table></figure>

<p>5.平衡节点数据</p>
<p>参考新增节点平衡数据</p>
]]></content>
      <categories>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>Hive自定义函数UDF、UDAF、UDTF</title>
    <url>/2024/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hive%E8%87%AA%E5%AE%9A%E4%B9%89%E5%87%BD%E6%95%B0UDF%E3%80%81UDAF%E3%80%81UDTF/</url>
    <content><![CDATA[<h2 id="自定义函数的种类"><a href="#自定义函数的种类" class="headerlink" title="自定义函数的种类"></a>自定义函数的种类</h2><p>UDF：一进一出，一对一的关系数据，例如substring、replace等</p>
<p>UDAF：多进一出，多对一的关系数据，例如sum、avg等</p>
<p>UDTF：一进多处，一对多的关系数据，例如collect_set、collect_list等</p>
<h2 id="添加依赖"><a href="#添加依赖" class="headerlink" title="添加依赖"></a>添加依赖</h2><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hive<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hive-exec<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--对应的hive的版本号--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.1.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="UDF函数编写"><a href="#UDF函数编写" class="headerlink" title="UDF函数编写"></a>UDF函数编写</h2><h3 id="1-编写函数"><a href="#1-编写函数" class="headerlink" title="1.编写函数"></a>1.编写函数</h3><p>编写mysubstring(字段，开始位置，结束位置)为例，截取字符串</p>
<p>1.继承org.apache.hadoop.hive.ql.udf.generic.GenericUDF类，有四个函数需要重写</p>
<p>2.代码块</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.zhouhj.tools.hive.udf;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.commons.lang3.StringUtils;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hive.ql.exec.UDFArgumentException;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hive.ql.metadata.HiveException;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hive.ql.udf.generic.GenericUDF;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorConverters.Converter;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector.PrimitiveCategory;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorUtils.PrimitiveGrouping.NUMERIC_GROUP;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorUtils.PrimitiveGrouping.STRING_GROUP;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> ZhouHJ</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MySubstringUDF</span> <span class="keyword">extends</span> <span class="title class_">GenericUDF</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">transient</span> PrimitiveCategory[] inputTypes = <span class="keyword">new</span> <span class="title class_">PrimitiveCategory</span>[<span class="number">3</span>];</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">transient</span> Converter[] converters = <span class="keyword">new</span> <span class="title class_">Converter</span>[<span class="number">3</span>];</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="type">Text</span> <span class="variable">output</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Text</span>();</span><br><span class="line"></span><br><span class="line">    <span class="comment">//校验入参个数等初始化操作，返回类型为自定义函数返回值的类型，可参考GenericUDF类的子类的写法</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> ObjectInspector <span class="title function_">initialize</span><span class="params">(ObjectInspector[] arguments)</span> <span class="keyword">throws</span> UDFArgumentException &#123;</span><br><span class="line">        <span class="comment">//校验参数列表长度</span></span><br><span class="line">        checkArgsSize(arguments, <span class="number">3</span>, <span class="number">3</span>);</span><br><span class="line">        <span class="comment">//用于检查函数的参数是否为原始类型（primitive）。</span></span><br><span class="line">        <span class="comment">// 它的作用是确保函数的参数是可以直接进行计算和操作的基本数据类型，而不是复杂的结构类型（如数组或结构体）。</span></span><br><span class="line">        checkArgPrimitive(arguments, <span class="number">0</span>);</span><br><span class="line">        checkArgPrimitive(arguments, <span class="number">1</span>);</span><br><span class="line">        checkArgPrimitive(arguments, <span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">        checkArgGroups(arguments, <span class="number">0</span>, inputTypes, STRING_GROUP);</span><br><span class="line">        checkArgGroups(arguments, <span class="number">1</span>, inputTypes, NUMERIC_GROUP);</span><br><span class="line">        checkArgGroups(arguments, <span class="number">2</span>, inputTypes, NUMERIC_GROUP);</span><br><span class="line"></span><br><span class="line">        obtainStringConverter(arguments, <span class="number">0</span>, inputTypes, converters);</span><br><span class="line">        obtainIntConverter(arguments, <span class="number">1</span>, inputTypes, converters);</span><br><span class="line">        obtainIntConverter(arguments, <span class="number">2</span>, inputTypes, converters);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> PrimitiveObjectInspectorFactory.writableStringObjectInspector;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//函数逻辑处理</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Object <span class="title function_">evaluate</span><span class="params">(DeferredObject[] arguments)</span> <span class="keyword">throws</span> HiveException &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">str</span> <span class="operator">=</span> getStringValue(arguments, <span class="number">0</span>, converters);</span><br><span class="line">        <span class="keyword">if</span> (StringUtils.isBlank(str)) &#123;</span><br><span class="line">            output.set(<span class="string">&quot;&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> output;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//获取字符串的长度</span></span><br><span class="line">        <span class="type">int</span> <span class="variable">len</span> <span class="operator">=</span> str.length();</span><br><span class="line">        <span class="type">Integer</span> <span class="variable">startIndex</span> <span class="operator">=</span> getIntValue(arguments, <span class="number">1</span>, converters);</span><br><span class="line">        <span class="type">Integer</span> <span class="variable">endIndex</span> <span class="operator">=</span> getIntValue(arguments, <span class="number">2</span>, converters);</span><br><span class="line">        <span class="keyword">if</span> (startIndex &lt; <span class="number">0</span> || startIndex &gt;= len || startIndex &gt; endIndex) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">UDFArgumentException</span>(<span class="string">&quot;startIndex is out of bound&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (endIndex &gt; len) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">UDFArgumentException</span>(<span class="string">&quot;endIndex is out of bound&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="type">String</span> <span class="variable">substring</span> <span class="operator">=</span> str.substring(startIndex, endIndex);</span><br><span class="line">        output.set(substring);</span><br><span class="line">        <span class="keyword">return</span> output;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//explain 执行计划中显示的语句,可不重写内容</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getDisplayString</span><span class="params">(String[] children)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> getStandardDisplayString(getFuncName(), children);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> String <span class="title function_">getFuncName</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;mysubstring&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="2-函数创建使用"><a href="#2-函数创建使用" class="headerlink" title="2.函数创建使用"></a>2.函数创建使用</h3><p>将打好的包上传到hdfs上，例如传到&#x2F;hive&#x2F;lib下</p>
<p>创建函数</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">add</span> jar hdfs:<span class="operator">/</span><span class="operator">/</span><span class="operator">/</span>hive<span class="operator">/</span>lib<span class="operator">/</span>HiveUDF<span class="number">-1.0</span><span class="operator">-</span>SNAPSHOT.jar;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">function</span> mysubstring <span class="keyword">as</span> <span class="string">&#x27;com.zhouhj.tools.hive.udf.MySubstringUDF&#x27;</span> <span class="keyword">USING</span> JAR <span class="string">&#x27;hdfs:///hive/lib/HiveUDF-1.0-SNAPSHOT.jar&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p>使用函数</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> mysubstring(<span class="string">&#x27;abc&#x27;</span>,<span class="number">0</span>,<span class="number">2</span>);</span><br><span class="line">OK</span><br><span class="line">_c0</span><br><span class="line">ab</span><br></pre></td></tr></table></figure>



<h2 id="UDAF函数编写"><a href="#UDAF函数编写" class="headerlink" title="UDAF函数编写"></a>UDAF函数编写</h2><p>编写mysum(字段)为例，求和</p>
<p>Hive UDAF函数编写需要继承org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator类，有7个方法需要重写</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// 确定各个阶段输入输出参数的数据格式ObjectInspectors  </span><br><span class="line">public ObjectInspector init(Mode m, ObjectInspector[] parameters) throws HiveException;</span><br><span class="line">  </span><br><span class="line">// 保存数据聚集结果的类</span><br><span class="line">public abstract AggregationBuffer getNewAggregationBuffer() throws HiveException;</span><br><span class="line">  </span><br><span class="line">// 重置聚集结果</span><br><span class="line">public abstract void reset(AggregationBuffer agg) throws HiveException;</span><br><span class="line">  </span><br><span class="line">// map阶段，迭代处理输入sql传过来的列数据</span><br><span class="line">public abstract void iterate(AggregationBuffer agg, Object[] parameters) throws HiveException;</span><br><span class="line">  </span><br><span class="line">// map与combiner结束返回结果，得到部分数据聚集结果  </span><br><span class="line">public abstract Object terminatePartial(AggregationBuffer agg) throws HiveException; </span><br><span class="line">  </span><br><span class="line">// combiner合并map返回的结果，还有reducer合并mapper或combiner返回的结果。  </span><br><span class="line">public abstract void merge(AggregationBuffer agg, Object partial) throws HiveException;</span><br><span class="line">  </span><br><span class="line">// reducer阶段，输出最终结果  </span><br><span class="line">public abstract Object terminate(AggregationBuffer agg) throws HiveException;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>一般情况下，完整的 UDAF 逻辑是一个 mapreduce 过程，如果有 mapper 和 reducer，就会经历 PARTIAL1 (mapper)，FINAL (reducer)，如果还有 combiner，那就会经历 PARTIAL1 (mapper)，PARTIAL2 (combiner)，FINAL (reducer)。<br>而有一些情况下的 mapreduce，只有 mapper，而没有 reducer，所以就会只有 COMPLETE 阶段，这个阶段直接输入原始数据，出结果。</p>
<p>其中还涉及到一个Model的概念，Model代表了UDAF在MapReduce里的各个阶段</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">enum</span> <span class="title class_">Mode</span> &#123;  </span><br><span class="line">    <span class="comment">/** </span></span><br><span class="line"><span class="comment">     * PARTIAL1: 这个是mapreduce的map阶段:从原始数据到部分数据聚合 </span></span><br><span class="line"><span class="comment">     * 将会调用iterate()和terminatePartial() </span></span><br><span class="line"><span class="comment">     */</span>  </span><br><span class="line">    PARTIAL1,  </span><br><span class="line">        <span class="comment">/** </span></span><br><span class="line"><span class="comment">     * PARTIAL2: 这个是mapreduce的map端的Combiner阶段，负责在map端合并map的数据::从部分数据聚合到部分数据聚合: </span></span><br><span class="line"><span class="comment">     * 将会调用merge() 和 terminatePartial()  </span></span><br><span class="line"><span class="comment">     */</span>  </span><br><span class="line">    PARTIAL2,  </span><br><span class="line">        <span class="comment">/** </span></span><br><span class="line"><span class="comment">     * FINAL: mapreduce的reduce阶段:从部分数据的聚合到完全聚合  </span></span><br><span class="line"><span class="comment">     * 将会调用merge()和terminate() </span></span><br><span class="line"><span class="comment">     */</span>  </span><br><span class="line">    FINAL,  </span><br><span class="line">        <span class="comment">/** </span></span><br><span class="line"><span class="comment">     * COMPLETE: 如果出现了这个阶段，表示mapreduce只有map，没有reduce，所以map端就直接出结果了:从原始数据直接到完全聚合 </span></span><br><span class="line"><span class="comment">      * 将会调用 iterate()和terminate() </span></span><br><span class="line"><span class="comment">     */</span>  </span><br><span class="line">    COMPLETE  </span><br><span class="line">  &#125;;  </span><br></pre></td></tr></table></figure>

<p>图解函数调用过程</p>
<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20240428155653.png" alt="image-20240428155645922" style="zoom:50%;" />

<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20240428155732.png" alt="image-20240428155732761" style="zoom: 67%;" />

<h3 id="1-自定义函数类"><a href="#1-自定义函数类" class="headerlink" title="1.自定义函数类"></a>1.自定义函数类</h3><p>新建MySumUDAF类，继承AbstractGenericUDAFResolver类，重写两个方法，返回处理类</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MySumUDAF</span> <span class="keyword">extends</span> <span class="title class_">AbstractGenericUDAFResolver</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> GenericUDAFEvaluator <span class="title function_">getEvaluator</span><span class="params">(GenericUDAFParameterInfo info)</span> <span class="keyword">throws</span> SemanticException &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">MySumUDAFEvaluator</span>();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> GenericUDAFEvaluator <span class="title function_">getEvaluator</span><span class="params">(TypeInfo[] info)</span> <span class="keyword">throws</span> SemanticException &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">MySumUDAFEvaluator</span>();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="2-自定义处理类"><a href="#2-自定义处理类" class="headerlink" title="2.自定义处理类"></a>2.自定义处理类</h3><p>新建MySumUDAFEvaluator类，继承org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator类，重写上述七个方法</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">MySumUDAFEvaluator</span> <span class="keyword">extends</span> <span class="title class_">GenericUDAFEvaluator</span>&#123;&#125;</span><br></pre></td></tr></table></figure>

<p>创建三个变量</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 输入的参数类型</span></span><br><span class="line"><span class="keyword">private</span> PrimitiveObjectInspector in;</span><br><span class="line"><span class="comment">// 输出的参数类型</span></span><br><span class="line"><span class="keyword">private</span> ObjectInspector out;</span><br><span class="line"><span class="comment">// 中间过程数据类型</span></span><br><span class="line"><span class="keyword">private</span> PrimitiveObjectInspector buffer;</span><br></pre></td></tr></table></figure>

<h3 id="3-重写init方法"><a href="#3-重写init方法" class="headerlink" title="3.重写init方法"></a>3.重写init方法</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> ObjectInspector <span class="title function_">init</span><span class="params">(Mode m, ObjectInspector[] parameters)</span> <span class="keyword">throws</span> HiveException &#123;</span><br><span class="line">    <span class="built_in">super</span>.init(m, parameters);</span><br><span class="line">    <span class="comment">//map阶段读取sql列，输入为String基础数据格式</span></span><br><span class="line">    <span class="keyword">if</span> (Mode.PARTIAL1.equals(m) || Mode.COMPLETE.equals(m)) &#123;</span><br><span class="line">        in = (PrimitiveObjectInspector) parameters[<span class="number">0</span>];</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// 其他阶段，处理与聚合结果，输入为Integer基础数据格式</span></span><br><span class="line">        buffer = (PrimitiveObjectInspector) parameters[<span class="number">0</span>];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//指定输出类型为Integer类型</span></span><br><span class="line">    out = ObjectInspectorFactory.getReflectionObjectInspector(Integer.class, ObjectInspectorFactory.ObjectInspectorOptions.JAVA);</span><br><span class="line">    <span class="keyword">return</span> out;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="4-重写getNewAggregationBuffer方法"><a href="#4-重写getNewAggregationBuffer方法" class="headerlink" title="4.重写getNewAggregationBuffer方法"></a>4.重写getNewAggregationBuffer方法</h3><p>该方法用于获取缓存类</p>
<p>新建MySumBuffer缓存类</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">MySumBuffer</span> <span class="keyword">extends</span> <span class="title class_">AbstractAggregationBuffer</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">MySumBuffer</span><span class="params">()</span> &#123;</span><br><span class="line">        sum=<span class="number">0L</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">private</span> Long sum;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">add</span><span class="params">(Long num)</span> &#123;</span><br><span class="line">        sum += num;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> Long <span class="title function_">getSum</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> sum;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">reset</span><span class="params">()</span> &#123;</span><br><span class="line">        sum = <span class="number">0L</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>重写getNewAggregationBuffer方法</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> AggregationBuffer <span class="title function_">getNewAggregationBuffer</span><span class="params">()</span> <span class="keyword">throws</span> HiveException &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">MySumBuffer</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="5-重写iterate方法"><a href="#5-重写iterate方法" class="headerlink" title="5.重写iterate方法"></a>5.重写iterate方法</h3><p>每行hive数据会调用一次该方法</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">iterate</span><span class="params">(AggregationBuffer agg, Object[] parameters)</span> <span class="keyword">throws</span> HiveException &#123;</span><br><span class="line">    <span class="type">Object</span> <span class="variable">obj</span> <span class="operator">=</span> in.getPrimitiveJavaObject(parameters[<span class="number">0</span>]);</span><br><span class="line">    ((MySumBuffer) agg).add(Long.parseLong(obj.toString()));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="6-重写merge方法"><a href="#6-重写merge方法" class="headerlink" title="6.重写merge方法"></a>6.重写merge方法</h3><p>Partial2 阶段和 final 阶段都会调用，聚合 buffer 中的数据</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 合并缓冲区,对于combine、reduce阶段</span></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">merge</span><span class="params">(AggregationBuffer agg, Object partial)</span> <span class="keyword">throws</span> HiveException &#123;</span><br><span class="line">    <span class="keyword">if</span> (Objects.nonNull(partial)) &#123;</span><br><span class="line">        <span class="type">Long</span> <span class="variable">in</span> <span class="operator">=</span> (Long) buffer.getPrimitiveJavaObject(partial);</span><br><span class="line">        ((MySumBuffer) agg).add(in);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="7-重写terminatePartial方法"><a href="#7-重写terminatePartial方法" class="headerlink" title="7.重写terminatePartial方法"></a>7.重写terminatePartial方法</h3><p>预聚合，对于combine阶段。由于这里自定义的是求和函数，因此这里预聚合和最终聚合操作一样</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> Object <span class="title function_">terminatePartial</span><span class="params">(AggregationBuffer agg)</span> <span class="keyword">throws</span> HiveException &#123;</span><br><span class="line">    <span class="keyword">return</span> terminate(agg);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="8-重写terminate方法"><a href="#8-重写terminate方法" class="headerlink" title="8.重写terminate方法"></a>8.重写terminate方法</h3><p>final 阶段调用，会聚合最终结果</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> Object <span class="title function_">terminate</span><span class="params">(AggregationBuffer agg)</span> <span class="keyword">throws</span> HiveException &#123;</span><br><span class="line">    <span class="keyword">return</span> ((MySumBuffer) agg).getSum();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="9-重写reset方法"><a href="#9-重写reset方法" class="headerlink" title="9.重写reset方法"></a>9.重写reset方法</h3><p>重置缓存类</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">reset</span><span class="params">(AggregationBuffer agg)</span> <span class="keyword">throws</span> HiveException &#123;</span><br><span class="line">    ((MySumBuffer) agg).reset();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="10-函数创建使用"><a href="#10-函数创建使用" class="headerlink" title="10.函数创建使用"></a>10.函数创建使用</h3><p>将打好的包上传到hdfs上，例如传到&#x2F;hive&#x2F;lib下</p>
<p>创建函数</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">add</span> jar hdfs:<span class="operator">/</span><span class="operator">/</span><span class="operator">/</span>hive<span class="operator">/</span>lib<span class="operator">/</span>HiveUDF<span class="number">-1.0</span><span class="operator">-</span>SNAPSHOT.jar;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">function</span> mysum <span class="keyword">as</span>  <span class="string">&#x27;com.zhouhj.tools.hive.udaf.MySumUDF&#x27;</span> <span class="keyword">USING</span> JAR <span class="string">&#x27;hdfs:///hive/lib/HiveUDF-1.0-SNAPSHOT.jar&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p>使用函数</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> mysum(a) <span class="keyword">from</span> e3;</span><br><span class="line">OK</span><br><span class="line">_c0</span><br><span class="line"><span class="number">17</span></span><br></pre></td></tr></table></figure>

<h2 id="UDTF函数编写"><a href="#UDTF函数编写" class="headerlink" title="UDTF函数编写"></a>UDTF函数编写</h2><h3 id="1-编写函数-1"><a href="#1-编写函数-1" class="headerlink" title="1.编写函数"></a>1.编写函数</h3><p>编写mysplit(字段,分隔符)为例，分割字符串</p>
<p>1.继承org.apache.hadoop.hive.ql.udf.generic.GenericUDTF类，有三个函数需要重写</p>
<p>2.代码块</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.zhouhj.tools.hive.udtf;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hive.ql.exec.UDFArgumentException;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hive.ql.metadata.HiveException;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hive.ql.udf.generic.GenericUDTF;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorFactory;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MySplitUDTF</span> <span class="keyword">extends</span> <span class="title class_">GenericUDTF</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> StructObjectInspector <span class="title function_">initialize</span><span class="params">(StructObjectInspector argOIs)</span> <span class="keyword">throws</span> UDFArgumentException &#123;</span><br><span class="line">        List&lt;String&gt; fieldsNameList = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">        <span class="comment">//查询输出数据的默认列名</span></span><br><span class="line">        fieldsNameList.add(<span class="string">&quot;_c0&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//输出的数据类型</span></span><br><span class="line">        List&lt;ObjectInspector&gt; fieldsOutPutOIList = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">        fieldsOutPutOIList.add(PrimitiveObjectInspectorFactory.javaStringObjectInspector);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//最终返回值,字段名，字段类型</span></span><br><span class="line">        <span class="keyword">return</span> ObjectInspectorFactory.getStandardStructObjectInspector(fieldsNameList, fieldsOutPutOIList);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">process</span><span class="params">(Object[] args)</span> <span class="keyword">throws</span> HiveException &#123;</span><br><span class="line">        <span class="comment">//校验参数个数</span></span><br><span class="line">        <span class="keyword">if</span> (args.length != <span class="number">2</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">HiveException</span>(<span class="string">&quot;args must be(str,splitKey)&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="type">String</span> <span class="variable">str</span> <span class="operator">=</span> args[<span class="number">0</span>].toString();</span><br><span class="line">        <span class="type">String</span> <span class="variable">splitKey</span> <span class="operator">=</span> args[<span class="number">1</span>].toString();</span><br><span class="line">        String[] strArr = str.split(splitKey);</span><br><span class="line">        <span class="comment">//这里一进多出，就像是map或者reduce的写出过程 context.write(key,value)</span></span><br><span class="line">        <span class="comment">//只不过在hive中是forward</span></span><br><span class="line">        <span class="keyword">for</span> (String s : strArr) &#123;</span><br><span class="line">            forward(s);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span> <span class="keyword">throws</span> HiveException &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="2-函数创建使用-1"><a href="#2-函数创建使用-1" class="headerlink" title="2.函数创建使用"></a>2.函数创建使用</h3><p>将打好的包上传到hdfs上，例如传到&#x2F;hive&#x2F;lib下</p>
<p>创建函数</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">add</span> jar hdfs:<span class="operator">/</span><span class="operator">/</span><span class="operator">/</span>hive<span class="operator">/</span>lib<span class="operator">/</span>HiveUDF<span class="number">-1.0</span><span class="operator">-</span>SNAPSHOT.jar;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">function</span> mysplitas <span class="string">&#x27;com.zhouhj.tools.hive.udf.MySplitUDTF&#x27;</span> <span class="keyword">USING</span> JAR <span class="string">&#x27;hdfs:///hive/lib/HiveUDF-1.0-SNAPSHOT.jar&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p>使用函数</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> mysplit(<span class="string">&#x27;a;b;c&#x27;</span>,<span class="string">&#x27;;&#x27;</span>);</span><br><span class="line">OK</span><br><span class="line">_c0</span><br><span class="line">a</span><br><span class="line">b</span><br><span class="line">c</span><br></pre></td></tr></table></figure>

<h2 id="UDF管理"><a href="#UDF管理" class="headerlink" title="UDF管理"></a>UDF管理</h2><p>以下操作如果 hiveserver2 是使用的 vip，则需要使用 beeline 连接每台 hiveserver2 上去，都执行一遍。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">添加jar包（推荐使用hdfs方式，本地包也可以，但是麻烦）如果自定义函数里有使用到第三方的jar包，也需要使用这种方式添加到hive里</span><br><span class="line"><span class="keyword">add</span> jar hdfs:<span class="operator">/</span><span class="operator">/</span><span class="operator">/</span>hive<span class="operator">/</span>lib<span class="operator">/</span>HiveUDF<span class="number">-1.0</span><span class="operator">-</span>SNAPSHOT.jar;</span><br><span class="line"></span><br><span class="line">创建函数(如果是在beeline连接创建的，则只有beeline连接的那台hiveserver2有效，其他的无效)</span><br><span class="line">如果是在hive shell执行，则对hive集群的所有hive shell都生效，对beeline无效。hive集群重启之后，对beeline也有效</span><br><span class="line"><span class="keyword">create</span> [temporary] <span class="keyword">function</span> mysum <span class="keyword">as</span>  <span class="string">&#x27;com.zhouhj.tools.hive.udaf.MySumUDF&#x27;</span> [<span class="keyword">USING</span> JAR <span class="string">&#x27;hdfs:///hive/lib/HiveUDF-1.0-SNAPSHOT.jar&#x27;</span>];</span><br><span class="line"></span><br><span class="line">删除函数(需要在所有 hiveserver2 节点删除，只在一个节点上操作，用 beeline 连接其他节点 UDF 函数还会存在。或者只 beeline 一个 hiveserver2 删除，重启所有 hiveserver2 后，生效)</span><br><span class="line"><span class="keyword">drop</span> [temporary] <span class="keyword">function</span> [if <span class="keyword">exists</span>] mysum;</span><br><span class="line"></span><br><span class="line">删除jar包</span><br><span class="line"><span class="keyword">delete</span> jar hdfs:<span class="operator">/</span><span class="operator">/</span><span class="operator">/</span>hive<span class="operator">/</span>lib<span class="operator">/</span>HiveUDF<span class="number">-1.0</span><span class="operator">-</span>SNAPSHOT.jar;</span><br><span class="line"></span><br><span class="line">更新UDF函数的话需要先走删除UDF函数、删除jar包、再新增jar包、新增函数的方式</span><br></pre></td></tr></table></figure>

<p>参考：</p>
<p><a href="https://blog.csdn.net/weixin_46429290/article/details/126634429">https://blog.csdn.net/weixin_46429290/article/details/126634429</a></p>
<p><a href="https://blog.csdn.net/nmsLLCSDN/article/details/125833600">https://blog.csdn.net/nmsLLCSDN/article/details/125833600</a></p>
<p><a href="https://mp.weixin.qq.com/s/9jGlRDfTW_G4TV7WHmHMdw">https://mp.weixin.qq.com/s/9jGlRDfTW_G4TV7WHmHMdw</a></p>
<p><a href="https://mp.weixin.qq.com/s/s3d2VGT_vQvZ12bNoIWNOg">https://mp.weixin.qq.com/s/s3d2VGT_vQvZ12bNoIWNOg</a></p>
<p><a href="https://blog.csdn.net/zyz_home/article/details/79889519">https://blog.csdn.net/zyz_home/article/details/79889519</a></p>
]]></content>
      <categories>
        <category>Hive</category>
      </categories>
      <tags>
        <tag>UDF</tag>
        <tag>Hive</tag>
        <tag>UDAF</tag>
        <tag>UDTF</tag>
      </tags>
  </entry>
  <entry>
    <title>Phoenix自定义函数UDF</title>
    <url>/2023/%E5%A4%A7%E6%95%B0%E6%8D%AE/Phoenix%E8%87%AA%E5%AE%9A%E4%B9%89%E5%87%BD%E6%95%B0UDF/</url>
    <content><![CDATA[<h2 id="以自定义函数生成rowkey前缀为例"><a href="#以自定义函数生成rowkey前缀为例" class="headerlink" title="以自定义函数生成rowkey前缀为例"></a>以自定义函数生成rowkey前缀为例</h2><h3 id="一：依赖"><a href="#一：依赖" class="headerlink" title="一：依赖"></a>一：依赖</h3><p>要自定义phoenix函数，必须有以下依赖</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.phoenix<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>phoenix-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--对应的phoenix的版本号--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>5.1.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="二：代码"><a href="#二：代码" class="headerlink" title="二：代码"></a>二：代码</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.zhouhj.tools.phoenix.udf;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.io.ImmutableBytesWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.phoenix.expression.Expression;</span><br><span class="line"><span class="keyword">import</span> org.apache.phoenix.expression.function.ScalarFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.phoenix.parse.FunctionParseNode;</span><br><span class="line"><span class="keyword">import</span> org.apache.phoenix.schema.tuple.Tuple;</span><br><span class="line"><span class="keyword">import</span> org.apache.phoenix.schema.types.PDataType;</span><br><span class="line"><span class="keyword">import</span> org.apache.phoenix.schema.types.PVarchar;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.security.MessageDigest;</span><br><span class="line"><span class="keyword">import</span> java.security.NoSuchAlgorithmException;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="meta">@FunctionParseNode</span>.BuiltInFunction(</span><br><span class="line">        name = <span class="string">&quot;rk&quot;</span>,</span><br><span class="line">        args = &#123;<span class="meta">@FunctionParseNode</span>.Argument(</span><br><span class="line">                allowedTypes = &#123;PVarchar.class&#125;</span><br><span class="line">        )&#125;</span><br><span class="line">)</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">RowKeyFunction</span> <span class="keyword">extends</span> <span class="title class_">ScalarFunction</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">String</span> <span class="variable">NAME</span> <span class="operator">=</span> <span class="string">&quot;rk&quot;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">RowKeyFunction</span><span class="params">()</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">RowKeyFunction</span><span class="params">(List&lt;Expression&gt; children)</span> &#123;</span><br><span class="line">        <span class="built_in">super</span>(children);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getName</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> NAME;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">evaluate</span><span class="params">(Tuple tuple, ImmutableBytesWritable ptr)</span> &#123;</span><br><span class="line">        <span class="type">Expression</span> <span class="variable">idExp</span> <span class="operator">=</span> <span class="built_in">this</span>.getIdExpression();</span><br><span class="line">        <span class="keyword">if</span> (!idExp.evaluate(tuple, ptr)) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="type">String</span> <span class="variable">userId</span> <span class="operator">=</span> (String) PVarchar.INSTANCE.toObject(ptr, idExp.getSortOrder());</span><br><span class="line">            <span class="type">String</span> <span class="variable">rowKey</span> <span class="operator">=</span> <span class="built_in">this</span>.getRowKey(userId, <span class="string">&quot;%&quot;</span>);</span><br><span class="line">            ptr.set(PVarchar.INSTANCE.toBytes(rowKey));</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> PDataType <span class="title function_">getDataType</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> PVarchar.INSTANCE;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Expression <span class="title function_">getIdExpression</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">this</span>.children.get(<span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> String <span class="title function_">getRowKey</span><span class="params">(String userId, String def)</span> &#123;</span><br><span class="line">        <span class="type">StringBuilder</span> <span class="variable">sb</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StringBuilder</span>();</span><br><span class="line">        <span class="comment">//此处省略业务</span></span><br><span class="line">        <span class="keyword">return</span> sb.toString();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="三：打包"><a href="#三：打包" class="headerlink" title="三：打包"></a>三：打包</h3><p>1.将自定义函数打成jar包</p>
<p>2.将自定义函数里用到的第三方的lib包也要拿出来（除HBase、Hadoop、Phoenix相关包以外）。比如额外引入了hutool且自定义函数里使用了的话，就需要hutool的lib包</p>
<h3 id="四：部署"><a href="#四：部署" class="headerlink" title="四：部署"></a>四：部署</h3><h4 id="1-配置修改"><a href="#1-配置修改" class="headerlink" title="1.配置修改"></a>1.配置修改</h4><p>修改hbase-site.xml</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;!-- phoenix支持自定义函数 -- &gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;phoenix.functions.allowUserDefinedFunctions&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 自定义函数，存储jar的hdfs目录 -- &gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hbase.dynamic.jars.dir&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;填写准备放自定义jar的地方，除了这个路径，jar放在其他路径哪怕指定了都没用。默认值是$&#123;hbase.rootdir&#125;/lib&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>

<h4 id="2-包部署"><a href="#2-包部署" class="headerlink" title="2.包部署"></a>2.包部署</h4><p>将自定义的jar包和所依赖的jar包，放到hbase.dynamic.jars.dir配置的路径下</p>
<h4 id="3-函数注册"><a href="#3-函数注册" class="headerlink" title="3.函数注册"></a>3.函数注册</h4><p>进入phoenix客户端</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">注册永久函数</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">FUNCTION</span> rk(<span class="type">varchar</span>) <span class="keyword">returns</span> <span class="type">varchar</span> <span class="keyword">as</span> <span class="string">&#x27;com.zhouhj.tools.phoenix.udf.RowKeyFunction&#x27;</span> <span class="keyword">using</span> jar <span class="string">&#x27;hdfs://mycluster/hbase/lib/PhoenixUDF.jar&#x27;</span>;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">FUNCTION</span> rk(<span class="type">varchar</span>) <span class="keyword">returns</span> <span class="type">varchar</span> <span class="keyword">as</span> <span class="string">&#x27;com.zhouhj.tools.phoenix.udf.RowKeyFunction&#x27;</span> <span class="keyword">using</span> jar <span class="string">&#x27;/hbase/lib/PhoenixUDF.jar&#x27;</span>;</span><br><span class="line"></span><br><span class="line">如果目录下没有其他包里的类会冲突的话，可以不需要指定jar</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">FUNCTION</span> rk(<span class="type">varchar</span>) <span class="keyword">returns</span> <span class="type">varchar</span> <span class="keyword">as</span> <span class="string">&#x27;com.zhouhj.tools.phoenix.udf.RowKeyFunction&#x27;</span>;</span><br><span class="line"></span><br><span class="line">注册临时函数</span><br><span class="line"><span class="keyword">CREATE</span> TEMPORARY <span class="keyword">FUNCTION</span> ...</span><br><span class="line"></span><br><span class="line">如果注册路径错了，需要删除函数，使用以下语句</span><br><span class="line"><span class="keyword">DROP</span> <span class="keyword">FUNCTION</span> IF <span class="keyword">EXISTS</span> rk;</span><br></pre></td></tr></table></figure>

<p>注意：</p>
<p>1.如果使用jdbc连接，需要指定phoenix.functions.allowUserDefinedFunctions的值，例如：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">Properties</span> <span class="variable">props</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line">props.setProperty(<span class="string">&quot;phoenix.functions.allowUserDefinedFunctions&quot;</span>, <span class="string">&quot;true&quot;</span>);</span><br><span class="line"><span class="type">Connection</span> <span class="variable">conn</span> <span class="operator">=</span> DriverManager.getConnection(<span class="string">&quot;jdbc:phoenix:localhost&quot;</span>, props);</span><br></pre></td></tr></table></figure>

<p>2.如果是在程序中，如java、jdbc等使用到该函数，程序运行时，会将该jar复制到本地的hbase.local.dir路径下，默认是</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hbase.local.dir&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;$&#123;hbase.tmp.dir&#125;/local/&lt;/value&gt;</span><br><span class="line">  &lt;description&gt;Directory on the local filesystem to be used</span><br><span class="line">    as a local storage.&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>

<p>详见官网</p>
<p><a href="https://phoenix.apache.org/udf.html">https://phoenix.apache.org/udf.html</a></p>
<h4 id="4-使用函数"><a href="#4-使用函数" class="headerlink" title="4.使用函数"></a>4.使用函数</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">0: jdbc:phoenix:&gt; select rk(&#x27;abc&#x27;) as id;</span><br><span class="line">+---------+</span><br><span class="line">|   ID    |</span><br><span class="line">+---------+</span><br><span class="line">| 0593abc% |</span><br><span class="line">+---------+</span><br><span class="line">1 row selected (0.007 seconds)</span><br><span class="line">也可传入字段例如</span><br><span class="line">select * from xxx where id like rk(user_no);</span><br></pre></td></tr></table></figure>

<h4 id="5-补充说明"><a href="#5-补充说明" class="headerlink" title="5.补充说明"></a>5.补充说明</h4><p>1.自定义jar包只能放在hbase-site.xml里配置的hbase.dynamic.jars.dir路径下，放其他路径哪怕注册函数时使用using jar的语法指定了路径也不行</p>
<p>2.注册函数后，第一次使用自定义函数时，phoenix客户端会将hbase.dynamic.jars.dir路径下的所有jar包，下载到本地的hbase.local.dir路径作为本地缓存。后续如果Phoenix客户端重启，如果本地这个jar包存在的话，会从本地加载这个类到内存。所以，如果自定义函数有修改需要换包的话，这个路径下的包记得删除让他重新从hdfs上拉取。</p>
<p>3.查看有哪些自定义函数<br>select * from SYSTEM.”FUNCTION”;</p>
<p><img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20240428143156.png" alt="image-20240428143007559"></p>
]]></content>
      <categories>
        <category>Phoenix</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>Phoenix</tag>
        <tag>UDF</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL学习笔记</title>
    <url>/2021/MySQL/MySQL%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h1 id="MySQL学习笔记"><a href="#MySQL学习笔记" class="headerlink" title="MySQL学习笔记"></a>MySQL学习笔记</h1><h2 id="MySQL基本架构"><a href="#MySQL基本架构" class="headerlink" title="MySQL基本架构"></a>MySQL基本架构</h2><p>MySQL分为Server层和存储引擎层两部分，Server层包括连接器、 查询缓存、 分析器、 优化器、 执行器等， 涵盖MySQL的大多数核心服务功能， 以及所有的内置函数（如日期、 时间、 数学和加密函数等） ， 所有跨存储引擎的功能都在这一层实现， 比如存储过程、 触发器、 视图等。而存储引擎层负责数据的存储和提取。 其架构模式是插件式的， 支持InnoDB、 MyISAM、Memory等多个存储引擎。 现在最常用的存储引擎是InnoDB， 它从MySQL 5.5.5版本开始成为了默认存储引擎。</p>
<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20221031174345.png" style="width: 50%;" />

<h3 id="连接器"><a href="#连接器" class="headerlink" title="连接器"></a>连接器</h3><p>主要负责跟客户端建立连接、获取权限、管理连接等工作。连接器会负责校验用户名密码，当用户名密码通过校验后，会到权限表获取当前用户的权限，这个连接里面的权限判断逻辑， 都将依赖于此时读到的权限 。</p>
<p>连接之后默认处于空闲状态，如果客户端长时间没有动作，且超过参数wait_timeout配置的超时时间（默认8小时），则会自动断开连接。</p>
<p>长连接是指连接成功后， 如果客户端持续有请求， 则一直使用同一个连接。</p>
<p>短连接则是指每次执行完很少的几次查询就断开连接， 下次查询再重新建立一个。</p>
<p>建立连接是一个比较复杂的过程，尽量使用长连接。但是都用长连接会导致MySQL内存涨的比较快，因为MySQL在执行过程中临时使用的内存是管理在对象里面的，这些资源在连接断开时才释放。所以长连接累积下来，会导致内存占用太大，被系统强行杀掉（OOM）。</p>
<p>解决：1.定期断开长连接  2.如果用的是MySQL5.7及以上版本，可以在每次执行一个较大操作后，通过执行mysql_reset_connection来重新初始化连接资源。 这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。  </p>
<h3 id="查询缓存"><a href="#查询缓存" class="headerlink" title="查询缓存"></a>查询缓存</h3><p>MySQL如果开启查询缓存的话，会在拿到一个查询请求之后，先到查询缓存判断查询缓存中是否有该语句及结果，有的话直接返回，没有的话才会继续执行后续操作。</p>
<p>执行过的语句以及结果会以key-value对的形式，被直接缓存在内存中，key是查询语句，value是查询的结果。</p>
<p><strong>不建议用查询缓存，弊大于利</strong></p>
<p>查询缓存失效很频繁，只要对一个表有更新操作，查询缓存上关于这个表的所有缓存结果都会被清空。</p>
<p>对于频繁更新的表不建议用查询缓存，对于静态表，比如历史数据或者系统配置数据等，才适合用查询缓存。</p>
<p>将参数<strong>query_cache_type</strong>设置成DEMAND， 这样对于默认的SQL语句都不使用查询缓存。 而对于你确定要使用查询缓存的语<br>句， 可以用SQL_CACHE显式指定， 像下面这个语句一样：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">select</span> SQL_CACHE <span class="operator">*</span> <span class="keyword">from</span> T <span class="keyword">where</span> ID<span class="operator">=</span><span class="number">10</span>；</span><br></pre></td></tr></table></figure>

<p>MySQL8.0开始，移除了查询缓存功能。</p>
<h3 id="分析器"><a href="#分析器" class="headerlink" title="分析器"></a>分析器</h3><p>主要先进行“词法分析”，再进行“语法分析”。</p>
<p>先分析一条SQL语句里面的字符串分表是什么，代表什么，再根据语法规则，分析这个SQL语句是否满足MySQL语法。</p>
<h3 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h3><p>经过分析器之后，MySQL就知道这条SQL语句要做什么了，但是在执行之前，还要先经过优化器的处理。</p>
<p>优化器是在表里面有多个索引的时候， 决定使用哪个索引； 或者在一个语句有多表关联（join）的时候， 决定各个表的连接顺序。</p>
<p>优化器阶段完成后， 这个语句的执行方案就确定下来了，然后进入执行器阶段。</p>
<h3 id="执行器"><a href="#执行器" class="headerlink" title="执行器"></a>执行器</h3><p>MySQL通过分析器，知道了一条SQL语句要做什么，通过优化器，知道了一条SQL语句要怎么做，接下来就是执行阶段。</p>
<p>执行的时候要先判断你对这个表是否有相应的权限，没有的话会返回权限的错误，有权限的话就打开表继续执行。打开表的时候会根据表的引擎定义，去使用这个引擎提供的接口。</p>
<p>比如查询语句select  * from T where ID&#x3D;10；</p>
<p>表T， ID字段没有索引， 那么执行器的执行流程是这样的：</p>
<ol>
<li>调用InnoDB引擎接口取这个表的第一行， 判断ID值是不是10， 如果不是则跳过， 如果是则<br>将这行存在结果集中；</li>
<li>调用引擎接口取“下一行”， 重复相同的判断逻辑， 直到取到这个表的最后一行。</li>
<li>执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。<br>至此， 这个语句就执行完成了。</li>
</ol>
<p>数据库的慢查询日志中看到一个<strong>rows_examined</strong>的字段， 表示这个语句执行过程中扫描了多少行。 这个值就是在执行器每次调用引擎获取数据行的时候累加的。在有些场景下， 执行器调用一次， 在引擎内部则扫描了多行， 因此引擎扫描行数跟rows_examined并不是完全相同的。  </p>
<h2 id="执行时间查看"><a href="#执行时间查看" class="headerlink" title="执行时间查看"></a>执行时间查看</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql&gt; set profiling=1;</span><br><span class="line">Query OK, 0 rows affected, 1 warning (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; select * from t;</span><br><span class="line">+----+------+------+</span><br><span class="line">| id | c    | d    |</span><br><span class="line">+----+------+------+</span><br><span class="line">|  0 |    0 |    0 |</span><br><span class="line">|  5 |    5 |    5 |</span><br><span class="line">| 10 |   10 |   10 |</span><br><span class="line">| 15 |   15 |   15 |</span><br><span class="line">| 20 |   20 |   20 |</span><br><span class="line">| 25 |   25 |   25 |</span><br><span class="line">+----+------+------+</span><br><span class="line">6 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; show profiles;</span><br><span class="line">+----------+------------+-----------------+</span><br><span class="line">| Query_ID | Duration   | Query           |</span><br><span class="line">+----------+------------+-----------------+</span><br><span class="line">|        1 | 0.00035500 | select * from t |</span><br><span class="line">+----------+------------+-----------------+</span><br><span class="line">1 row in set, 1 warning (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; show profile;（默认查看最近执行的一条，指定查询：show profile for query $(query_id)）</span><br><span class="line">+----------------------+----------+</span><br><span class="line">| Status               | Duration |</span><br><span class="line">+----------------------+----------+</span><br><span class="line">| starting             | 0.000049 |</span><br><span class="line">| checking permissions | 0.000004 |</span><br><span class="line">| Opening tables       | 0.000013 |</span><br><span class="line">| init                 | 0.000013 |</span><br><span class="line">| System lock          | 0.000005 |</span><br><span class="line">| optimizing           | 0.000002 |</span><br><span class="line">| statistics           | 0.000007 |</span><br><span class="line">| preparing            | 0.000018 |</span><br><span class="line">| executing            | 0.000002 |</span><br><span class="line">| Sending data         | 0.000032 |</span><br><span class="line">| end                  | 0.000002 |</span><br><span class="line">| query end            | 0.000005 |</span><br><span class="line">| closing tables       | 0.000003 |</span><br><span class="line">| freeing items        | 0.000196 |</span><br><span class="line">| cleaning up          | 0.000006 |</span><br><span class="line">+----------------------+----------+</span><br><span class="line">15 rows in set, 1 warning (0.00 sec)</span><br></pre></td></tr></table></figure>

<h2 id=""><a href="#" class="headerlink" title=""></a></h2><h2 id="redo-log-重做日志-和binlog-归档日志"><a href="#redo-log-重做日志-和binlog-归档日志" class="headerlink" title="redo log(重做日志)和binlog(归档日志)"></a>redo log(重做日志)和binlog(归档日志)</h2><h3 id="redo-log-重做日志"><a href="#redo-log-重做日志" class="headerlink" title="redo log(重做日志)"></a>redo log(重做日志)</h3><p>redo log是引擎层的日志，是InnoDB特有的。redo log是物理日志， 记录的是“在某个数据页上做了什么修改”。 </p>
<p>redo log其实用到的是WAL技术，<strong>WAL的全称是Write Ahead Logging</strong>， 它的关键点就是先写日志， 再写磁盘 。</p>
<p>具体来说， 当有一条记录需要更新的时候， InnoDB引擎就会先把记录写到redo log 里面， 并更新内存， 这个时候更新就算完成了。 同时， InnoDB引擎会在适当的时候， 将这个操作记录更新到磁盘里面， 而这个更新往往是在系统比较空闲的时候做。 但是当redo log写满的时候，不能再执行新的更新了，只能先把部分更新先更新到磁盘，并擦除这部分redo log后才能继续更新。</p>
<p><strong>InnoDB的redo log是固定大小的</strong>， 比如可以配置为一组4个文件， 每个文件的大小是1GB， 那么redo log总共就可以记录4GB的操作。从头开始写， 写到末尾就又回到开头循环写。</p>
<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20221101143420.png" style="width: 50%;" />

<p>write pos是当前记录的位置， 一边写一边后移， 写到第3号文件末尾后就回到0号文件开头。checkpoint是当前要擦除的位置， 也是往后推移并且循环的， 擦除记录前要把记录更新到数据文件。  </p>
<p>write pos和checkpoint之间的是redo log上还空着的部分， 可以用来记录新的操作。 如果write pos追上checkpoint， 表示redo log满了， 这时候不能再执行新的更新， 得停下来先擦掉一些记录， 把checkpoint推进一下。  </p>
<p><strong>有了redo log， InnoDB就可以保证即使数据库发生异常重启， 之前提交的记录都不会丢失， 这个能力称为crash-safe。</strong>  </p>
<p><strong>innodb_flush_log_at_trx_commit</strong>这个参数设置成1的时候，表示每次事务的redo log都直接持久化到磁盘，建议设成1。</p>
<h4 id="redo-log的写入机制"><a href="#redo-log的写入机制" class="headerlink" title="redo log的写入机制"></a>redo log的写入机制</h4><p>事务在执行过程中， 生成的redo log是要先写到redo log buffer的。  </p>
<p>redo log buffer里面的内容， 不是每次生成后都要直接持久化到磁盘。</p>
<p>如果事务执行期间MySQL发生异常重启， 那这部分日志就丢了。 由于事务并没有提交， 所以这时日志丢了也不会有损失。</p>
<p>事务还没提交的时候， redo log buffer中的部分日志也有可能被持久化到磁盘</p>
<h5 id="redolog的三种状态"><a href="#redolog的三种状态" class="headerlink" title="redolog的三种状态"></a>redolog的三种状态</h5><img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20221118163550.png" style="width: 40%;" />

<p>这三种状态分别是：</p>
<ol>
<li>存在redo log buffer中， 物理上是在MySQL进程内存中， 就是图中的红色部分；</li>
<li>写到磁盘(write)， 但是没有持久化（fsync)， 物理上是在文件系统的page cache里面， 也就是图中的黄色部分；</li>
<li>持久化到磁盘， 对应的是hard disk， 也就是图中的绿色部分。</li>
</ol>
<p>日志写到redo log buffer是很快的， wirte到page cache也差不多， 但是持久化到磁盘的速度就慢多了。<br>为了控制redo log的写入策略， InnoDB提供了innodb_flush_log_at_trx_commit参数， 它有三种可能取值：</p>
<ol>
<li>设置为0的时候， 表示每次事务提交时都只是把redo log留在redo log buffer中;</li>
<li>设置为1的时候， 表示每次事务提交时都将redo log直接持久化到磁盘；（将redo log buffer里的日志全部持久化到磁盘）</li>
<li>设置为2的时候， 表示每次事务提交时都只是把redo log写到page cache。InnoDB有一个后台线程， 每隔1秒， 就会把redo log buffer中的日志， 调用write写到文件系统的page cache， 然后调用fsync持久化到磁盘。</li>
</ol>
<p><strong>注意， 事务执行中间过程的redo log也是直接写在redo log buffer中的， 这些redo log也会被后台线程一起持久化到磁盘。 也就是说， 一个没有提交的事务的redo log， 也是可能已经持久化到磁盘的 。</strong></p>
<p>实际上， 除了后台线程每秒一次的轮询操作外， 还有两种场景会让一个没有提交的事务的redo log写入到磁盘中 ：</p>
<ol>
<li>一种是， redo log buffer占用的空间即将达到 innodb_log_buffer_size一半的时候，后台线程会主动写盘。 注意， 由于这个事务并没有提交， 所以这个写盘动作只是write， 而没有调用fsync， 也就是只留在了文件系统的page cache。</li>
<li>另一种是， 并行的事务提交的时候， 顺带将这个事务的redo log buffer持久化到磁盘。 假设一个事务A执行到一半， 已经写了一些redo log到buffer中， 这时候有另外一个线程的事务B提交， 如果innodb_flush_log_at_trx_commit设置的是1， 那么按照这个参数的逻辑， 事务B要把redo log buffer里的日志全部持久化到磁盘。 这时候， 就会带上事务A在redo log buffer里的日志一起持久化到磁盘。</li>
</ol>
<p>如果把innodb_flush_log_at_trx_commit设置成1， 那么redo log在prepare阶段就要持久化一次，因为有一个崩溃恢复逻辑是要依赖于prepare 的redo log， 再加上binlog来恢复的。   </p>
<p>每秒一次后台轮询刷盘， 再加上崩溃恢复这个逻辑， InnoDB就认为redo log在commit的时候就不需要fsync了， 只会write到文件系统的page cache中就够了。  </p>
<p><strong>通常我们说MySQL的“双1”配置， 指的就是sync_binlog和innodb_flush_log_at_trx_commit都设置成 1。 也就是说， 一个事务完整提交前， 需要等待两次刷盘， 一次是redo log（prepare 阶段） ， 一次是binlog。</strong>  </p>
<h5 id="组提交（group-commit）-机制"><a href="#组提交（group-commit）-机制" class="headerlink" title="组提交（group commit） 机制"></a>组提交（group commit） 机制</h5><p>LSN（log sequence number  ）是单调递增的， 用来对应redo log的一个个写入点。 每次写入长度为length的redo log， LSN的值就会加上length。</p>
<p>LSN也会写到InnoDB的数据页中， 来确保数据页不会被多次执行重复的redo log。  </p>
<p>如图所示， 是三个并发事务(trx1, trx2, trx3)在prepare 阶段， 都写完redo log buffer， 持久化到磁盘的过程， 对应的LSN分别是50、 120 和160。</p>
<p><img src="C:/Users/ZhouHJ/AppData/Roaming/Typora/typora-user-images/image-20221119135129305.png" alt="image-20221119135129305"></p>
<p>从图中可以看到，</p>
<ol>
<li>trx1是第一个到达的， 会被选为这组的 leader；</li>
<li>等trx1要开始写盘的时候， 这个组里面已经有了三个事务， 这时候LSN也变成了160；</li>
<li>trx1去写盘的时候， 带的就是LSN&#x3D;160， 因此等trx1返回时， 所有LSN小于等于160的redolog， 都已经被持久化到磁盘；</li>
<li>这时候trx2和trx3就可以直接返回了</li>
</ol>
<p>所以， 一次组提交里面， 组员越多， 节约磁盘IOPS的效果越好。 但如果只有单线程压测， 那就只能老老实实地一个事务对应一次持久化操作了。在并发更新场景下， 第一个事务写完redo log buffer以后， 接下来这个fsync越晚调用， 组员可能越多， 节约IOPS的效果就越好。为了让一次fsync带的组员更多， MySQL有一个很有趣的优化： 拖时间。  </p>
<p>原先的两阶段提交：</p>
<p><img src="C:/Users/ZhouHJ/AppData/Roaming/Typora/typora-user-images/image-20221119140015587.png" alt="image-20221119140015587"></p>
<p>但实际上， 写binlog是分成两步的：</p>
<ol>
<li>先把binlog从binlog cache中写到磁盘上的binlog文件；</li>
<li>调用fsync持久化。MySQL为了让组提交的效果更好， 把redo log做fsync的时间拖到了步骤1之后。 也就是说， 上面<br>的图变成了这样：</li>
</ol>
<p><img src="C:/Users/ZhouHJ/AppData/Roaming/Typora/typora-user-images/image-20221119140612229.png" alt="image-20221119140612229"></p>
<p>这么一来， binlog也可以组提交了。 在执行图中第4步把binlog fsync到磁盘时， 如果有多个事务的binlog已经写完了， 也是一起持久化的， 这样也可以减少IOPS的消耗。<br>不过通常情况下第3步执行得会很快， 所以binlog的write和fsync间的间隔时间短， 导致能集合到一起持久化的binlog比较少， 因binlog的组提交的效果通常不如redo log的效果那么好。<br>如果你想提升binlog组提交的效果， 可以通过设置 binlog_group_commit_sync_delay和binlog_group_commit_sync_no_delay_count来实现。</p>
<ol>
<li>binlog_group_commit_sync_delay参数， 表示延迟多少微秒后才调用fsync;</li>
<li>binlog_group_commit_sync_no_delay_count参数， 表示累积多少次以后才调用fsync。</li>
</ol>
<p>这两个条件是或的关系， 也就是说只要有一个满足条件就会调用fsync。<br>所以， 当binlog_group_commit_sync_delay设置为0的时候， binlog_group_commit_sync_no_delay_count也无效了。  </p>
<p><strong>WAL机制主要得益于两个方面：</strong></p>
<ol>
<li>redo log 和 binlog都是顺序写， 磁盘的顺序写比随机写速度要快；</li>
<li>组提交机制， 可以大幅度降低磁盘的IOPS消耗。</li>
</ol>
<h3 id="binlog-归档日志"><a href="#binlog-归档日志" class="headerlink" title="binlog(归档日志)"></a>binlog(归档日志)</h3><p>binlog是Server层的日志，所有引擎都能使用。binlog是逻辑日志， 记录的是这个语句的原始逻辑， 比如“给ID&#x3D;2这一行的c字段加1”。binlog是可以追加写入的。 “追加写”是指binlog文件写到一定大小后会切换到下一个， 并不会覆盖以前的日志。</p>
<p><strong>sync_binlog</strong>这个参数设置成1的时候， 表示每次事务的binlog都持久化到磁盘，建议设成1。</p>
<h4 id="binlog的三种格式对比"><a href="#binlog的三种格式对比" class="headerlink" title="binlog的三种格式对比"></a>binlog的三种格式对比</h4><p>查看binlog格式</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">SHOW VARIABLES LIKE &#x27;binlog_format&#x27;;</span><br></pre></td></tr></table></figure>

<h5 id="statement"><a href="#statement" class="headerlink" title="statement"></a>statement</h5><p>记录的是sql原文</p>
<p>如果sql里有带now()，这种函数的，mysql会在写binlog的时候，先将这个时间记录下来。以此保证传输到备库的时候，不会因为主从延迟，而出现主库和从库该字段不一致的情况。</p>
<h5 id="row"><a href="#row" class="headerlink" title="row"></a>row</h5><p>记录的是行的内容或关键内容</p>
<h5 id="mixed"><a href="#mixed" class="headerlink" title="mixed"></a>mixed</h5><p>是上面两种方式的结合。</p>
<ul>
<li>有些statement格式的binlog可能会导致主备不一致， 所以要使用row格式  </li>
<li>但row格式的缺点是， 很占空间。 比如你用一个delete语句删掉10万行数据， 用statement的话就是一个SQL语句被记录到binlog中， 占用几十个字节的空间。 但如果用row格式的binlog，就要把这10万条记录都写到binlog中。</li>
</ul>
<p><strong>MySQL就取了个折中方案， 也就是有了mixed格式的binlog。 mixed格式的意思是， MySQL自己会判断这条SQL语句是否可能引起主备不一致， 如果有可能， 就用row格式，否则就用statement格式</strong>  </p>
<p><strong>用binlog来恢复数据的标准做法是， 用 mysqlbinlog工具解析出来， 然后把解析结果整个发给MySQL执行</strong>  </p>
<h4 id="binlog写入机制"><a href="#binlog写入机制" class="headerlink" title="binlog写入机制"></a>binlog写入机制</h4><p>事务执行过程中， 先把日志写到binlog cache， 事务提交的时候， 再把binlog cache写到binlog文件中。  </p>
<p>一个事务的binlog是不能被拆开的， 因此不论这个事务多大， 也要确保一次性写入。 这就涉及到了binlog cache的保存问题。  </p>
<p><strong>系统给binlog cache分配了一片内存， 每个线程一个， 参数 binlog_cache_size用于控制单个线程内binlog cache所占内存的大小。 如果超过了这个参数规定的大小， 就要暂存到磁盘。</strong></p>
<p>事务提交的时候， 执行器把binlog cache里的完整事务写入到binlog中， 并清空binlog cache。  </p>
<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20221118162542.png" style="width: 50%;" />

<p>每个线程有自己binlog cache， 但是共用同一份binlog文件。</p>
<ul>
<li>图中的write， 指的就是指把日志写入到文件系统的page cache， 并没有把数据持久化到磁盘， 所以速度比较快。</li>
<li>图中的fsync， 才是将数据持久化到磁盘的操作。 一般情况下， 我们认为fsync才占磁盘的IOPS</li>
</ul>
<p><strong>write 和fsync的时机， 是由参数sync_binlog控制的：</strong></p>
<ol>
<li><strong>sync_binlog&#x3D;0的时候， 表示每次提交事务都只write， 不fsync；</strong></li>
<li><strong>sync_binlog&#x3D;1的时候， 表示每次提交事务都会执行fsync；</strong></li>
<li><strong>sync_binlog&#x3D;N(N&gt;1)的时候， 表示每次提交事务都write， 但累积N个事务后才fsync。</strong></li>
</ol>
<p>因此， <strong>在出现IO瓶颈的场景里， 将sync_binlog设置成一个比较大的值， 可以提升性能。</strong> 在实际的业务场景中， 考虑到丢失日志量的可控性， 一般不建议将这个参数设成0， 比较常见的是将其设置为100~1000中的某个数值。但是， 将sync_binlog设置为N， 对应的风险是： 如果主机发生异常重启， 会丢失最近N个事务的binlog日志。  </p>
<h3 id="InnoDB引擎实现update流程"><a href="#InnoDB引擎实现update流程" class="headerlink" title="InnoDB引擎实现update流程"></a>InnoDB引擎实现update流程</h3><p>比如SQL：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">update</span> T <span class="keyword">set</span> C<span class="operator">=</span>C<span class="operator">+</span><span class="number">1</span> <span class="keyword">where</span> ID<span class="operator">=</span><span class="number">2</span>;</span><br></pre></td></tr></table></figure>

<ol>
<li>执行器先找引擎取ID&#x3D;2这一行。 ID是主键， 引擎直接用树搜索找到这一行。 如果ID&#x3D;2这一行<strong>所在的数据页</strong>本来就在内存中， 就直接返回给执行器； 否则， 需要先从磁盘读入内存， 然后再返回。</li>
<li>执行器拿到引擎给的行数据， 把这个值加上1， 比如原来是N， 现在就是N+1， 得到新的一行数据， 再调用引擎接口写入这行新数据。</li>
<li><strong>引擎将这行新数据更新到内存中， 同时将这个更新操作记录到redo log里面， 此时redo log处于prepare状态。 然后告知执行器执行完成了， 随时可以提交事务。</strong></li>
<li>执行器生成这个操作的binlog， 并把binlog写入磁盘。</li>
<li>执行器调用引擎的提交事务接口， 引擎把刚刚写入的redo log改成提交（commit） 状态， 更新完成。</li>
</ol>
<p>update执行流程图，图中<strong>浅色框表示是在InnoDB内部执行</strong>的， <strong>深色框表示是在执行器中执行</strong>的  </p>
<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20221101154221.png" style="width: 30%;" />

<h3 id="两阶段提交"><a href="#两阶段提交" class="headerlink" title="两阶段提交"></a>两阶段提交</h3><p>为什么必须有“两阶段提交”呢？ 这是为了让两份日志之间的逻辑一致。</p>
<ol>
<li>如果先写redo log，后写binlog。在写完redo log之后，MySQL crash了，那么在binlog里将会缺少这条记录。在程序恢复之后，会恢复redo log里的内容，而这个行为会导致MySQL实际以及执行了这条更新语句。后续如果采用binlog做备份恢复或者从库读取主库的binlog的时候，会缺失了这个更新。</li>
<li>如果先写binlog，后先redo log，则会出现和上面相反的情况，当前数据库缺失这个更新，用binlog做备份恢复或者从库读取主库的binlog的时候，会存在这个更新</li>
</ol>
<h3 id="奔溃恢复"><a href="#奔溃恢复" class="headerlink" title="奔溃恢复"></a>奔溃恢复</h3><ol>
<li>如果redo log里面的事务是完整的， 也就是已经有了commit标识， 则直接提交；</li>
<li>如果redo log里面的事务只有完整的prepare， 则判断对应的事务binlog是否存在并完整：<br>a. 如果是， 则提交事务；<br>b. 否则， 回滚事务。</li>
</ol>
<h3 id="MySQL怎么知道binlog是完整的"><a href="#MySQL怎么知道binlog是完整的" class="headerlink" title="MySQL怎么知道binlog是完整的"></a>MySQL怎么知道binlog是完整的</h3><p> 一个事务的binlog是有完整格式的：</p>
<ul>
<li>statement格式的binlog， 最后会有COMMIT；</li>
<li>row格式的binlog， 最后会有一个XID event。</li>
</ul>
<p>另外， 在MySQL 5.6.2版本以后， 还引入了binlog-checksum参数， 用来验证binlog内容的正确性。 对于binlog日志由于磁盘原因， 可能会在日志中间出错的情况， MySQL可以通过校验checksum的结果来发现。 所以， MySQL还是有办法验证事务binlog的完整性的  。</p>
<h3 id="redo-log-和-binlog是怎么关联起来的"><a href="#redo-log-和-binlog是怎么关联起来的" class="headerlink" title="redo log 和 binlog是怎么关联起来的"></a>redo log 和 binlog是怎么关联起来的</h3><p>它们有一个共同的数据字段， 叫XID。 崩溃恢复的时候， 会按顺序扫描redo log：</p>
<ul>
<li>如果碰到既有prepare、 又有commit的redo log， 就直接提交；</li>
<li>如果碰到只有parepare、 而没有commit的redo log， 就拿着XID去binlog找对应的事务。</li>
</ul>
<h3 id="处于prepare阶段的redo-log加上完整binlog，-重启就能恢复，-MySQL为什么要这么设计"><a href="#处于prepare阶段的redo-log加上完整binlog，-重启就能恢复，-MySQL为什么要这么设计" class="headerlink" title="处于prepare阶段的redo log加上完整binlog， 重启就能恢复， MySQL为什么要这么设计"></a>处于prepare阶段的redo log加上完整binlog， 重启就能恢复， MySQL为什么要这么设计</h3><p>由于binlog里已经完整记录了这次事务，之后就会被从库（或者用这个binlog恢复出来的库）使用，因此在主库上也要提交这个事务，以保证数据的一致性。</p>
<h3 id="如果这样的话，-为什么还要两阶段提交呢？-干脆先redo-log写完，-再写binlog。-崩溃恢复的时候，-必须得两个日志都完整才可以。-是不是一样的逻辑？"><a href="#如果这样的话，-为什么还要两阶段提交呢？-干脆先redo-log写完，-再写binlog。-崩溃恢复的时候，-必须得两个日志都完整才可以。-是不是一样的逻辑？" class="headerlink" title="如果这样的话， 为什么还要两阶段提交呢？ 干脆先redo log写完， 再写binlog。 崩溃恢复的时候， 必须得两个日志都完整才可以。 是不是一样的逻辑？"></a>如果这样的话， 为什么还要两阶段提交呢？ 干脆先redo log写完， 再写binlog。 崩溃恢复的时候， 必须得两个日志都完整才可以。 是不是一样的逻辑？</h3><p>其实， 两阶段提交是经典的分布式系统问题， 并不是MySQL独有的。  </p>
<p>如果必须要举一个场景， 来说明这么做的必要性的话， 那就是事务的持久性问题。对于InnoDB引擎来说， 如果redo log提交完成了， 事务就不能回滚（如果这还允许回滚， 就可能覆盖掉别的事务的更新） 。 而如果redo log直接提交， 然后binlog写入的时候失败， InnoDB又回滚不了， 数据和binlog日志又不一致了。<br>两阶段提交就是为了给所有人一个机会， 当每个人都说“我ok”的时候， 再一起提交 。</p>
<h3 id="redo-log一般设置多大？"><a href="#redo-log一般设置多大？" class="headerlink" title="redo log一般设置多大？"></a>redo log一般设置多大？</h3><p>redo log太小的话， 会导致很快就被写满， 然后不得不强行刷redo log， 这样WAL机制的能力就发挥不出来了。<br>所以， 如果是现在常见的几个TB的磁盘的话， 就不要太小气了， 直接将redo log设置为4个文件、 每个文件1GB吧。  </p>
<h3 id="正常运行中的实例，-数据写入后的最终落盘，-是从redo-log更新过来的还是从buffer-pool更新过来的呢？"><a href="#正常运行中的实例，-数据写入后的最终落盘，-是从redo-log更新过来的还是从buffer-pool更新过来的呢？" class="headerlink" title="正常运行中的实例， 数据写入后的最终落盘， 是从redo log更新过来的还是从buffer pool更新过来的呢？"></a>正常运行中的实例， 数据写入后的最终落盘， 是从redo log更新过来的还是从buffer pool更新过来的呢？</h3><p>实际上， redo log并没有记录数据页的完整数据， 所以它并没有能力自己去更新磁盘数据页， 也就不存在“数据最终落盘， 是由redo log更新过去”的情况。</p>
<ol>
<li>如果是正常运行的实例的话， 数据页被修改以后， 跟磁盘的数据页不一致， 称为脏页。 最终数据落盘， 就是把内存中的数据页写盘。 这个过程， 甚至与redo log毫无关系。</li>
<li>在崩溃恢复场景中， InnoDB如果判断到一个数据页可能在崩溃恢复的时候丢失了更新， 就会将它读到内存， 然后让redo log更新内存内容。 更新完成后， 内存页变成脏页， 就回到了第一种情况的状态。</li>
</ol>
<h3 id="redo-log-buffer是什么？-是先修改内存，-还是先写redo-log文件？"><a href="#redo-log-buffer是什么？-是先修改内存，-还是先写redo-log文件？" class="headerlink" title="redo log buffer是什么？ 是先修改内存， 还是先写redo log文件？"></a>redo log buffer是什么？ 是先修改内存， 还是先写redo log文件？</h3><p>在一个事务的更新过程中， 日志是要写多次的。 比如下面这个事务：  </p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">begin</span>;</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t1 ...</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t2 ...</span><br><span class="line"><span class="keyword">commit</span>;</span><br></pre></td></tr></table></figure>

<p>这个事务要往两个表中插入记录， 插入数据的过程中， 生成的日志都得先保存起来， 但又不能在还没commit的时候就直接写到redo log文件里。所以， redo log buffer就是一块内存， 用来先存redo日志的。 也就是说， 在执行第一个insert的时候， 数据的内存被修改了， redo log buffer也写入了日志。但是， 真正把日志写到redo log文件（文件名是 ib_logfile+数字） ， 是在执行commit语句的时候做的。<br>（这里说的是事务执行过程中不会“主动去刷盘”， 以减少不必要的IO消耗。 但是可能会出现“被动写入磁盘”， 比如内存不够、 其他事务提交等情况。   </p>
<p>单独执行一个更新语句的时候， InnoDB会自己启动一个事务， 在语句执行完成的时候提交。 过<br>程跟上面是一样的， 只不过是“压缩”到了一个语句里面完成。  </p>
<h3 id="如果你的MySQL现在出现了性能瓶颈，-而且瓶颈在IO上，-可以通过哪些方法来提升性能呢？"><a href="#如果你的MySQL现在出现了性能瓶颈，-而且瓶颈在IO上，-可以通过哪些方法来提升性能呢？" class="headerlink" title="如果你的MySQL现在出现了性能瓶颈， 而且瓶颈在IO上， 可以通过哪些方法来提升性能呢？"></a>如果你的MySQL现在出现了性能瓶颈， 而且瓶颈在IO上， 可以通过哪些方法来提升性能呢？</h3><p>针对这个问题， 可以考虑以下三种方法：</p>
<ol>
<li>设置 binlog_group_commit_sync_delay和 binlog_group_commit_sync_no_delay_count参数， 减少binlog的写盘次数。 这个方法是基于“额外的故意等待”来实现的， 因此可能会增加语句的响应时间， 但没有丢失数据的风险。</li>
<li>将sync_binlog 设置为大于1的值（比较常见是100~1000） 。 这样做的风险是， 主机掉电时会丢binlog日志。</li>
<li>将innodb_flush_log_at_trx_commit设置为2。 这样做的风险是， 主机掉电的时候会丢数据。我不建议你把innodb_flush_log_at_trx_commit 设置成0。 因为把这个参数设置成0， 表示redolog只保存在内存中， 这样的话MySQL本身异常重启也会丢数据， 风险太大。 而redo log写到文件系统的page cache的速度也是很快的， 所以将这个参数设置成2跟设置成0其实性能差不多，但这样做MySQL异常重启时就不会丢数据了， 相比之下风险会更小。</li>
</ol>
<h2 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h2><p>简单来说， 事务就是要保证一组数据库操作， 要么全部成功， 要么全部失败。  </p>
<p>在MySQL中， 事务支持是在引擎层实现的。MyISAM不支持事务， InnoDB支持事务。  </p>
<h3 id="四大特性"><a href="#四大特性" class="headerlink" title="四大特性"></a>四大特性</h3><p>ACID（Atomicity、 Consistency、 Isolation、 Durability， 即原子性、 一致性、 隔离性、 持久性）</p>
<ul>
<li>Atomicity（原子性）：一个事务（transaction）中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被恢复（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。</li>
<li>Consistency（一致性）：在事务开始之前和事务结束以后，数据库的数据完整性没有被破坏。比如A给B转账100元，要么A的账户少掉100，B的账户多100，要么两个人的账户都没有变化。不可能A的账户少了100，B的账户没有增加，或者B的账户增加了100，A的账户没有减少，这样就不一致了。</li>
<li>Isolation（隔离性）：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括读未提交（Read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（Serializable）。</li>
<li>Durability（持久性）：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。</li>
</ul>
<h3 id="隔离性与隔离级别"><a href="#隔离性与隔离级别" class="headerlink" title="隔离性与隔离级别"></a>隔离性与隔离级别</h3><p><strong>当数据库上有多个事务同时执行的时候， 就可能出现脏读（dirtyread） 、 不可重复读（nonrepeatable read） 、 幻读（ phantom read） 的问题，</strong> 为了解决这些问题， 就有了“隔离级别”的概念。</p>
<ul>
<li><p><strong>脏读</strong>：脏读就是指当一个事务正在访问数据，并且对数据进行了修改，而这种修改还没有提交到数据库中，这时，另外一个事务也访问这个数据，然后使用了这个数据。<strong>脏读强调的是第二个事务读到的不够新</strong>。</p>
</li>
<li><p><strong>不可重复读</strong>：是指在一个事务内，多次读同一数据。在这个事务还没有结束时，另外一个事务也访问该同一数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改，那么第一个事务两次读到的的数据可能是不一样的。这样就发生了在一个事务内两次读到的数据是不一样的，因此称为是不可重复读。<strong>不可重复读的重点是修改 ，</strong>同一事务，两次读取到的数据不一样。</p>
</li>
<li><p><strong>幻读</strong>：是指当事务不是独立执行时发生的一种现象，例如第一个事务对一个表中的数据进行了修改，这种修改涉及到表中的全部数据行。同时，第二个事务也修改这个表中的数据，这种修改是向表中插入一行新数据。那么，以后就会发生操作第一个事务的用户发现表中还有没有修改的数据行，就好象发生了幻觉一样。<strong>幻读的重点在于新增或者删除</strong>，同样的条件，第 1 次和第 2 次读出来的记录数不一样。</p>
</li>
</ul>
<p>SQL标准的事务隔离级别包括： 读未提交（ read uncommitted） 、读提交（read committed） 、 可重复读（ repeatable read） 和串行化（ serializable ）。</p>
<ul>
<li><strong>读未提交：</strong> 一个事务还没提交时， 它做的变更就能被别的事务看到。</li>
<li><strong>读提交：</strong> 一个事务提交之后， 它做的变更才会被其他事务看到。</li>
<li><strong>可重复读：</strong> 一个事务执行过程中看到的数据， 总是跟这个事务在启动时看到的数据是一致的。 当然在可重复读隔离级别下， 未提交变更对其他事务也是不可见的。</li>
<li><strong>串行化：</strong> 顾名思义是对于同一行记录， “写”会加“写锁”， “读”会加“读锁”。 当出现读写锁冲突的时候， 后访问的事务必须等前一个事务执行完成， 才能继续执行。</li>
</ul>
<p>数据库里面会创建一个视图， 访问的时候以视图的逻辑结果为准。 在“可重复读”隔离级别下， 这个视图是在事务启动时创建的， 整个事务存在期间都用这个视图。 在“读提交”隔离级别下， 这个视图是在每个SQL语句开始执行的时候创建的。 这里需要注意的是， “读未提交”隔离级别下直接返回记录上的最新值， 没有视图概念； 而“串行化”隔离级别下直接用加锁的方式来避免并行访问。</p>
<p>Oracle数据库的默认隔离级别是“读提交”，  MySQL数据库的默认隔离级别是“可重复读”。</p>
<h3 id="事务隔离的实现"><a href="#事务隔离的实现" class="headerlink" title="事务隔离的实现"></a>事务隔离的实现</h3><p>以下内容基于”可重复读“。</p>
<p>在MySQL中， 实际上每条记录在更新的时候都会同时记录一条回滚操作。 每条记录上的最新值， 通过回滚操作， 都可以得到前一个状态的值。假设一个值从1被按顺序改成了2、 3、 4， 在回滚日志（undo log）里面就会有类似下面的记录。  </p>
<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20221101164800.png" style="width: 50%;" />

<p>当前值是4， 但是在查询这条记录的时候， 不同时刻启动的事务会有不同的read-view。 如图中看到的， 在视图A、 B、 C里面， 这一个记录的值分别是1、 2、 4， 同一条记录在系统中可以存在多个版本， 就是数据库的<strong>多版本并发控制（MVCC）</strong> 。 对于read-view A， 要得到1， 就必须将当前值依次执行图中所有的回滚操作得到。 即使现在有另外一个事务正在将4改成5， 这个事务跟read-view A、 B、 C对应的事务是不会冲突的。  </p>
<p>回滚日志在不需要的时候才删除。也就是说， 系统会判断， 当没有事务再需要用到这些回滚日志时， 回滚日志会被删除。什么时候才不需要了呢？ 就是当系统里没有比这个回滚日志更早的read-view的时候 。</p>
<p>因此要尽量避免长事务，长事务意味着系统里面会存在很老的事务视图。 由于这些事务随时可能访问数据库里面的任何数据， 所以这个事务提交之前， 数据库里面它可能用到的回滚记录都必须保留， 这就会导致大量占用存储空间。</p>
<p>在MySQL 5.5及以前的版本， 回滚日志是跟数据字典一起放在ibdata文件里的， 即使长事务最终提交， 回滚段被清理， 文件也不会变小。 除了对回滚段的影响， 长事务还占用锁资源， 也可能拖垮整个库。</p>
<h3 id="事务的启动方式"><a href="#事务的启动方式" class="headerlink" title="事务的启动方式"></a>事务的启动方式</h3><p>MySQL的事务启动方式有以下几种：</p>
<ol>
<li><strong>显式启动事务语句</strong>， <strong>begin</strong> 或 <strong>start transaction</strong>。 配套的提交语句是<strong>commit</strong>， 回滚语句是<strong>rollback</strong>（<strong>begin&#x2F;start transaction 命令并不是一个事务的起点， 在执行到它们之后的第一个操作InnoDB表的语句， 事务才真正启动。 如果你想要马上启动一个事务， 可以使用start transaction with consistent snapshot 这个命令</strong>）。  </li>
<li><strong>set autocommit&#x3D;0</strong>， 这个命令会将这个线程的自动提交关掉。 意味着如果你只执行一个select语句， 这个事务就启动了， 而且并不会自动提交。 这个事务持续存在直到你主动执行commit 或 rollback 语句， 或者断开连接。</li>
</ol>
<p>在autocommit为1的情况下， 用begin显式启动的事务， 如果执行<strong>commit则提交事务</strong>。 如果执行<strong>commit work and chain</strong>， <strong>则是提交事务并自动启动下一个事务</strong>， 这样也省去了再次执行begin语句的开销。 同时带来的好处是从程序开发的角度明确地知道每个语句是否处于事务中。  </p>
<p>可以在information_schema库的innodb_trx这个表中查询长事务， 比如下面这个语句， 用于查找持续时间超过60s的事务  </p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> information_schema.innodb_trx <span class="keyword">where</span> TIME_TO_SEC(timediff(now(),trx_started))<span class="operator">&gt;</span><span class="number">60</span>;</span><br></pre></td></tr></table></figure>

<h3 id="“快照”在MVCC里是怎么工作的"><a href="#“快照”在MVCC里是怎么工作的" class="headerlink" title="“快照”在MVCC里是怎么工作的"></a>“快照”在MVCC里是怎么工作的</h3><p>在MySQL里， 有两个“视图”的概念：<strong>一个是view</strong>。 它是一个用查询语句定义的虚拟表， 在调用的时候执行查询语句并生成结果。<br>创建视图的语法是create view …， 而它的查询方法与表一样。<strong>另一个是InnoDB在实现MVCC时用到的一致性读视图， 即consistent read view</strong>， <strong>用于支持RC（Read Committed， 读提交） 和RR（ Repeatable Read， 可重复读） 隔离级别的实现</strong>。它没有物理结构， 作用是事务执行期间用来定义“我能看到什么数据”。  </p>
<p>在可重复读隔离级别下， 事务在启动的时候就“拍了个快照”。 注意， 这个快照是基于整库的。  </p>
<p><strong>InnoDB里面每个事务有一个唯一的事务ID， 叫作transaction id。 它是在事务开始的时候向InnoDB的事务系统申请的， 是按申请顺序严格递增的。而每行数据也都是有多个版本的。 每次事务更新数据的时候， 都会生成一个新的数据版本， 并且把transaction id赋值给这个数据版本的事务ID， 记为row trx_id。 同时， 旧的数据版本要保留，并且在新的数据版本中， 能够有信息可以直接拿到它。也就是说， 数据表中的一行记录， 其实可能有多个版本(row)， 每个版本有自己的row trx_id。</strong>  </p>
<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20221102164000.png" style="width: 60%;" />

<p>图中的三个虚线箭头， 就是undo log； 而V1、 V2、 V3并不是物理上真实存在的， 而是每次需要的时候根据当前版本和undo log计算出来的。 比如， 需要V2的时候， 就是通过V4依次执行U3、 U2算出来。  </p>
<p>按照可重复读的定义， 一个事务启动的时候， 能够看到所有已经提交的事务结果。 但是之后， 这个事务执行期间， 其他事务的更新对它不可见。</p>
<p><strong>InnoDB为每个事务构造了一个数组， 用来保存这个事务启动瞬间， 当前正在“活跃”的所有事务ID。 “活跃”指的就是， 启动了但还没提交。数组里面事务ID的最小值记为低水位， 当前系统里面已经创建过的事务ID的最大值加1记为高水位。这个视图数组和高水位， 就组成了当前事务的一致性视图（read-view） 。而数据版本的可见性规则， 就是基于数据的row trx_id和这个一致性视图的对比结果得到的。</strong>  </p>
<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20221102171747.png" style="width: 50%;" />

<p><strong>这样， 对于当前事务的启动瞬间来说， 一个数据版本的row trx_id， 有以下几种可能：</strong></p>
<ol>
<li><strong>如果落在绿色部分， 表示这个版本是已提交的事务或者是当前事务自己生成的， 这个数据是可见的；</strong></li>
<li><strong>如果落在红色部分， 表示这个版本是由将来启动的事务生成的， 是肯定不可见的；</strong></li>
<li><strong>如果落在黄色部分， 那就包括两种情况</strong><br><strong>a. 若 row trx_id在数组中， 表示这个版本是由还没提交的事务生成的， 不可见；</strong><br><strong>b. 若 row trx_id不在数组中， 表示这个版本是已经提交了的事务生成的， 可见。</strong></li>
</ol>
<p><strong>InnoDB利用了“所有数据都有多个版本”的这个特性， 实现了“秒级创建快照”的能力。</strong>  </p>
<p>一个数据版本， 对于一个事务视图来说， 除了自己的更新总是可见以外， 有三种情况：</p>
<ol>
<li>版本未提交， 不可见；</li>
<li>版本已提交， 但是是在视图创建后提交的， 不可见；</li>
<li>版本已提交， 而且是在视图创建前提交的， 可见。</li>
</ol>
<h3 id="当前读"><a href="#当前读" class="headerlink" title="当前读"></a>当前读</h3><p><strong>更新数据都是先读后写的， 而这个读， 只能读当前的值， 称为“当前读”（ current read）。 除了update语句外， select语句如果加锁， 也是当前读。</strong>  </p>
<p>比如在查询SQL加上<strong>lock in share mode 或 for update</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">select</span> k <span class="keyword">from</span> t <span class="keyword">where</span> id<span class="operator">=</span><span class="number">1</span> lock <span class="keyword">in</span> share mode; 读锁（S锁， 共享锁）</span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">select</span> k <span class="keyword">from</span> t <span class="keyword">where</span> id<span class="operator">=</span><span class="number">1</span> <span class="keyword">for</span> <span class="keyword">update</span>;写锁（X锁， 排他锁） </span><br></pre></td></tr></table></figure>

<p><strong>当前读， 必须要读最新版本， 而且必须加锁 ，如果有其他事务锁住了这行数据，则会阻塞等到其他事务释放这行数据的锁之后，才能读取到数据。</strong></p>
<p><strong>InnoDB的行数据有多个版本， 每个数据版本有自己的row trx_id， 每个事务或者语句有自己的一致性视图。 普通查询语句是一致性读， 一致性读会根据row trx_id和一致性视图确定数据版本的可见性。</strong></p>
<ul>
<li><strong>对于可重复读， 查询只承认在事务启动前就已经提交完成的数据；</strong></li>
<li><strong>对于读提交， 查询只承认在语句启动前就已经提交完成的数据；</strong></li>
<li><strong>而当前读， 总是读取已经提交完成的最新版本。</strong></li>
</ul>
<h3 id="事务的可重复读的能力是怎么实现的"><a href="#事务的可重复读的能力是怎么实现的" class="headerlink" title="事务的可重复读的能力是怎么实现的"></a>事务的可重复读的能力是怎么实现的</h3><p><strong>可重复读的核心就是一致性读（consistent read）</strong> <strong>；</strong> <strong>而事务更新数据的时候， 只能用当前读。</strong> <strong>如果当前的记录的行锁被其他事务占用的话， 就需要进入锁等待。</strong>而读提交的逻辑和可重复读的逻辑类似， 它们最主要的区别是：</p>
<ul>
<li>在可重复读隔离级别下， 只需要在事务开始的时候创建一致性视图， 之后事务里的其他查询都共用这个一致性视图；</li>
<li>在读提交隔离级别下， 每一个语句执行前都会重新算出一个新的视图。</li>
</ul>
<h2 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h2><p>索引的出现其实就是为了提高数据查询的效率， 就像书的目录一样。  </p>
<h3 id="索引的常见模型"><a href="#索引的常见模型" class="headerlink" title="索引的常见模型"></a>索引的常见模型</h3><p>常用的索引模型有三种，分别是哈希表、 有序数组和搜索树 。</p>
<h4 id="哈希表"><a href="#哈希表" class="headerlink" title="哈希表"></a>哈希表</h4><p>哈希表是一种以键-值（key-value） 存储数据的结构， 我们只要输入待查找的值即key， 就可以找到其对应的值即Value。 哈希的思路很简单， 把值放在数组里， 用一个哈希函数把key换算成一个确定的位置， 然后把value放在数组的这个位置。多个key值经过哈希函数的换算， 会出现同一个值的情况。 处理这种情况的一种方法是， 拉出一个链表（跟Hashmap的处理方式相同）。  </p>
<p>适合等值查询，不适合范围查询以及排序等操作</p>
<h4 id="有序数组"><a href="#有序数组" class="headerlink" title="有序数组"></a>有序数组</h4><p>有序数组是将数据按索引排序的形式有序存放在数组里。</p>
<p>查找数据的时候使用二分法，时间复杂度O(log(N))  。适合等值查询和范围查询。</p>
<p>但是， 在需要更新数据的时候就麻烦了， 你往中间插入一个记录就必须得挪动后面所有的记录， 成本太高 ，所以， 有序数组索引只适用于静态存储引擎，   </p>
<h4 id="搜索树"><a href="#搜索树" class="headerlink" title="搜索树"></a>搜索树</h4><p>二叉搜索树的特点是： 每个节点的左儿子小于父节点， 父节点又小于右儿子。  </p>
<p>查询和更新的时间复杂度都是O(log(N)) 。</p>
<p>二叉树是搜索效率最高的， 但是实际上大多数的数据库存储却并不使用二叉树。 其原因是， 索引不止存在内存中， 还要写到磁盘上。  </p>
<p>想象一下一棵100万节点的平衡二叉树， 树高20。 一次查询可能需要访问20个数据块。 在机械硬盘时代， 从磁盘随机读一个数据块需要10 ms左右的寻址时间。 也就是说， 对于一个100万行的表， 如果使用二叉树来存储， 单独访问一个行可能需要20个10 ms的时间， 这个查询可真够慢的。为了让一个查询尽量少地读磁盘， 就必须让查询过程访问尽量少的数据块。 那么， 我们就不应该使用二叉树， 而是要使用“N叉”树。 这里， “N叉”树中的“N”取决于数据块的大小。</p>
<p>以InnoDB的一个整数字段索引为例， 这个N差不多是1200。 这棵树高是4的时候， 就可以存1200的3次方个值， 这已经17亿了。 考虑到树根的数据块总是在内存中的， 一个10亿行的表上一个整数字段的索引， 查找一个值最多只需要访问3次磁盘。 其实， 树的第二层也有很大概率在内存中， 那么访问磁盘的平均次数就更少了 。</p>
<h3 id="InnoDB-的索引模型"><a href="#InnoDB-的索引模型" class="headerlink" title="InnoDB 的索引模型"></a>InnoDB 的索引模型</h3><p>在InnoDB中， 表都是根据主键顺序以索引的形式存放的， 这种存储方式的表称为索引组织表。  InnoDB使用了B+树索引模型， 所以数据都是存储在B+树中的。  <strong>每一个索引在InnoDB里面对应一棵B+树。</strong>  </p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">create</span> <span class="keyword">table</span> T(</span><br><span class="line">id <span class="type">int</span> <span class="keyword">primary</span> key,</span><br><span class="line">k <span class="type">int</span> <span class="keyword">not</span> <span class="keyword">null</span>,</span><br><span class="line">name <span class="type">varchar</span>(<span class="number">16</span>),</span><br><span class="line">index (k))engine<span class="operator">=</span>InnoDB;</span><br></pre></td></tr></table></figure>

<p>插入数据R1~R5 ，(100,1)、 (200,2)、 (300,3)、 (500,5)和(600,6) ，则索引组织结构如下：</p>
<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20221101192448.png" style="width: 50%;" />

<p>根据叶子节点的内容， 索引类型分为主键索引和非主键索引。</p>
<p>主键索引的叶子节点存的是整行数据。 在InnoDB里， 主键索引也被称为聚簇索引（clusteredindex） 。<br>非主键索引的叶子节点内容是主键的值。 在InnoDB里， 非主键索引也被称为二级索引（secondaryindex） 。  </p>
<p><strong>基于主键索引查询的话能够直接获取到数据行，而基于非主键索引查询的话需要先搜索索引树，获取对应的主键值，再通过主键值去主键索引上获取数据行，这个过程称为回表。因此基于非主键索引的查询需要多扫描一颗索引树，推荐尽量使用主键查询。</strong></p>
<h3 id="索引维护"><a href="#索引维护" class="headerlink" title="索引维护"></a>索引维护</h3><p>B+树为了维护索引有序性， 在插入新值的时候需要做必要的维护。 以上面这个图为例， 如果插入新的行ID值为700， 则只需要在R5的记录后面插入一个新记录。 如果新插入的ID值为400， 就相对麻烦了， 需要逻辑上挪动后面的数据， 空出位置。</p>
<p>而更糟的情况是， 如果R5所在的数据页已经满了， 根据B+树的算法， 这时候需要申请一个新的数据页， 然后挪动部分数据过去。 这个过程称为页分裂。 在这种情况下， 性能自然会受影响。除了性能外， 页分裂操作还影响数据页的利用率。 原本放在一个页的数据， 现在分到两个页中，整体空间利用率降低大约50%。</p>
<p>当然有分裂就有合并。 当相邻两个页由于删除了数据， 利用率很低之后， 会将数据页做合并。 合并的过程， 可以认为是分裂过程的逆过程。  </p>
<p><strong>推荐使用自增主键，这样每次新插入数据都是追加操作，而不会是插入操作，不涉及挪动其他记录，也不会触发叶子节点的分裂。并且使用自增主键，主键占用的空间较小，非主键索引存储的是主键的值，这样非主键索引的占用空间会减少，且一个数据页可以存储更多的内容。</strong></p>
<p>重建非主键索引</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> T <span class="keyword">drop</span> index k;</span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> T <span class="keyword">add</span> index(k);</span><br></pre></td></tr></table></figure>

<p>重建主键索引</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> Tengine<span class="operator">=</span>InnoDB;</span><br></pre></td></tr></table></figure>

<h3 id="覆盖索引"><a href="#覆盖索引" class="headerlink" title="覆盖索引"></a>覆盖索引</h3><p>在《InnoDB 的索引模型》笔记的表结构上，如果执行的语句是select ID from T where k &#x3D; 3;， 这时只需要查ID的值， 而ID的值已经在k索引树上了， 因此可以直接提供查询结果， 不需要回表。 也就是说， 在这个查询里面，索引k已经“覆盖了”查询需求， 称为覆盖索引。<br><strong>由于覆盖索引可以减少树的搜索次数， 显著提升查询性能， 所以使用覆盖索引是一个常用的性能优化手段。</strong>  </p>
<h3 id="最左前缀原则"><a href="#最左前缀原则" class="headerlink" title="最左前缀原则"></a>最左前缀原则</h3><p><strong>B+树这种索引结构， 可以利用索引的“最左前缀”， 来定位记录。</strong></p>
<p>只要满足最左前缀， 就可以利用索引来加速检索。 这个最左前缀可以是联合索引的最左N个字段， 也可以是字符串索引的最左M个字符。</p>
<p>在建立联合索引时，第一原则是， 如果通过调整顺序， 可以少维护一个索引， 那么这个顺序往往就是需要优先考虑采用的。  比如建立了索引(a,b)  ，就不需要再建立索引(a)。第二个原则就是空间，比如当需要同时维护(a,b)、(b) 这两个索引的时候，将占用空间比较大的字段放到联合索引里，小的字段建立单独的索引，这样可以降低空间占用。</p>
<h3 id="索引下推"><a href="#索引下推" class="headerlink" title="索引下推"></a>索引下推</h3><p>比如有一张表，有联合索引（name, age），现在有一个需求： 检索出表中“名字第一个字是张， 而且年龄是10岁的所有男孩” ，SQL：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> tuser <span class="keyword">where</span> name <span class="keyword">like</span> <span class="string">&#x27;张%&#x27;</span> <span class="keyword">and</span> age<span class="operator">=</span><span class="number">10</span> <span class="keyword">and</span> ismale<span class="operator">=</span><span class="number">1</span>;</span><br></pre></td></tr></table></figure>

<p>根据最左前缀原则，能用‘张’找到符合条件的第一条数据，比全表扫描好。</p>
<p>在MySQL 5.6之前， 只能从ID3开始一个个回表。 到主键索引上找出数据行， 再对比字段值。<br>而MySQL 5.6 引入的索引下推优化（indexcondition pushdown)， 可以在索引遍历过程中， 对索引中包含的字段先做判断， 直接过滤掉不满足条件的记录， 减少回表次数。  </p>
<p>比如这个例子中，MySQL5.6版本的就可以先在索引中判断age是否等于10，age等于10时，才回表去判断ismale是否为1。</p>
<h3 id="普通索引与唯一索引"><a href="#普通索引与唯一索引" class="headerlink" title="普通索引与唯一索引"></a>普通索引与唯一索引</h3><h4 id="查询过程"><a href="#查询过程" class="headerlink" title="查询过程"></a>查询过程</h4><ul>
<li>对于普通索引来说， 根据索引值查找到第一条记录后， 需要查找下一个记录， 直到碰到第一个不满足索引值的记录。</li>
<li>对于唯一索引来说， 由于索引定义了唯一性， 查找到第一个满足条件的记录后， 就会停止继续检索。</li>
</ul>
<p>性能基本没差异</p>
<p><strong>InnoDB的数据是按数据页为单位来读写的</strong>。 <strong>也就是说， 当需要读一条记录的时候，并不是将这个记录本身从磁盘读出来， 而是以页为单位， 将其整体读入内存。 在InnoDB中， 每个数据页的大小默认是16KB。</strong></p>
<p>因此当读取到满足的第一条记录时，该索引值所在的数据页已经在内存了，对于普通索引来说，要多做的那一次“查找和判断下一条记录”的操作， 就只需要一次指针寻找和一次计算。  而相同索引值在下一个数据页的概率小，计算平均性能消耗的时候忽略不计。</p>
<h4 id="更新过程"><a href="#更新过程" class="headerlink" title="更新过程"></a>更新过程</h4><h5 id="change-buffer"><a href="#change-buffer" class="headerlink" title="change buffer"></a>change buffer</h5><p>当需要更新一个数据页时， 如果数据页在内存中就直接更新， 而如果这个数据页还没有在内存中的话， 在不影响数据一致性的前提下， <strong>InooDB会将这些更新操作缓存在change buffer中， 这样就不需要从磁盘中读入这个数据页了。</strong> 在下次查询需要访问这个数据页的时候， 将数据页读入内存， 然后执行change buffer中与这个页有关的操作。 通过这种方式就能保证这个数据逻辑的正确性。  </p>
<p><strong>虽然名字叫作change buffer， 实际上它是可以持久化的数据。 也就是说， change buffer在内存中有拷贝， 也会被写入到磁盘上</strong>  </p>
<p>将change buffer中的操作应用到原数据页， 得到最新结果的过程称为merge。 除了访问这个数据页会触发merge外， 系统有后台线程会定期merge。 在数据库正常关闭（shutdown） 的过程中，也会执行merge操作。<br>显然， 如果能够将更新操作先记录在change buffer， 减少读磁盘， 语句的执行速度会得到明显的提升。 而且， 数据读入内存是需要占用buffer pool的， 所以这种方式还能够避免占用内存， 提高内存利用率 。</p>
<p>change buffer用的是buffer pool里的内存， 因此不能无限增大。 </p>
<p><strong>change buffer的大小， 可以通过参数innodb_change_buffer_max_size来动态设置</strong>。 这个参数设置为50的时候， 表示change buffer的大小最多只能占用buffer pool的50% 。</p>
<h5 id="什么条件下可以使用change-buffer"><a href="#什么条件下可以使用change-buffer" class="headerlink" title="什么条件下可以使用change buffer"></a><strong>什么条件下可以使用change buffer</strong></h5><ul>
<li>唯一索引的更新就不能使用change buffer</li>
<li>只有普通索引可以使用</li>
</ul>
<p>在更新过程中</p>
<ul>
<li><p>唯一索引</p>
<p>a）需要更新的数据页在内存中：找到索引值对应的位置，判断是否有数据违反唯一性约束，没有则插入</p>
<p>b）需要更新的数据页不在内存中：需要先将数据页从磁盘读入内存，再进行a操作</p>
</li>
<li><p>普通索引</p>
<p>a）需要更新的数据页在内存中：找到索引值对应的位置，直接插入索引</p>
<p>b）需要更新的数据页不在内存中：将更新记录在change buffer</p>
</li>
</ul>
<p>因此对于唯一索引来说，更新的过程会造成随机IO的访问，造成性能下降。 </p>
<h5 id="change-buffer的使用场景"><a href="#change-buffer的使用场景" class="headerlink" title="change buffer的使用场景"></a>change buffer的使用场景</h5><ul>
<li><p>适用普通索引，不适用唯一索引。</p>
</li>
<li><p>适用写多读少的场景，或者数据写了之后，不会马上需要读取相关数据页操作的。</p>
<p>因为merge的时候是真正进行数据更新的时刻， 而change buffer的主要目的就是将记录的变更动作缓存下来， 所以<strong>在一个数据页做merge之前， change buffer记录的变更越多（也就是这个页面上要更新的次数越多） ， 收益就越大。</strong><br>因此， 对于写多读少的业务来说， 页面在写完以后马上被访问到的概率比较小， 此时change buffer的使用效果最好。 这种业务模型常见的就是账单类、 日志类的系统。<br>反过来， 假设一个业务的更新模式是写入之后马上会做查询， 那么即使满足了条件， 将更新先记录在change buffer， 但之后由于马上要访问这个数据页， 会立即触发merge过程。 这样随机访问IO的次数不会减少， 反而增加了change buffer的维护代价。 所以， 对于这种业务模式来说， change buffer反而起到了副作用 。</p>
</li>
</ul>
<h5 id="change-buffer-和-redo-log"><a href="#change-buffer-和-redo-log" class="headerlink" title="change buffer 和 redo log"></a>change buffer 和 redo log</h5><p>假如有如下语句</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">insert</span> <span class="keyword">into</span> t(id,k) <span class="keyword">values</span>(id1,k1),(id2,k2);</span><br></pre></td></tr></table></figure>

<p>假设当前k索引树的状态， 查找到位置后， k1所在的数据页在内存(InnoDB buffer pool)中， k2所在的数据页不在内存中。 下图所示是带change buffer的更新状态图。  </p>
<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20221108094956.png" style="width: 80%;" />

<p>分析这条更新语句， 会发现它涉及了四个部分： 内存、 redo log（ib_log_fileX） 、 数据表空间（t.ibd） 、 系统表空间（ibdata1） 。<br>这条更新语句做了如下的操作（按照图中的数字顺序） ：</p>
<ol>
<li>Page 1在内存中， 直接更新内存；</li>
<li>Page 2没有在内存中， 就在内存的change buffer区域， 记录下“我要往Page 2插入一行”这个信息  </li>
<li>将上述两个动作记入redo log中（图中3和4） 。</li>
</ol>
<p>做完上面这些， 事务就可以完成了。 所以， 执行这条更新语句的成本很低， 就是写了两处内存， 然后写了一处磁盘（两次操作合在一起写了一次磁盘） ， 而且还是顺序写的。同时， 图中的两个虚线箭头， 是后台操作， 不影响更新的响应时间。  </p>
<p>这之后的读请求， 比如，现在要执行 select * from t where k in (k1, k2) ，如果读语句发生在更新语句后不久， 内存中的数据都还在， 那么此时的这两个读操作就与系统表空间（ibdata1） 和 redo log（ib_log_fileX） 无关了  </p>
<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20221108094935.png" style="width: 80%;" />

<ol>
<li>读Page 1的时候， 直接从内存返回。WAL之后如果读数据， 是不是一定要读盘， 是不是一定要从redo log里面把数据更新以后才可以返回？ 其实是不用的。看一下图中的这个状态， 虽然磁盘上还是之前的数据， 但是这里直接从内存返回结果， 结果是正确的。</li>
<li>要读Page 2的时候， 需要把Page 2从磁盘读入内存中， 然后应用change buffer里面的操作日志， 生成一个正确的版本并返回结果。可以看到， 直到需要读Page 2的时候， 这个数据页才会被读入内存。</li>
</ol>
<p><strong>简单地对比这两个机制在提升更新性能上的收益的话， redo log 主要节省的是随机写磁盘的IO消耗（ 转成顺序写） ， 而change buffer主要节省的则是随机读磁盘的IO消耗。</strong>  </p>
<h5 id="merge的执行流程"><a href="#merge的执行流程" class="headerlink" title="merge的执行流程"></a>merge的执行流程</h5><ol>
<li>从磁盘读入数据页到内存（老版本的数据页） ；</li>
<li>从change buffer里找出这个数据页的change buffer 记录(可能有多个） ， 依次应用， 得到新版数据页；</li>
<li>写redo log。 这个redo log包含了数据的变更和change buffer的变更</li>
</ol>
<h4 id="索引选择"><a href="#索引选择" class="headerlink" title="索引选择"></a>索引选择</h4><p>在业务保证数据唯一的情况下，推荐使用普通索引，因为在查询性能上，普通索引和唯一索引相差无几，在更新性能上，普通索引可以使用change buffer可以优化表的更新操作。</p>
<p>如果所有的更新后面， 都马上伴随着对这个记录的查询， 那么应该关闭change buffer。 而在其他情况下， change buffer都能提升更新性能。</p>
<h3 id="选错索引"><a href="#选错索引" class="headerlink" title="选错索引"></a>选错索引</h3><p>参数long_query_time(单位秒)表示慢查询的时间，超过这个设定值的都会被记录到慢查询日志里。</p>
<h4 id="优化器的逻辑"><a href="#优化器的逻辑" class="headerlink" title="优化器的逻辑"></a>优化器的逻辑</h4><p>优化器选择索引的目的， 是找到一个最优的执行方案， 并用最小的代价去执行语句 。</p>
<h5 id="扫描行数是怎么判断的"><a href="#扫描行数是怎么判断的" class="headerlink" title="扫描行数是怎么判断的"></a>扫描行数是怎么判断的</h5><p>一个索引上不同的值越多， 这个索引的区分度就越好。 而一个索引上不同的值的个数， 我们称之为“基数”（cardinality） 。 也就是说， 这个基数越大， 索引的区分度越好。</p>
<p>可以使用show index方法， 看到一个索引的基数，但是这个基数并不准确，只是MySQL采用采样统计法得到的估值</p>
<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20221108094912.png" style="width: 100%;" />

<p>采样统计的时候， InnoDB默认会选择N个数据页， 统计这些页面上的不同值， 得到一个平均值， 然后乘以这个索引的页面数， 就得到了这个索引的基数。而数据表是会持续更新的， 索引统计信息也不会固定不变。 所以， 当变更的数据行数超过1&#x2F;M的时候， 会自动触发重新做一次索引统计 。</p>
<p>在MySQL中， 有两种存储索引统计的方式， 可以通过设置参数innodb_stats_persistent的值来选择：</p>
<ul>
<li>设置为on的时候， 表示统计信息会持久化存储。 这时， 默认的N是20， M是10。</li>
<li>设置为off的时候， 表示统计信息只存储在内存中。 这时， 默认的N是8， M是16。</li>
</ul>
<p>由于是采样统计， 所以不管N是20还是8， 这个基数都是很容易不准的  </p>
<p><strong>优化器选择索引时，会根据预计扫描行数以及是否需要回表综合判断选择哪个索引更合适，但是由于预计扫描行数的误差，会偶尔造成优化器选错了索引。</strong></p>
<p><strong>可以使用analyze table table_name 命令， 用来重新统计索引信息。</strong>如果发现explain的结果预估的rows值跟实际情况差距比较大， 可以采用这个方法来处理 。</p>
<h4 id="索引选择异常和处理"><a href="#索引选择异常和处理" class="headerlink" title="索引选择异常和处理"></a>索引选择异常和处理</h4><ol>
<li>采用force index强行选择一个索引 ，语法select * from table_name force index(idx_name) where……</li>
<li>在不改变语义的前提下，修改语句， 引导MySQL使用我们期望的索引  </li>
<li>在有些场景下， 可以新建一个更合适的索引， 来提供给优化器做选择， 或删掉误用的索引</li>
</ol>
<h3 id="字符串索引优化"><a href="#字符串索引优化" class="headerlink" title="字符串索引优化"></a>字符串索引优化</h3><p>MySQL 支持前缀索引，也就是说可以指定字符串的前N位作为索引，默认为整个字符串作为索引。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql&gt; alter table SUser add index index1(email);</span><br><span class="line">mysql&gt; alter table SUser add index index2(email(6));</span><br></pre></td></tr></table></figure>

<p><strong>使用前缀索引， 定义好长度， 就可以做到既节省空间， 又不用额外增加太多的查询成本 。</strong></p>
<h4 id="区分度"><a href="#区分度" class="headerlink" title="区分度"></a>区分度</h4><p>区分度越高越好。 因为区分度越高， 意味着重复的键值越少，索引的效率越高。</p>
<p>使用以下SQL可以判断区分度</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql&gt; select count(distinct email) as L from SUser;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql&gt; select</span><br><span class="line">count(distinct left(email,4)） as L4,</span><br><span class="line">count(distinct left(email,5)） as L5,</span><br><span class="line">count(distinct left(email,6)） as L6,</span><br><span class="line">count(distinct left(email,7)） as L7,</span><br><span class="line">from SUser;</span><br></pre></td></tr></table></figure>

<p>这样可以寻找一个区分度较高，但是占用空间少的综合方案</p>
<p><strong>但是需要注意的是使用前缀索引的话，覆盖索引会失效。</strong></p>
<p>对于前缀索引区分度小的数据，可以采用其他办法</p>
<ol>
<li>倒序存储，比如身份证号可以考虑采用倒序存储的方式，并配合前缀索引，使得区分度高</li>
<li>使用hash字段，再添加一个整型字段用来存储该字段的hash值。使用crc32()  函数生成，由于会存在hash冲突，因此在查询时，需要根据该hash字段查询的同时，带上原字段的值做比较。</li>
</ol>
<h3 id="索引失效"><a href="#索引失效" class="headerlink" title="索引失效"></a>索引失效</h3><ul>
<li><p><strong>对索引字段做函数操作或计算操作（但是在有的函数操作时，MySQL优化器可能会觉得该索引树比主键索引小，遍历该索引树比较快，因此通过explain命令查看的话，会发现走了索引。但是这里并不是使用了索引树的搜索定位功能，而是遍历索引树）</strong></p>
</li>
<li><p>隐式类型转换：在MySQL中， 字符串和数字做比较的话， 是将字符串转换成数字。 </p>
<p>比如有以下sql</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql&gt; select * from tradelog where tradeid=110717;</span><br></pre></td></tr></table></figure>

<p>相当于</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql&gt; select * from tradelog where CAST(tradid AS signed int) = 110717;</span><br></pre></td></tr></table></figure>

<p>触发了对索引字段做函数操作规则，优化器会放弃走树搜索功能，而走索引树遍历</p>
</li>
<li><p>隐式字符编码转换 ：比如表关联时，一个是utf8， 一个是utf8mb4。则效果相当于以下sql</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql&gt;select * from trade_detail where CONVERT(traideid USING utf8mb4)=$L2.tradeid.value;</span><br></pre></td></tr></table></figure>

<p>还是触发了索引字段函数操作。</p>
</li>
</ul>
<h2 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h2><p>根据加锁的范围， MySQL里面的锁大致可以分成全局锁、 表级锁和行锁三类。  </p>
<h3 id="全局锁"><a href="#全局锁" class="headerlink" title="全局锁"></a>全局锁</h3><p><strong>全局锁就是对整个数据库实例加锁</strong>。 MySQL提供了一个加全局读锁的方法， 命令是<strong>Flush tables with read lock (FTWRL)<strong>。 当你需要让整个库处于只读状态的时候， 可以使用这个命令， 之后其他线程的</strong>以下语句会被阻塞： 数据更新语句（数据的增删改） 、 数据定义语句（包括建表、 修改表结构等） 和更新类事务的提交语句 。</strong></p>
<p><strong>全局锁的典型使用场景是， 做全库逻辑备份</strong>。也就是把整库每个表都select出来存成文本。  </p>
<p>官方自带的逻辑备份工具是<strong>mysqldump</strong>。 当mysqldump使用参数<strong>–single-transaction</strong>的时候， 导数据之前就会启动一个事务， 来确保拿到一致性视图。 而由于MVCC的支持， 这个过程中数据是可以正常更新的。  </p>
<p>不过single-transaction方法<strong>只适用于所有的表使用事务引擎的库</strong>。 如果有的表使用了不支持事务的引擎， 那么备份就只能通过FTWRL方法。 这往往是DBA要求业务开发人员使用InnoDB替代MyISAM的原因之一。  </p>
<p><strong>set global readonly&#x3D;true</strong>的方式也可以让全库进入只读状态， 但还是会<strong>建议用FTWRL方式</strong>， 主要有两个原因 ：</p>
<ul>
<li>一是， 在有些系统中， readonly的值会被用来做其他逻辑， 比如用来判断一个库是主库还是备库。 因此， 修改global变量的方式影响面更大， 不建议使用。</li>
<li>在异常处理机制上有差异。 如果执行FTWRL命令之后由于客户端发生异常断开， 那么MySQL会自动释放这个全局锁， 整个库回到可以正常更新的状态。 而将整个库设置为readonly之后， 如果客户端发生异常， 则数据库就会一直保持readonly状态， 这样会导致整个库长时间处于不可写状态， 风险较高</li>
</ul>
<h3 id="表锁"><a href="#表锁" class="headerlink" title="表锁"></a>表锁</h3><p>MySQL里面表级别的锁有两种： 一种是<strong>表锁</strong>， 一种是<strong>元数据锁（meta data lock， MDL)</strong>  。</p>
<p>表锁的语法是 <strong>lock tables …read&#x2F;write</strong>。 与FTWRL类似， 可以用<strong>unlock tables主动释放锁</strong>，也可以在客户端断开的时候自动释放。 需要注意， lock tables语法除了会限制别的线程的读写外， 也限定了本线程接下来的操作对象。  </p>
<p>如果在某个线程A中执行<strong>lock tables t1 read, t2 write;</strong> 这个语句， 则<strong>其他线程写t1、 读写t2的语句都会被阻塞</strong>。 同时， <strong>线程A在执行unlock tables之前， 也只能执行读t1、 读写t2的操作</strong>。 连写t1都不允许， 自然也不能访问其他表。 </p>
<p>**另一类表级的锁是MDL（ metadata lock)**。 <strong>MDL不需要显式使用， 在访问一个表的时候会被自动加上。 MDL的作用是， 保证读写的正确性</strong>。 如果一个查询正在遍历一个表中的数据， 而执行期间另一个线程对这个表结构做变更， 删了一列， 那么查询线程拿到的结果跟表结构对不上， 肯定是不行的。  </p>
<p>在MySQL 5.5版本中引入了MDL， <strong>当对一个表做增删改查操作的时候， 加MDL读锁； 当要对表做结构变更操作的时候， 加MDL写锁。</strong>  </p>
<ul>
<li><strong>读锁之间不互斥， 因此你可以有多个线程同时对一张表增删改查。</strong></li>
<li><strong>读写锁之间、 写锁之间是互斥的， 用来保证变更表结构操作的安全性。 因此， 如果有两个线程要同时给一个表加字段， 其中一个要等另一个执行完才能开始执行。</strong>  如果有一个线程要加字段，获取了MDL写锁，另一个线程执行增删改查操作，需要等MDL写锁释放之后才能执行成功。</li>
</ul>
<p>给一个表加字段， 或者修改字段， 或者加索引， 需要扫描全表的数据。   </p>
<p><strong>注意：假如有一个查询的长事务在对数据库进行增删改查获取了MDL读锁，这个时候修改去修改表结构，尝试获取MDL写锁失败阻塞，而在这个修改表结构语句之后的增删改查也都会阻塞住，导致这个表不可读不可写。</strong></p>
<h4 id="如何安全地给表加字段"><a href="#如何安全地给表加字段" class="headerlink" title="如何安全地给表加字段"></a>如何安全地给表加字段</h4><ol>
<li><strong>首先我们要解决长事务</strong>， 事务不提交， 就会一直占着MDL锁。 在MySQL的<strong>information_schema</strong>库的 <strong>innodb_trx</strong>表中， 你可以查到当前执行中的事务。 如果你要做DDL变更的表刚好有长事务在执行， 要考虑先暂停DDL， 或者kill掉这个长事务。  </li>
<li><strong>在alter table语句里面设定等待时间</strong>， 如果在这个指定的等待时间里面能够拿到MDL写锁最好， 拿不到也不要阻塞后面的业务语句， 先放弃。 之后开发人员或者DBA再通过重试命令重复这个过程 。</li>
</ol>
<h3 id="行锁"><a href="#行锁" class="headerlink" title="行锁"></a>行锁</h3><p><strong>MySQL的行锁是在引擎层由各个引擎自己实现的。 但并不是所有的引擎都支持行锁， 比如MyISAM引擎就不支持行锁。 不支持行锁意味着并发控制只能使用表锁， 对于这种引擎的表， 同一张表上任何时刻只能有一个更新在执行， 这就会影响到业务并发度。</strong> </p>
<p><strong>行锁就是针对数据表中行记录的锁</strong>。 这很好理解， 比如事务A更新了一行， 而这时候事务B也要更新同一行， 则必须等事务A的操作完成后才能进行更新。  </p>
<p>行锁， 分成读锁和写锁  </p>
<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20221110210336.png" style="width: 50%;" />

<h4 id="两阶段锁"><a href="#两阶段锁" class="headerlink" title="两阶段锁"></a>两阶段锁</h4><p>在InnoDB事务中， 行锁是在需要的时候才加上的， 但并不是不需要了就立刻释放， 而是要等到事务结束时才释放。 这个就是<strong>两阶段锁协议。</strong>  </p>
<p><strong>如果你的事务中需要锁多个行， 要把最可能造成锁冲突、 最可能影响并发度的锁尽量往后放。</strong>   </p>
<h4 id="死锁和死锁检测"><a href="#死锁和死锁检测" class="headerlink" title="死锁和死锁检测"></a>死锁和死锁检测</h4><p>当并发系统中不同线程出现<strong>循环资源依赖， 涉及的线程都在等待别的线程释放资源时</strong>， 就会导致这几个线程都进入无限等待的状态， 称为死锁。  </p>
<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20221102154339.png" style="width: 50%;" />

<p>这时候， 事务A在等待事务B释放id&#x3D;2的行锁， 而事务B在等待事务A释放id&#x3D;1的行锁。 事务A和事务B在互相等待对方的资源释放， 就是进入了死锁状态。 当出现死锁以后， 有两种策略：  </p>
<ul>
<li>一种策略是， 直接<strong>进入等待， 直到超时</strong>。 这个超时时间可以通过参数<strong>innodb_lock_wait_timeout</strong>来设置（InnoDB中， <strong>innodb_lock_wait_timeout的默认值是50s</strong>，太长，且这个时间不好界定，不建议使用这种方式）。</li>
<li>另一种策略是， 发起<strong>死锁检测</strong>， 发现死锁后， 主动回滚死锁链条中的某一个事务， 让其他事务得以继续执行。 将参数<strong>innodb_deadlock_detect设置为on</strong>， 表示开启这个逻辑（默认就是开启，不过有额外消耗，每个新来的被堵住的线程都要判断会不会由于自己的加入导致死锁，这个操作时间复杂度是O(n) ，会消耗大量的CPU资源，因此会出现CPU利用率很高，但每秒执行不了几个事务）。</li>
</ul>
<p><strong>怎么解决由这种热点行更新导致的性能问题呢？</strong> 问题的症结在于， <strong>死锁检测要耗费大量的CPU资源</strong>  </p>
<ol>
<li><p>如果你能确保这个业务一定不会出现死锁， 可以临时把死锁检测关掉  </p>
</li>
<li><p>另一个思路是控制并发度 </p>
<p>①在客户端做并发控制，但是客户端较多的时候，无效</p>
<p>②使用中间件控制并发度</p>
<p>③修改MySQL源码，使得对于相同行的更新，在进入引擎之前排队  </p>
<p>④将热点数据一行分多行存放，减少冲突</p>
</li>
</ol>
<h3 id="读锁写锁"><a href="#读锁写锁" class="headerlink" title="读锁写锁"></a>读锁写锁</h3><p><strong>读锁与读锁之间可共享，读锁和写锁之间互斥，写锁和写锁之间也互斥。</strong></p>
<p>在select语句中加<strong>lock in share mode</strong>或<strong>for update</strong>可以显式的加锁，从而进行当前读，而非快照读。</p>
<h4 id="lock-in-share-mode-和-for-update-的区别"><a href="#lock-in-share-mode-和-for-update-的区别" class="headerlink" title="lock in share mode 和 for update 的区别"></a>lock in share mode 和 for update 的区别</h4><ul>
<li><p>select … lock in share mode，是 IS 锁 (意向共享锁 ，读锁)，在符合条件的 rows 上都加了共享锁，因此 其他 session 可以读取这些记录，也可以继续添加 IS 锁，但是无法修改这些记录直到你这个加锁的 Session A 执行完成 (否则直接锁等待超时)。</p>
</li>
<li><p>select … for update，是 IX 锁 (意向排它锁，写锁)，在符合条件的 rows 上都加了排它锁，其他 session 也就无法在这些记录上添加任何的 S 锁或 X 锁。</p>
<p>如果不存在一致性非锁定读的话，那么其他 session 是无法读取和修改这些记录的，但是 innodb 有非锁定读 (快照读并不需要加锁)，for update 之后并不会阻塞其他 session 的快照读取操作，除了 select …lock in share mode 和 select … for update 这种显示加锁的查询操作。</p>
</li>
</ul>
<h3 id="间隙锁（Gap-Lock-）"><a href="#间隙锁（Gap-Lock-）" class="headerlink" title="间隙锁（Gap Lock  ）"></a>间隙锁（Gap Lock  ）</h3><p><strong>间隙锁在可重复读隔离级别下才有效。</strong></p>
<p><strong>产生幻读的原因是， 行锁只能锁住行， 但是新插入记录这个动作， 要更新的是记录之间的“间隙”。 因此， 为了解决幻读问题， InnoDB只好引入新的锁， 也就是间隙锁(GapLock)。</strong> </p>
<p>顾名思义， 间隙锁， 锁的就是两个值之间的空隙。 比如一张表t， 初始化插入了6个记录，这就产生了7个间隙。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">CREATE TABLE `t` (</span><br><span class="line">`id` int(11) NOT NULL,</span><br><span class="line">`c` int(11) DEFAULT NULL,</span><br><span class="line">`d` int(11) DEFAULT NULL,</span><br><span class="line">PRIMARY KEY (`id`),</span><br><span class="line">KEY `c` (`c`)</span><br><span class="line">) ENGINE=InnoDB;</span><br><span class="line">insert into t values(0,0,0),(5,5,5),</span><br><span class="line">(10,10,10),(15,15,15),(20,20,20),(25,25,25);</span><br></pre></td></tr></table></figure>

<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20221110203747.png" style="width: 50%;" />

<p>比如执行</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql&gt;select * from t where d=5 for update</span><br></pre></td></tr></table></figure>

<p><strong>数据库扫描的过程中，不止是给数据库中已有的6个记录加上了行锁， 还同时加了7个间隙锁。 这样就确保了无法再插入新的记录。</strong></p>
<p><strong>跟间隙锁存在冲突关系的， 是“往这个间隙中插入一个记录”这个操作。 间隙锁之间都不存在冲突关系。</strong>  </p>
<p>而如果执行</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql&gt;select * from t where c=7 for update</span><br></pre></td></tr></table></figure>

<p>c字段上有索引，但表t里并没有c&#x3D;7这个记录， 因此加的是c索引上的间隙锁(5,10) </p>
<h4 id="next-key-lock"><a href="#next-key-lock" class="headerlink" title="next-key lock"></a>next-key lock</h4><p><strong>间隙锁和行锁合称next-keylock， 每个next-keylock是前开后闭区间。</strong>  </p>
<p>上一章节《间隙锁》中的表t初始化以后， 如果用select * from t for update要把整个表所有记录锁起来， 就形成了7个next-key<br>lock， 分别是 (-∞,0]、 (0,5]、 (5,10]、 (10,15]、 (15,20]、 (20, 25]、 (25, +supremum]。</p>
<p>supremum是因为+∞是开区间。 实现上，InnoDB给每个索引加了一个不存在的最大值supremum， 这样才符合“都是前开后闭区间”。  </p>
<p><strong>间隙锁和next-key lock的引入， 帮我们解决了幻读的问题， 但同时也带来了一些“困扰</strong>  </p>
<p><strong>间隙锁的引入， 可能会导致同样的语句锁住更大的范围， 这其实是影响了并发度的。</strong>  </p>
<p>比如session A在(5,10)上加了间隙锁，session B在(5,10)上也加了间隙锁。而session A和session B都往(5,10)这个间隙上插入数据的时候，会被对方的间隙锁锁住，从而导致死锁问题的发送。</p>
<h4 id="加锁规则"><a href="#加锁规则" class="headerlink" title="加锁规则"></a>加锁规则</h4><p>**锁是加在索引上的；   **</p>
<p>适用5.x系列&lt;&#x3D;5.7.24， 8.0系列 &lt;&#x3D;8.0.13。  </p>
<ol>
<li>原则1： 加锁的基本单位是next-keylock。 希望你还记得， next-keylock是前开后闭区间。</li>
<li>原则2： 查找过程中访问到的对象才会加锁。</li>
<li>优化1： 索引上的等值查询， 给唯一索引加锁的时候， next-keylock退化为行锁。</li>
<li>优化2： 索引上的等值查询， 向右遍历时且最后一个值不满足等值条件的时候， next-key lock退化为间隙锁。</li>
<li>一个bug： 唯一索引上的范围查询会访问到不满足条件的第一个值为止。</li>
</ol>
<p>其中原则2，如果要用的select查询，并且查询字段在覆盖索引里，且select加的是读锁的话，则只会锁覆盖索引，不会锁主键索引。而如果加的是写锁，则也会将主键索引上满足条件的行加上行锁。</p>
<p><strong>next-keylock实际上是由间隙锁加行锁实现的，具体执行的时候， 是要分成间隙锁和行锁两段来执行的。</strong>  </p>
<h2 id="Flush过程"><a href="#Flush过程" class="headerlink" title="Flush过程"></a>Flush过程</h2><p><strong>当内存数据页跟磁盘数据页内容不一致的时候， 我们称这个内存页为“脏页”。 内存数据写入到磁盘后， 内存和磁盘上的数据页的内容就一致了， 称为“干净页”。</strong>  </p>
<p>平时执行很快的更新操作， 其实就是在写内存和日志， 而MySQL偶尔卡顿一下的那个瞬间， 可能就是在刷脏页（flush）。</p>
<h3 id="触发flush的情况"><a href="#触发flush的情况" class="headerlink" title="触发flush的情况"></a>触发flush的情况</h3><ol>
<li><strong>redo log写满</strong>，这时候系统会停止所有更新操作， 把checkpoint往前推进， redo log留出空间可以继续写。  </li>
<li><strong>内存不足</strong>，当需要新的内存页， 而内存不够用的时候， 就要淘汰一些数据页， 空出内存给别的数据页使用。 如果淘汰的是“脏页”， 就要先将脏页写到磁盘。  </li>
<li><strong>MySQL认为系统“空闲”的时候</strong>，会进行刷脏页，平时也会见缝插针有机会就刷</li>
<li><strong>MySQL关闭的时候</strong>，这时候， MySQL会把内存的脏页都flush到磁盘上， 这样下次MySQL启动的时候， 就可以直接从磁盘上读数据， 启动速度会很快。</li>
</ol>
<h3 id="flush对性能的影响"><a href="#flush对性能的影响" class="headerlink" title="flush对性能的影响"></a>flush对性能的影响</h3><p>触发flush的情况3和情况4基本对性能没什么影响。</p>
<p>情况一：会阻塞住所有的更新，导致系统的更新不可用，需要尽量避免。</p>
<p>情况二：是“内存不够用了， 要先将脏页写到磁盘”， 这种情况其实是常态。 InnoDB用缓冲池（buffer pool） 管理内存， 缓冲池中的内存页有三种状态：</p>
<ul>
<li>第一种是， 还没有使用的；</li>
<li>第二种是， 使用了并且是干净页；</li>
<li>第三种是， 使用了并且是脏页。</li>
</ul>
<p>InnoDB的策略是尽量使用内存， 因此对于一个长时间运行的库来说， 未被使用的页面很少。而当要读入的数据页没有在内存的时候， 就必须到缓冲池中申请一个数据页。 这时候只能把最久不使用的数据页从内存中淘汰掉： 如果要淘汰的是一个干净页， 就直接释放出来复用； 但如果是脏页呢， 就必须将脏页先刷到磁盘， 变成干净页后才能复用。<br>所以， 刷脏页虽然是常态， 但是出现以下这两种情况， 都是会明显影响性能的：</p>
<ol>
<li><strong>一个查询要淘汰的脏页个数太多， 会导致查询的响应时间明显变长；</strong></li>
<li><strong>日志写满， 更新全部堵住， 写性能跌为0， 这种情况对敏感业务来说， 是不能接受的。</strong></li>
</ol>
<h3 id="InnoDB刷脏页的控制策略"><a href="#InnoDB刷脏页的控制策略" class="headerlink" title="InnoDB刷脏页的控制策略"></a>InnoDB刷脏页的控制策略</h3><ol>
<li><p>首先， 要正确地告诉InnoDB<strong>所在主机的IO能力</strong>， 这样InnoDB才能知道需要全力刷脏页的时候， 可以刷多快。</p>
<p><strong>参数innodb_io_capacity，它会告诉InnoDB你的磁盘能力。 这个值建议设置成磁盘的IOPS。</strong></p>
<p>这个值可以用fio工具来进行压测得到</p>
</li>
<li><p><strong>按百分比刷</strong>，参数innodb_max_dirty_pages_pct是脏页比例上限（默认75%）。</p>
<p>InnoDB 会根据redo log的写入能力和脏页比例，算出一个值R，之后引擎就可以按照innodb_io_capacity定义的能力乘以R%来控制刷脏页的速度 。</p>
</li>
<li><p><strong>连坐制度</strong>，在准备刷一个脏页的时候， 如果这个数据页旁边的数据页刚好是脏页， 就会把这个“邻居”也带着一起刷掉；此策略对于该邻居也适用。</p>
<p>参数innodb_flush_neighbors 控制这个行为，innodb_flush_neighbors &#x3D; 1的时候开启连坐制度，innodb_flush_neighbors &#x3D; 0的时候表示自己刷自己的。</p>
<p>机械硬盘建议设为1，可以减少很多随机IO  ，SSD建议设置为0。在MySQL8.0开始，默认为0；</p>
</li>
</ol>
<h2 id="表空间回收"><a href="#表空间回收" class="headerlink" title="表空间回收"></a>表空间回收</h2><h3 id="参数innodb-file-per-table"><a href="#参数innodb-file-per-table" class="headerlink" title="参数innodb_file_per_table"></a>参数innodb_file_per_table</h3><p>表数据既可以存在共享表空间里， 也可以是单独的文件。 这个行为是由参数innodb_file_per_table控制的：  </p>
<ol>
<li>这个参数设置为OFF表示的是， 表的数据放在系统共享表空间， 也就是跟数据字典放在一<br>起；</li>
<li>这个参数设置为ON表示的是， 每个InnoDB表数据存储在一个以 .ibd为后缀的文件中。<br>从MySQL 5.6.6版本开始， 它的默认值就是ON了。</li>
</ol>
<p><strong>建议该参数一直设为ON，一个表单独存储为一个文件更容易管理， 而且在你不需要这个表的时候， 通过drop table命令， 系统就会直接删除这个文件。 而如果是放在共享表空间中， 即使表删掉了， 空间也是不会回收的。</strong>  </p>
<h3 id="数据删除流程"><a href="#数据删除流程" class="headerlink" title="数据删除流程"></a>数据删除流程</h3><img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20221108094837.png" style="width: 40%;" />

<p>​                                                                                                     索引结构示意图</p>
<p><strong>比如要删除R4这个记录，InnoDB引擎只会把R4这个记录标记为删除，之后如果要再插入一个ID在300到600之间的记录时，可能会复用这个位置，但是磁盘文件的大小并不会缩小。</strong></p>
<p>InnoDB按页存储，假如删除了一个页上的所有数据，则该页可复用。</p>
<p><strong>记录的复用，只限于符合范围条件的数据 。而页的复用，可以复用到任何位置 。</strong></p>
<p><strong>如果delete删除了全表上的数据，则所有的数据页都可复用，而磁盘上的存储空间不会变小。</strong></p>
<h3 id="页合并"><a href="#页合并" class="headerlink" title="页合并"></a>页合并</h3><p>如果相邻的两个数据页利用率都很小， 系统就会把这两个页上的数据合到其中一个页上， 另外一个数据页就被标记为可复用。  </p>
<p><strong>删除数据或者更新索引值有可能会导致页合并。</strong></p>
<h3 id="页分裂"><a href="#页分裂" class="headerlink" title="页分裂"></a>页分裂</h3><p>比如一个数据页满了，但是插入的数据索引值是在这个数据页的范围内的，则会申请一个新的页面，把部分数据给分出去。</p>
<p><strong>随机插入数据或者更新索引值有可能会导致页分裂。</strong></p>
<h3 id="数据空洞"><a href="#数据空洞" class="headerlink" title="数据空洞"></a>数据空洞</h3><p>可以复用， 而没有被使用的空间， 看起来就像是“空洞”。  </p>
<p>经过大量增删改的表， 都是可能是存在空洞的。 所以， 如果能够把这些空洞去掉， 就能达到收缩表空间的目的。  </p>
<h4 id="重建表"><a href="#重建表" class="headerlink" title="重建表"></a>重建表</h4><p>可以使用alter table A engine&#x3D;InnoDB命令来重建表。</p>
<p>但在MySQL5.5版本之前，重建表的时候不支持对该表进行更新，所以需要停机重建表。而从MySQL5.6开始，支持online操作。</p>
<p>对于很大的表来说， 这个操作是很消耗IO和CPU资源的。 因此， 如果是线上服务， 你要很小心地控制操作时间。 如果想要比较安全的操作的话， 我推荐你使用GitHub开源的gh-ost来做。</p>
<h2 id="count用法"><a href="#count用法" class="headerlink" title="count用法"></a>count用法</h2><h3 id="不同引擎count-的实现方式不同"><a href="#不同引擎count-的实现方式不同" class="headerlink" title="不同引擎count(*)的实现方式不同"></a>不同引擎count(*)的实现方式不同</h3><p>不带条件查询的时候</p>
<p>MyISAM引擎把一个表的总行数存在了磁盘上， 因此执行count(<em>)的时候会直接返回这个数，效率很高；<br>而InnoDB引擎就麻烦了， 它执行count(</em>)的时候， 需要把数据一行一行地从引擎里面读出来， 然后累积计数。  </p>
<h3 id="count-优化"><a href="#count-优化" class="headerlink" title="count(*)优化"></a>count(*)优化</h3><p>count(*)会找到最小的那棵索引树来遍历进行累计值，在保证逻辑正确的前提下， 尽量减少扫描的数据量， 是数据库系统设计的通用法则之一。</p>
<h3 id="几种计数方式"><a href="#几种计数方式" class="headerlink" title="几种计数方式"></a>几种计数方式</h3><h4 id="缓存系统"><a href="#缓存系统" class="headerlink" title="缓存系统"></a>缓存系统</h4><p>缓存可能存在丢失更新，或缓存与数据库不一致的情况。</p>
<h4 id="在数据库保存计数"><a href="#在数据库保存计数" class="headerlink" title="在数据库保存计数"></a>在数据库保存计数</h4><p>只要保证在一个事务里，可以解决在缓存系统中的问题。</p>
<h4 id="不同的count用法"><a href="#不同的count用法" class="headerlink" title="不同的count用法"></a>不同的count用法</h4><p>count()是一个聚合函数， 对于返回的结果集， 一行行地判断， 如果count函数的参数不是NULL， 累计值就加1， 否则不加。 最后返回累计值。</p>
<p>count(*)：优化器做了优化，并不会取字段，而是直接按行累加。</p>
<p>count(主键id)：InnoDB引擎会遍历整张表， 把每一行的id值都取出来， 返回给server层。 server层拿到id后， 判断是不可能为空的， 就按行累加  </p>
<p>count(字段)：如果这个“字段”是定义为not null的话， 一行行地从记录里面读出这个字段， 判断不能为null， 按行累加；如果这个“字段”定义允许为null， 那么执行的时候， 判断到有可能是null， 还要把值取出来再判断一下， 不是null才累加。  </p>
<p>count(1) ：InnoDB引擎遍历整张表， 但不取值。 server层对于返回的每一行， 放一个数字“1”进去， 判断是不可能为空的， 按行累加  </p>
<p><strong>所以结论是： 按照效率排序的话， count(字段)&lt;count(主键id)&lt;count(1)≈count(*)， 所以我建议你， 尽量使用count(*)。</strong>  </p>
<h2 id="Order-By执行流程"><a href="#Order-By执行流程" class="headerlink" title="Order By执行流程"></a>Order By执行流程</h2><p>表结构</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">CREATE TABLE `t` (</span><br><span class="line">`id` int(11) NOT NULL,</span><br><span class="line">`city` varchar(16) NOT NULL,</span><br><span class="line">`name` varchar(16) NOT NULL,</span><br><span class="line">`age` int(11) NOT NULL,</span><br><span class="line">`addr` varchar(128) DEFAULT NULL,</span><br><span class="line">PRIMARY KEY (`id`),</span><br><span class="line">KEY `city` (`city`)</span><br><span class="line">) ENGINE=InnoDB;</span><br></pre></td></tr></table></figure>

<p>查询sql</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">select city,name,age from t where city=&#x27;杭州&#x27; order by name limit 1000 ;</span><br></pre></td></tr></table></figure>

<h3 id="全字段排序"><a href="#全字段排序" class="headerlink" title="全字段排序"></a>全字段排序</h3><p>查询sql使用explain执行结果</p>
<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20221109104026.png" style="width: 80%;" />

<p>Extra这个字段中的“Using filesort”表示的就是需要排序， MySQL会给每个线程分配一块内存用于排序， 称为sort_buffer 。</p>
<p>通常情况下， 这个语句执行流程如下所示 ：</p>
<ol>
<li>初始化sort_buffer， 确定放入name、 city、 age这三个字段；</li>
<li>从索引city找到第一个满足city&#x3D;’杭州’条件的主键id；</li>
<li>到主键id索引取出整行， 取name、 city、 age三个字段的值， 存入sort_buffer中；</li>
<li>从索引city取下一个记录的主键id；</li>
<li>重复步骤3、 4直到city的值不满足查询条件为止；</li>
<li>对sort_buffer中的数据按照字段name做快速排序；</li>
<li>按照排序结果取前1000行返回给客户端</li>
</ol>
<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20221109104251.png" style="width: 50%;" />

<p>图中“按name排序”这个动作， 可能在内存中完成， 也可能需要使用外部排序， 这取决于排序所需的内存和参数sort_buffer_size。sort_buffer_size， 就是MySQL为排序开辟的内存（sort_buffer） 的大小。 如果要排序的数据量小于sort_buffer_size， 排序就在内存中完成。 但如果排序数据量太大， 内存放不下， 则不得不利用磁盘临时文件辅助排序。  </p>
<p>使用磁盘临时文件辅助的时候，一般使用的是归并排序，MySQL将需要排序的数据分成n份， 每一份单独排序后存在这些临时文件中。 然后把这n个有序文件再合并成一个有序的大文件。</p>
<h3 id="rowid排序"><a href="#rowid排序" class="headerlink" title="rowid排序"></a>rowid排序</h3><p>参数：max_length_for_sort_data  </p>
<p>max_length_for_sort_data， 是MySQL中专门控制用于排序的行数据的长度的一个参数。 它的意思是， 如果单行的长度超过这个值， MySQL就认为单行太大， 要换一个算法。  </p>
<p>新的算法放入sort_buffer的字段， 只有要排序的列（ 即name字段） 和主键id。  </p>
<p>执行流程：</p>
<ol>
<li>初始化sort_buffer， 确定放入两个字段， 即name和id；</li>
<li>从索引city找到第一个满足city&#x3D;’杭州’条件的主键id；</li>
<li>到主键id索引取出整行， 取name、 id这两个字段， 存入sort_buffer中；</li>
<li>从索引city取下一个记录的主键id；</li>
<li>重复步骤3、 4直到不满足city&#x3D;’杭州’条件为止；</li>
<li>对sort_buffer中的数据按照字段name进行排序；</li>
<li>遍历排序结果， 取前1000行， 并按照id的值回到原表中取出city、 name和age三个字段返回<br>给客户端。</li>
</ol>
<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20221109105121.png" style="width: 50%;" />

<p>最后的“结果集”是一个逻辑概念， 实际上MySQL服务端从排序后的sort_buffer中依次取出id， 然后到原表查到city、 name和age这三个字段的结果， 不需要在服务端再耗费内存存储结果， 是直接返回给客户端的 。</p>
<h3 id="全字段排序-VS-rowid排序"><a href="#全字段排序-VS-rowid排序" class="headerlink" title="全字段排序 VS rowid排序"></a>全字段排序 VS rowid排序</h3><p>如果MySQL实在是担心排序内存太小， 会影响排序效率， 才会采用rowid排序算法， 这样排序过程中一次可以排序更多行， 但是需要再回到原表去取数据。</p>
<p>如果MySQL认为内存足够大， 会优先选择全字段排序， 把需要的字段都放到sort_buffer中， 这样排序后就会直接从内存里面返回查询结果了， 不用再回到原表去取数据。<br><strong>这也就体现了MySQL的一个设计思想： 如果内存够， 就要多利用内存， 尽量减少磁盘访问。对于InnoDB表来说， rowid排序会要求回表多造成磁盘读， 因此不会被优先选择。</strong>  </p>
<p>如果order by的字段本来就是有序的话（比如是索引字段），则不需要排序直接返回。</p>
<h3 id="临时表上的排序"><a href="#临时表上的排序" class="headerlink" title="临时表上的排序"></a>临时表上的排序</h3><h4 id="内存临时表"><a href="#内存临时表" class="headerlink" title="内存临时表"></a>内存临时表</h4><p>假如有sql</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql&gt; select word from words order by rand() limit 3;</span><br></pre></td></tr></table></figure>

<p>explain 信息</p>
<p><img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20221110162736.png" alt="image-20221110162729114"></p>
<p>Extra字段显示Using temporary， 表示的是需要使用临时表； Using filesort， 表示的是需要执行排序操作。<br>因此这个Extra的意思就是， 需要临时表， 并且需要在临时表上排序  </p>
<p><strong>对于InnoDB表来说， 执行全字段排序会减少磁盘访问， 因此会被优先选择。</strong></p>
<p><strong>对于内存表， 回表过程只是简单地根据数据行的位置， 直接访问内存得到数据， 根本不会导致多访问磁盘。 优化器没有了这一层顾虑， 那么它会优先考虑的， 就是用于排序的行越少越好了， 所以， MySQL这时就会选择rowid排序。</strong>    </p>
<h4 id="磁盘临时表"><a href="#磁盘临时表" class="headerlink" title="磁盘临时表"></a>磁盘临时表</h4><p>tmp_table_size这个配置限制了内存临时表的大小， 默认值是16M。 如果临时表大小超过了tmp_table_size， 那么内存临时表就会转成磁盘临时表。  </p>
<p>磁盘临时表使用的引擎默认是InnoDB， 是由参数internal_tmp_disk_storage_engine控制的。<br>当使用磁盘临时表的时候， 对应的就是一个没有显式索引的InnoDB表的排序过程。  </p>
<p>语句里使用了limit的话，优先采用堆排序，只有当采用堆排序内存会大于设置的sort_buffer_size大小时，才会使用归并排序。</p>
<h2 id="查询单条数据慢问题"><a href="#查询单条数据慢问题" class="headerlink" title="查询单条数据慢问题"></a>查询单条数据慢问题</h2><h3 id="第一类：-查询长时间不返回"><a href="#第一类：-查询长时间不返回" class="headerlink" title="第一类： 查询长时间不返回"></a>第一类： 查询长时间不返回</h3><p>使用show processlist  命令查看语句状态</p>
<ul>
<li>等MDL锁</li>
</ul>
<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20221110190818.png" style="width: 80%;" />

<p>这个状态表示的是， 现在有一个线程正在表t上请求或者持有MDL写锁， 把select语句堵住了  </p>
<p>解决：杀掉持有MDL写锁的线程</p>
<p>通过performance_schema和sys系统库进行分析，（MySQL启动时需要设置performance_schema&#x3D;on， 相比于设置为off会有10%左右的性能损失)  。</p>
<p>通过查询sys.schema_table_lock_waits这张表， 就可以直接找出造成阻塞的process id， 把这个连接用kill 命令断开即可  </p>
<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20221110191046.png" style="width: 80%;" />

<ul>
<li>等flush</li>
</ul>
<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20221110191130.png" style="width: 80%;" />

<p>flush用法</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">flush tables t with read lock;</span><br><span class="line">flush tables with read lock;</span><br></pre></td></tr></table></figure>

<p>这两个flush语句， 如果指定表t的话， 代表的是只关闭表t； 如果没有指定具体的表名， 则表示关闭MySQL里所有打开的表。<br>但是正常这两个语句执行起来都很快， 除非它们也被别的线程堵住了  </p>
<p>所以， 出现Waiting for table flush状态的可能情况是： 有一个flush tables命令被别的语句堵住了， 然后它又堵住了我们的select语句。 </p>
<ul>
<li>等行锁</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql&gt; select * from t where id=1 lock in share mode;</span><br></pre></td></tr></table></figure>

<p>以上语句在访问id&#x3D;1这条数据时，需要加读锁。而如果这时候已经有一个事务在这行记录上持有一个写锁， 我们的select语句就会被堵住  </p>
<p>如果你用的是MySQL 5.7版本， 可以通过sys.innodb_lock_waits 表查到是哪个进程占用着该写锁。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql&gt; select * from t sys.innodb_lock_waits where locked_table=`&#x27;test&#x27;.&#x27;t&#x27;`\G</span><br></pre></td></tr></table></figure>

<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20221110191706.png" style="width: 80%;" />

<p>使用KILL 4，也就是说直接断开这个连接。 这里隐含的一个逻辑就是， 连接被断开的时候， 会自动回滚这个连接里面正在执行的线程， 也就释放了id&#x3D;1上的行锁。  </p>
<h3 id="第二类：-查询慢"><a href="#第二类：-查询慢" class="headerlink" title="第二类： 查询慢"></a>第二类： 查询慢</h3><ul>
<li>扫描行数多</li>
<li>一致性读，在查询期间回滚日志(undo log)过长</li>
</ul>
<h2 id="连接数过多"><a href="#连接数过多" class="headerlink" title="连接数过多"></a>连接数过多</h2><p>max_connections参数， 用来控制一个MySQL实例同时存在的连接数的上限， 超过这个值， 系统就会拒绝接下来的连接请求， 并报错提示“Too manyconnections”。 对于被拒绝连接的请求来说， 从业务角度看就是数据库不可用。  </p>
<p>在机器负载比较高的时候， 处理现有请求的时间变长， 每个连接保持的时间也更长。 这时， 再有新建连接的话， 就可能会超过max_connections的限制。  </p>
<h3 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h3><p><strong>第一种方法： 先处理掉那些占着连接但是不工作的线程。</strong>  </p>
<p>max_connections的计算， 不是看谁在running， 是只要连着就占用一个计数位置。 对于那些不需要保持的连接， 我们可以通过kill connection主动踢掉。 这个行为跟事先设置wait_timeout的效果是一样的。 设置wait_timeout参数表示的是， 一个线程空闲wait_timeout这么多秒之后， 就会被MySQL直接断开连接。  </p>
<p>通过show processlist查看连接状态</p>
<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20221116005805.png" style="width: 60%;" />

<p>查询查information_schema库的innodb_trx表 查看事务状态</p>
<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20221116005930.png" style="width: 60%;" />

<p><strong>如果是连接数过多， 你可以优先断开事务外空闲太久的连接； 如果这样还不够， 再考虑断开事务内空闲太久的连接 。</strong></p>
<p>从服务端断开连接使用的是kill connection + id的命令， 一个客户端处于sleep状态时， 它的连接被服务端主动断开后， 这个客户端并不会马上知道。 直到客户端在发起下一个请求的时候， 才会收到这样的报错“ERROR 2013 (HY000): Lost connection to MySQL server during query”。  </p>
<p>从数据库端主动断开连接可能是有损的， 尤其是有的应用端收到这个错误后， 不重新连接， 而是直接用这个已经不能用的句柄重试查询。 这会导致从应用端看上去， “MySQL一直没恢复”。  </p>
<p><strong>第二种方法： 减少连接过程的消耗。</strong>  </p>
<p>如果现在数据库确认是被连接行为打挂了， 那么一种可能的做法， 是让数据库跳过权限验证阶段。  </p>
<p>跳过权限验证的方法是： 重启数据库， 并使用–skip-grant-tables参数启动。 这样， 整个MySQL会跳过所有的权限验证阶段， 包括连接过程和语句执行过程在内。  </p>
<p>风险极高， 特别不建议使用的方案。尤其数据库外网可访问的话， 就更不能这么做了  </p>
<h2 id="慢查询性能问题"><a href="#慢查询性能问题" class="headerlink" title="慢查询性能问题"></a>慢查询性能问题</h2><p>在MySQL中慢查询大体有以下三种原因：</p>
<h3 id="索引没有设计好"><a href="#索引没有设计好" class="headerlink" title="索引没有设计好"></a>索引没有设计好</h3><p>一般就是通过紧急创建索引来解决 ，对于那种高峰期数据库已经被这个语句打挂了的情况， 最高效的做法就是直接执行alter table 语句。  </p>
<p>比较理想的是能够在备库先执行。 假设你现在的服务是一主一备， 主库A、 备库B， 这个方案的大致流程是这样的：</p>
<ol>
<li>在备库B上执行 set sql_log_bin&#x3D;off， 也就是不写binlog， 然后执行alter table 语句加上索引；</li>
<li>执行主备切换；</li>
<li>这时候主库是B， 备库是A。 在A上执行 set sql_log_bin&#x3D;off， 然后执行alter table 语句加上索引</li>
</ol>
<p>这是一个“古老”的DDL方案。 平时在做变更的时候， 你应该考虑类似gh-ost这样的方案， 更加稳妥。 但是在需要紧急处理时， 上面这个方案的效率是最高的。  </p>
<h3 id="SQL语句没写好"><a href="#SQL语句没写好" class="headerlink" title="SQL语句没写好"></a>SQL语句没写好</h3><p>可以通过改写SQL语句来处理。 MySQL 5.7提供了query_rewrite功能， 可以把输入的一种语句改写成另外一种模式  </p>
<p>比如错误sql为：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql &gt; select * from t where id + 1 = 10000;</span><br></pre></td></tr></table></figure>

<p>但是因为在字段上做运算，会导致没有走索引，因此需要将此语句修改为：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql &gt; select * from t where id = 10000-1;</span><br></pre></td></tr></table></figure>

<p>让其走索引。</p>
<p>安装 query_rewrite 插件后，可以进行查询重写</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">--插入一条规则（注：我这张表在 employees 库中）</span><br><span class="line">insert into query_rewrite.rewrite_rules(pattern, replacement, pattern_database) values </span><br><span class="line">(&quot;select * from t where id + 1 = ? &quot;, &quot;select * from t where id = ? - 1 &quot;, &quot;employees&quot;);</span><br><span class="line"> </span><br><span class="line"> -- 存储过程，是让插入的新规则生效，也就是我们说的“查询重写”。</span><br><span class="line">call query_rewrite.flush_rewrite_rules();</span><br><span class="line"> </span><br><span class="line">--查询规则表</span><br><span class="line">SELECT * FROM query_rewrite.rewrite_rules;</span><br></pre></td></tr></table></figure>

<p>查看规则是否生效</p>
<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20221118112731.png" style="width: 80%;" />



<h3 id="MySQL选错了索引"><a href="#MySQL选错了索引" class="headerlink" title="MySQL选错了索引"></a>MySQL选错了索引</h3><p>这时候， 应急方案就是给这个语句加上force index。<br>同样地， 使用查询重写功能， 给原来的语句加上force index， 也可以解决这个问题。  </p>
<p>比较常见的是遇见前两种情况，不过可以预先避免。</p>
<ol>
<li>上线前， 在测试环境， 把慢查询日志（slow log） 打开， 并且把long_query_time设置成0，确保每个语句都会被记录入慢查询日志；</li>
<li>在测试表里插入模拟线上的数据， 做一遍回归测试；</li>
<li>观察慢查询日志里每类语句的输出， 特别留意Rows_examined字段是否与预期一致。<strong>使用pt-query-digest工具</strong>可以分析慢查询日志。</li>
</ol>
<h2 id="MySQL主备的基本原理"><a href="#MySQL主备的基本原理" class="headerlink" title="MySQL主备的基本原理"></a>MySQL主备的基本原理</h2><h3 id="最基本的主备切换流程"><a href="#最基本的主备切换流程" class="headerlink" title="最基本的主备切换流程"></a>最基本的主备切换流程</h3><img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20230207191024.png" alt="image-20230207191017612" style="zoom:80%;" />

<p>备中心readonly设置对超级(super)权限用户是无效的， 而用于同步更新的线程， 就拥有超级权限  </p>
<h3 id="主备同步完整流程"><a href="#主备同步完整流程" class="headerlink" title="主备同步完整流程"></a>主备同步完整流程</h3><p><img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20230207191120.png" alt="image-20230207191119818"></p>
<p>主库接收到客户端的更新请求后， 执行内部事务的更新逻辑， 同时写binlog。<br>备库B跟主库A之间维持了一个长连接。 主库A内部有一个线程， 专门用于服务备库B的这个长连接。 一个事务日志同步的完整过程是这样的：</p>
<ol>
<li>在备库B上通过change master命令， 设置主库A的IP、 端口、 用户名、 密码， 以及要从哪个位置开始请求binlog， 这个位置包含文件名和日志偏移量。</li>
<li>在备库B上执行start slave命令， 这时候备库会启动两个线程， 就是图中的io_thread和sql_thread。 其中io_thread负责与主库建立连接。</li>
<li>主库A校验完用户名、 密码后， 开始按照备库B传过来的位置， 从本地读取binlog， 发给B。</li>
<li>备库B拿到binlog后， 写到本地文件， 称为中转日志（relaylog） 。</li>
<li>sql_thread读取中转日志， 解析出日志里的命令， 并执行（后来由于多线程复制方案的引入， sql_thread演化成为了多个线程  ）</li>
</ol>
<h3 id="循环复制问题"><a href="#循环复制问题" class="headerlink" title="循环复制问题"></a>循环复制问题</h3><p>实际生产会用的比较多的会是双M结构</p>
<p><img src="C:/Users/ZhouHJ/AppData/Roaming/Typora/typora-user-images/image-20221119155800906.png" alt="image-20221119155800906"></p>
<p>双M结构和M-S结构， 其实区别只是多了一条线， 即： 节点A和B之间总是互为主备关系。 这样在切换的时候就不用再修改主备关系。  </p>
<p>双M结构还有一个问题需要解决。业务逻辑在节点A上更新了一条语句， 然后再把生成的binlog 发给节点B， 节点B执行完这条更新<br>语句后也会生成binlog。 （我建议你把参数log_slave_updates设置为on， 表示备库执行relaylog后生成binlog） 。  </p>
<p>那么， 如果节点A同时是节点B的备库， 相当于又把节点B新生成的binlog拿过来执行了一次， 然后节点A和B间， 会不断地循环执行这个更新语句， 也就是循环复制了。 这个要怎么解决呢？  </p>
<p>可以用下面的逻辑， 来解决两个节点间的循环复制的问题：</p>
<ol>
<li>规定两个库的server id必须不同， 如果相同， 则它们之间不能设定为主备关系；</li>
<li>一个备库接到binlog并在重放的过程中， 生成与原binlog的server id相同的新的binlog；</li>
<li>每个库在收到从自己的主库发过来的日志后， 先判断server id， 如果跟自己的相同， 表示这个日志是自己生成的， 就直接丢弃这个日志。</li>
</ol>
<p>按照这个逻辑， 如果我们设置了双M结构， 日志的执行流就会变成这样：</p>
<ol>
<li>从节点A更新的事务， binlog里面记的都是A的server id；</li>
<li>传到节点B执行一次以后， 节点B生成的binlog 的server id也是A的server id；</li>
<li>再传回给节点A， A判断到这个server id与自己的相同， 就不会再处理这个日志。 所以， 死循环在这里就断掉了</li>
</ol>
<h2 id="主备延迟"><a href="#主备延迟" class="headerlink" title="主备延迟"></a>主备延迟</h2><p><strong>备库执行show slave status命令，返回内容里的seconds_behind_master（单位秒）， 用于表示当前备库延迟了多少秒。</strong></p>
<p>主备延迟最直接的表现是， 备库消费中转日志（ relaylog） 的速度， 比主库生产binlog的速度要慢。  </p>
<h3 id="主备延迟的来源"><a href="#主备延迟的来源" class="headerlink" title="主备延迟的来源"></a>主备延迟的来源</h3><p>1.备库所在机器的性能要比主库所在的机器性能差。  (对称部署)</p>
<p>2.备库的压力大，比如读写分离。读的是备库但读的压力大导致备库压力大，耗费了大量的CPU资源， 影响了同步速度， 造成主备延<br>迟。（采用一主多从分担压力，保证备库的压力不会超过主库 ）</p>
<p>3.大事务，如果一个主库上的语句执行10分钟， 那这个事务很可能就会导致从库延迟10分钟（不要一次性地用delete语句删除太多数据  ，大表DDL  ）</p>
<p>4.备库的并行复制能力  </p>
<h3 id="主备切换策略"><a href="#主备切换策略" class="headerlink" title="主备切换策略"></a>主备切换策略</h3><h4 id="可靠性优先策略"><a href="#可靠性优先策略" class="headerlink" title="可靠性优先策略"></a>可靠性优先策略</h4><ol>
<li>判断备库B现在的seconds_behind_master， 如果小于某个值（比如5秒） 继续下一步， 否则持续重试这一步；</li>
<li>把主库A改成只读状态， 即把readonly设置为true；</li>
<li>判断备库B的seconds_behind_master的值， 直到这个值变成0为止；</li>
<li>把备库B改成可读写状态， 也就是把readonly设置为false；</li>
<li>把业务请求切到备库B。</li>
</ol>
<p>这个切换流程， 一般是由专门的HA系统来完成的。</p>
<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20221207112217.png" style="width: 80%;" />

<p>这个切换流程中是有不可用时间的。 因为在步骤2之后， 主库A和备库B都处于readonly状态， 也就是说这时系统处于不可写状态， 直到步骤5完成后才能恢复。  </p>
<h4 id="可用性优先策略"><a href="#可用性优先策略" class="headerlink" title="可用性优先策略"></a>可用性优先策略</h4><p>如果强行把步骤4、 5调整到最开始执行， 也就是说不等主备数据同步， 直接把连接切到备库B， 并且让备库B可以读写， 那么系统几乎就没有不可用时间了。但是这个切换流程的代价， 就是可能出现数据不一致的情况。  </p>
<h3 id="备库并行复制能力"><a href="#备库并行复制能力" class="headerlink" title="备库并行复制能力"></a>备库并行复制能力</h3><p>官方的5.6版本之前， MySQL只支持单线程复制， 由此在主库并发高、 TPS高时就会出现严重的主备延迟问题（主库多个线程在写，而备库只有一个线程，会导致延迟越来越严重）。</p>
<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20221207141620.png" style="width: 60%;" />



<p>coordinator就是原来的sql_thread, 不过现在它不再直接更新数据了， 只负责读取中转日志和分发事务。 真正更新日志的， 变成了worker线程。 而work线程的个数， 就是由参数slave_parallel_workers决定的。把这个值设置为8~16之间最好（32核物理机的<br>情况） ， 毕竟备库还有可能要提供读查询， 不能把CPU都吃光了。</p>
<p><strong>coordinator在分发的时候， 需要满足以下这两个基本要求：</strong></p>
<ol>
<li>不能造成更新覆盖。 这就要求更新同一行的两个事务， 必须被分发到同一个worker中。</li>
<li>同一个事务不能被拆开， 必须放到同一个worker中。</li>
</ol>
<h3 id="并行复制策略"><a href="#并行复制策略" class="headerlink" title="并行复制策略"></a>并行复制策略</h3><h4 id="MySQL-5-5版本的并行复制策略"><a href="#MySQL-5-5版本的并行复制策略" class="headerlink" title="MySQL 5.5版本的并行复制策略"></a>MySQL 5.5版本的并行复制策略</h4><p>官方MySQL 5.5版本是不支持并行复制的。 自己实现的话有以下两种策略：</p>
<p><strong>按表分发策略</strong></p>
<p><strong>按表分发事务的基本思路是， 如果两个事务更新不同的表， 它们就可以并行。</strong> 因为数据是存储在表里的， 所以按表分发， 可以保证两个worker不会更新同一行。<br><strong>当然， 如果有跨表的事务， 还是要把两张表放在一起考虑的。</strong> </p>
<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20221208102032.png" style="width: 50%;" />

<p>每个事务在分发的时候， 跟所有worker的冲突关系包括以下三种情况：</p>
<ol>
<li>如果跟所有worker都不冲突， coordinator线程就会把这个事务分配给最空闲的woker;</li>
<li>如果跟多于一个worker冲突， coordinator线程就进入等待状态， 直到和这个事务存在冲突关系的worker只剩下1个；</li>
<li>如果只跟一个worker冲突， coordinator线程就会把这个事务分配给这个存在冲突关系的<br>worker。</li>
</ol>
<p>按表分发的方案， 在多个表负载均匀的场景里应用效果很好。 但是， 如果碰到热点表， 比如所有的更新事务都会涉及到某一个表的时候， 所有事务都会被分配到同一个worker中， 就变成单线程复制了 。</p>
<p><strong>按行分发策略</strong></p>
<p>按行复制的核心思路是： 如果两个事务没有更新相同的行， 它们在备库上可以并行执行。 显然， 这个模式要求binlog格式必须<br>是row 。</p>
<p><strong>worker结果跟按表分发的类似，只是map的key变成了库名+表名+主键+唯一索引名字+唯一索引的值</strong>  </p>
<p><strong>相比于按表并行分发策略， 按行并行策略在决定线程分发的时候， 需要消耗更多的计算资源。</strong></p>
<p>这两个方案其实都有一些约束条件：  </p>
<ol>
<li>要能够从binlog里面解析出表名、 主键值和唯一索引的值。 也就是说， 主库的binlog格式必须是row；</li>
<li>表必须有主键；</li>
<li>不能有外键。 表上如果有外键， 级联更新的行不会记录在binlog中， 这样冲突检测就不准确。</li>
</ol>
<p>对比按表分发和按行分发这两个方案的话， 按行分发策略的并行度更高。   如果是要操作很多行的大事务的话， 按行分发的策略有两个问题：</p>
<ol>
<li>耗费内存。 比如一个语句要删除100万行数据， 这时候hash表就要记录100万个项。</li>
<li>耗费CPU。 解析binlog， 然后计算hash值， 对于大事务， 这个成本还是很高的。</li>
</ol>
<h4 id="MySQL-5-6版本的并行复制策略"><a href="#MySQL-5-6版本的并行复制策略" class="headerlink" title="MySQL 5.6版本的并行复制策略"></a>MySQL 5.6版本的并行复制策略</h4><p>官方MySQL5.6版本， 支持了并行复制， 只是支持的粒度是按库并行。  </p>
<p>决定分发策略的hash表里， key就是数据库名 。</p>
<p>这个策略的并行效果， 取决于压力模型。 如果在主库上有多个DB， 并且各个DB的压力均衡， 使用这个策略的效果会很好。  </p>
<p>相比于按表和按行分发， 这个策略有两个优势：</p>
<ol>
<li>构造hash值的时候很快， 只需要库名； 而且一个实例上DB数也不会很多， 不会出现需要构造100万个项这种情况。</li>
<li>不要求binlog的格式。 因为statement格式的binlog也可以很容易拿到库名。</li>
</ol>
<h4 id="MariaDB的并行复制策略"><a href="#MariaDB的并行复制策略" class="headerlink" title="MariaDB的并行复制策略"></a>MariaDB的并行复制策略</h4><p>MariaDB的并行复制策略利用的是redo log组提交(group commit)优化特性：</p>
<ol>
<li>能够在同一组里提交的事务， 一定不会修改同一行；</li>
<li>主库上可以并行执行的事务， 备库上也一定是可以并行执行的。</li>
</ol>
<p>在实现上， MariaDB是这么做的：  </p>
<ol>
<li>在一组里面一起提交的事务， 有一个相同的commit_id， 下一组就是commit_id+1；</li>
<li>commit_id直接写到binlog里面；</li>
<li>传到备库应用的时候， 相同commit_id的事务分发到多个worker执行；</li>
<li>这一组全部执行完成后， coordinator再去取下一批</li>
</ol>
<p>但是， 这个策略有一个问题， 它并没有实现“真正的模拟主库并发度”这个目标。 在主库上， 一组事务在commit的时候， 下一组事务是同时处于“执行中”状态的。  </p>
<p>主库并行事务：</p>
<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20221208113254.png" style="width: 50%;" />

<p>备库并行复制：</p>
<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20230207192603.png" alt="image-20230207192603388" style="zoom:50%;" />

<p>在备库上执行的时候， 要等第一组事务完全执行完成提交后， 第二组事务才能开始执行，这样系统的吞吐量就不够。  </p>
<p>另外， 这个方案很容易被大事务拖后腿。 假设trx2是一个超大事务， 那么在备库应用的时候， trx1和trx3执行完成后， 就只能等trx2完全执行完成， 下一组才能开始执行。 这段时间， 只有一个worker线程在工作， 是对资源的浪费。  </p>
<h4 id="MySQL-5-7的并行复制策略"><a href="#MySQL-5-7的并行复制策略" class="headerlink" title="MySQL 5.7的并行复制策略"></a>MySQL 5.7的并行复制策略</h4><p>在MariaDB并行复制实现之后， 官方的MySQL5.7版本也提供了类似的功能， 由参数slaveparallel-type来控制并行复制策略：</p>
<ol>
<li>配置为DATABASE， 表示使用MySQL 5.6版本的按库并行策略；</li>
<li>配置为 LOGICAL_CLOCK， 表示的就是类似MariaDB的策略。 不过， MySQL 5.7这个策略， 针对并行度做了优化。 这个优化的思路也很有趣儿。</li>
</ol>
<p>MySQL 5.7并行复制策略的思想是：</p>
<ol>
<li>同时处于prepare状态的事务， 在备库执行时是可以并行的；</li>
<li>处于prepare状态的事务， 与处于commit状态的事务之间， 在备库执行时也是可以并行的。</li>
</ol>
<p>binlog_group_commit_sync_delay参数， 表示延迟多少微秒后才调用fsync;<br>binlog_group_commit_sync_no_delay_count参数， 表示累积多少次以后才调用fsync。<br>这两个参数是用于故意拉长binlog从write到fsync的时间， 以此减少binlog的写盘次数。 在MySQL5.7的并行复制策略里， 它们可以用来制造更多的“同时处于prepare阶段的事务”。 这样就增加了备库复制的并行度。<br><strong>也就是说， 这两个参数， 既可以“故意”让主库提交得慢些， 又可以让备库执行得快些。 在MySQL5.7处理备库延迟的时候， 可以考虑调整这两个参数值， 来达到提升备库复制并发度的目的。</strong>  </p>
<h4 id="MySQL-5-7-22的并行复制策略"><a href="#MySQL-5-7-22的并行复制策略" class="headerlink" title="MySQL 5.7.22的并行复制策略"></a>MySQL 5.7.22的并行复制策略</h4><p>在2018年4月份发布的MySQL 5.7.22版本里， MySQL增加了一个新的并行复制策略， 基于WRITESET的并行复制。<br>相应地， 新增了一个参数binlog-transaction-dependency-tracking（**SHOW VARIABLES LIKE ‘binlog_transaction_dependency_tracking’;**）， 用来控制是否启用这个新策略。 这个参数的可选值有以下三种。  </p>
<ol>
<li>COMMIT_ORDER， 表示的就是前面介绍的， 根据同时进入prepare和commit来判断是否可以并行的策略。</li>
<li>WRITESET， 表示的是对于事务涉及更新的每一行， 计算出这一行的hash值， 组成集合writeset。 如果两个事务没有操作相同的行， 也就是说它们的writeset没有交集， 就可以并行。</li>
<li>WRITESET_SESSION， 是在WRITESET的基础上多了一个约束， 即在主库上同一个线程先后执行的两个事务， 在备库执行的时候， 要保证相同的先后顺序。</li>
</ol>
<p>为了唯一标识， 这个hash值是通过“库名+表名+索引名+值”计算出来的。 如果一个表上除了有主键索引外， 还有其他唯一索引， 那么对于每个唯一索引， insert语句对应的writeset就要多增加一个hash值。</p>
<p>这跟我们前面介绍的基于MySQL 5.5版本的按行分发的策略是差不多的。 不过， MySQL官方的这个实现还是有很大的优势：  </p>
<ol>
<li>writeset是在主库生成后直接写入到binlog里面的， 这样在备库执行的时候， 不需要解析binlog内容（event里的行数据） ， 节省了很多计算量；</li>
<li>不需要把整个事务的binlog都扫一遍才能决定分发到哪个worker， 更省内存；</li>
<li>由于备库的分发策略不依赖于binlog内容， 所以binlog是statement格式也是可以的。</li>
</ol>
<p>因此， MySQL 5.7.22的并行复制策略在通用性上还是有保证的。<br>当然， 对于“表上没主键”和“外键约束”的场景， WRITESET策略也是没法并行的， 也会暂时退化为单线程模型。</p>
<h2 id="一主多从"><a href="#一主多从" class="headerlink" title="一主多从"></a>一主多从</h2><p>一主多从结构：</p>
<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20221212110828.png" style="width: 60%;" />

<p>主备切换后结构：</p>
<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20221212112106.png" style="width: 60%;" />

<p>虚线箭头表示的是主备关系， 也就是A和A’互为主备， 从库B、 C、 D指向的是主库A。 一主多从的设置， 一般用于读写分离， 主库负责所有的写入和一部分读， 其他的读请求则由从库分担。</p>
<h3 id="一主多从的主备切换过程"><a href="#一主多从的主备切换过程" class="headerlink" title="一主多从的主备切换过程"></a>一主多从的主备切换过程</h3><h4 id="基于位点的主备切换"><a href="#基于位点的主备切换" class="headerlink" title="基于位点的主备切换"></a>基于位点的主备切换</h4><p>把节点B设置成节点A’的从库的时候， 需要执行一条change master命令：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">CHANGE MASTER <span class="keyword">TO</span></span><br><span class="line">MASTER_HOST<span class="operator">=</span>$host_name</span><br><span class="line">MASTER_PORT<span class="operator">=</span>$port</span><br><span class="line">MASTER_USER<span class="operator">=</span>$user_name</span><br><span class="line">MASTER_PASSWORD<span class="operator">=</span>$password</span><br><span class="line">MASTER_LOG_FILE<span class="operator">=</span>$master_log_name</span><br><span class="line">MASTER_LOG_POS<span class="operator">=</span>$master_log_pos</span><br></pre></td></tr></table></figure>

<p>这条命令有这么6个参数：<br>MASTER_HOST、 MASTER_PORT、 MASTER_USER和MASTER_PASSWORD四个参数， 分别代表了主库A’的IP、 端口、 用户名和密码。<br>最后两个参数MASTER_LOG_FILE和MASTER_LOG_POS表示， 要从主库的master_log_name文件的master_log_pos这个位置的日志继续同步。 而这个位置就是我们所说的同步位点， 也就是主库对应的文件名和日志偏移量。  </p>
<p>原来节点B是A的从库， 本地记录的也是A的位点。 但是相同的日志， A的位点和A’的位点是不同的。 因此， 从库B要切换的时候， 就需要先经过“找同步位点”这个逻辑。  </p>
<p>考虑到切换过程中不能丢数据， 所以我们找位点的时候， 总是要找一个“稍微往前”的， 然后再通<br>过判断跳过那些在从库B上已经执行过的事务。<br><strong>一种取同步位点的方法是这样的：</strong></p>
<ol>
<li><p>等待新主库A’把中转日志（relaylog） 全部同步完成；</p>
</li>
<li><p>在A’上执行show master status命令， 得到当前A’上最新的File 和 Position；</p>
</li>
<li><p>取原主库A故障的时刻T；</p>
</li>
<li><p>用mysqlbinlog工具解析A’的File， 得到T时刻的位点。  </p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysqlbinlog File <span class="comment">--stop-datetime=T --start-datetime=T</span></span><br></pre></td></tr></table></figure></li>
</ol>
<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20221212113207.png" style="width: 80%;" />

<p>end_log_pos后面的值“123”， 表示的就是A’这个实例， 在T时刻写入新的binlog的位置。然后， 我们就可以把123这个值作为$master_log_pos ， 用在节点B的change master命令里。  </p>
<p>当然这个值并不精确。  有可能还会导致从库执行过的语句再次执行，会出现一些错误。</p>
<p>通常情况下， 我们在切换任务的时候， 要先主动跳过这些错误， 有两种常用的方法。</p>
<p><strong>一种做法是， 主动跳过一个事务。 跳过命令的写法是：</strong>  </p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">set</span> <span class="keyword">global</span> sql_slave_skip_counter<span class="operator">=</span><span class="number">1</span>;</span><br><span class="line"><span class="keyword">start</span> slave;   </span><br></pre></td></tr></table></figure>

<p> 因为切换过程中， 可能会不止重复执行一个事务， 所以我们需要在从库B刚开始接到新主库A’时， 持续观察， 每次碰到这些错误就停下来， 执行一次跳过命令， 直到不再出现停下来的情况， 以此来跳过可能涉及的所有事务。  </p>
<p><strong>另外一种方式是， 通过设置slave_skip_errors参数， 直接设置跳过指定的错误。</strong>  </p>
<p>在执行主备切换时， 有这么两类错误， 是经常会遇到的：</p>
<p>1.1062错误是插入数据时唯一键冲突；<br>2.1032错误是删除数据时找不到行。  </p>
<p>因此， 我们可以把slave_skip_errors 设置为 “1032,1062”， 这样中间碰到这两个错误时就直接跳过。</p>
<p><strong>这里需要注意的是， 这种直接跳过指定错误的方法， 针对的是主备切换时， 由于找不到精确的同步位点， 所以只能采用这种方法来创建从库和新主库的主备关系。</strong>  </p>
<h4 id="GTID"><a href="#GTID" class="headerlink" title="GTID"></a>GTID</h4><p><strong>MySQL 5.6版本引入了GTID， 彻底解决了基于位点的主备切换带来的重复执行的问题。</strong></p>
<p>GTID的全称是Global Transaction Identifier， 也就是全局事务ID， 是一个事务在提交的时候生成的， 是这个事务的唯一标识。 它由两部分组成， 格式是：  </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">GTID=server_uuid:gno </span><br></pre></td></tr></table></figure>

<p> 其中：<br>server_uuid是一个实例第一次启动时自动生成的， 是一个全局唯一的值；<br>gno是一个整数， 初始值是1， 每次提交事务的时候分配给这个事务， 并加1。  </p>
<p>在MySQL的官方文档里， GTID格式是这么定义的：  </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">GTID=source_id:transaction_id  </span><br></pre></td></tr></table></figure>

<p>这里的source_id就是server_uuid； 而后面的这个transaction_id， 我觉得容易造成误导， 所以我改成了gno。 为什么说使用transaction_id容易造成误解呢？<br>因为， 在MySQL里面我们说transaction_id就是指事务id， 事务id是在事务执行过程中分配的， 如果这个事务回滚了， 事务id也会递增， 而gno是在事务提交的时候才会分配。<br>从效果上看， GTID往往是连续的， 因此我们用gno来表示更容易理解。GTID模式的启动也很简单， 我们只需要在启动一个MySQL实例的时候， 加上参数gtid_mode&#x3D;on和enforce_gtid_consistency&#x3D;on就可以了。  </p>
<p>在GTID模式下， 每个事务都会跟一个GTID一一对应。 这个GTID有两种生成方式， 而使用哪种<br>方式取决于session变量gtid_next的值。</p>
<ol>
<li>如果gtid_next&#x3D;automatic， 代表使用默认值。 这时， MySQL就会把server_uuid:gno分配给这个事务。<br>a. 记录binlog的时候， 先记录一行 SET@@SESSION.GTID_NEXT&#x3D;‘server_uuid:gno’;<br>b. 把这个GTID加入本实例的GTID集合。</li>
<li>如果gtid_next是一个指定的GTID的值， 比如通过set gtid_next&#x3D;’current_gtid’指定为current_gtid， 那么就有两种可能：<br>a. 如果current_gtid已经存在于实例的GTID集合中， 接下来执行的这个事务会直接被系统忽略；<br>b. 如果current_gtid没有存在于实例的GTID集合中， 就将这个current_gtid分配给接下来要执行的事务， 也就是说系统不需要给这个事务生成新的GTID， 因此gno也不用加1。</li>
</ol>
<p>一个current_gtid只能给一个事务使用。 这个事务提交后， 如果要执行下一个事务， 就要执行set 命令， 把gtid_next设置成另外一个gtid或者automatic。这样， 每个MySQL实例都维护了一个GTID集合， 用来对应“这个实例执行过的所有事务”。  </p>
<h4 id="基于GTID的主备切换"><a href="#基于GTID的主备切换" class="headerlink" title="基于GTID的主备切换"></a>基于GTID的主备切换</h4><p>在GTID模式下， 备库B要设置为新主库A’的从库的语法如下：  </p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">CHANGE MASTER <span class="keyword">TO</span></span><br><span class="line">MASTER_HOST<span class="operator">=</span>$host_name</span><br><span class="line">MASTER_PORT<span class="operator">=</span>$port</span><br><span class="line">MASTER_USER<span class="operator">=</span>$user_name</span><br><span class="line">MASTER_PASSWORD<span class="operator">=</span>$password</span><br><span class="line">master_auto_position<span class="operator">=</span><span class="number">1</span></span><br></pre></td></tr></table></figure>

<p>其中， master_auto_position&#x3D;1就表示这个主备关系使用的是GTID协议。 可以看到， 前面让我们头疼不已的MASTER_LOG_FILE和MASTER_LOG_POS参数， 已经不需要指定了。  </p>
<p>我们把现在这个时刻， 实例A’的GTID集合记为set_a， 实例B的GTID集合记为set_b。 接下来，我们就看看现在的主备切换逻辑  </p>
<p><strong>我们在实例B上执行start slave命令， 取binlog的逻辑是这样的：</strong>  </p>
<ol>
<li>实例B指定主库A’， 基于主备协议建立连接。</li>
<li>实例B把set_b发给主库A’。</li>
<li>实例A’算出set_a与set_b的差集， 也就是所有存在于set_a， 但是不存在于set_b的GITD的集合， 判断A’本地是否包含了这个差集需要的所有binlog事务。<br>a. 如果不包含， 表示A’已经把实例B需要的binlog给删掉了， 直接返回错误；<br>b. 如果确认全部包含， A’从自己的binlog文件里面， 找出第一个不在set_b的事务， 发给B；</li>
<li>之后就从这个事务开始， 往后读文件， 按顺序取binlog发给B去执行。</li>
</ol>
<p><strong>其实， 这个逻辑里面包含了一个设计思想： 在基于GTID的主备关系里， 系统认为只要建立主备关系， 就必须保证主库发给备库的日志是完整的。 因此， 如果实例B需要的日志已经不存在， A’就拒绝把日志发给B</strong>  </p>
<p>这跟基于位点的主备协议不同。 基于位点的协议， 是由备库决定的， 备库指定哪个位点， 主库就发哪个位点， 不做日志的完整性判断。  </p>
<p><strong>引入GTID后， 一主多从的切换场景下， 主备切换是如何实现的：</strong></p>
<p>由于不需要找位点了， 所以从库B、 C、 D只需要分别执行change master命令指向实例A’即可。</p>
<p>其实， 严谨地说， 主备切换不是不需要找位点了， 而是找位点这个工作， 在实例A’内部就已经自动完成了。 但由于这个工作是自动的， 所以对HA系统的开发人员来说， 非常友好。</p>
<p>之后这个系统就由新主库A’写入， 主库A’的自己生成的binlog中的GTID集合格式是：server_uuid_of_A’:1-M。</p>
<p>如果之前从库B的GTID集合格式是 server_uuid_of_A:1-N， 那么切换之后GTID集合的格式就变成了server_uuid_of_A:1-N, server_uuid_of_A’:1-M。当然， 主库A’之前也是A的备库， 因此主库A’和从库B的GTID集合是一样的。 这就达到了我们预期 。</p>
<p><strong>如果你使用的MySQL版本支持GTID的话， 我都建议你尽量使用GTID模式来做一主多从的切换。</strong>  </p>
<h2 id="读写分离"><a href="#读写分离" class="headerlink" title="读写分离"></a>读写分离</h2><p>读写分离一般有两种模式，一种是client，一种是proxy 。</p>
<ol>
<li>客户端直连方案， 因为少了一层proxy转发， 所以查询性能稍微好一点儿， 并且整体架构简单， 排查问题更方便。 但是这种方案， 由于要了解后端部署细节， 所以在出现主备切换、 库迁移等操作的时候， 客户端都会感知到， 并且需要调整数据库连接信息。你可能会觉得这样客户端也太麻烦了， 信息大量冗余， 架构很丑。 其实也未必， 一般采用这样的架构， 一定会伴随一个负责管理后端的组件， 比如Zookeeper， 尽量让业务端只专注于业务逻辑开发。</li>
<li>带proxy的架构， 对客户端比较友好。 客户端不需要关注后端细节， 连接维护、 后端信息维护等工作， 都是由proxy完成的。 但这样的话， 对后端维护团队的要求会更高。 而且， proxy也需要有高可用架构。 因此， 带proxy架构的整体就相对比较复杂。</li>
</ol>
<p>由于主从可能存在延迟， 客户端执行完一个更新事务后马上发起查询， 如果查询选择的是从库的话， 就有可能读到刚刚的事务更新之前的状态。将这种查询结果称之为过期读。</p>
<p>一般解决过期读有以下方案：</p>
<ul>
<li>强制走主库方案；</li>
<li>sleep方案；</li>
<li>判断主备无延迟方案；</li>
<li>配合semi-sync方案；</li>
<li>等主库位点方案；</li>
<li>等GTID方案;</li>
</ul>
<h3 id="强制走主库方案"><a href="#强制走主库方案" class="headerlink" title="强制走主库方案"></a>强制走主库方案</h3><p>强制走主库方案其实就是， 将查询请求做分类。 通常情况下， 我们可以将查询请求分为这么两类：</p>
<ol>
<li>对于必须要拿到最新结果的请求， 强制将其发到主库上。 比如， 在一个交易平台上， 卖家发布商品以后， 马上要返回主页面， 看商品是否发布成功。 那么， 这个请求需要拿到最新的结果， 就必须走主库。</li>
<li>对于可以读到旧数据的请求， 才将其发到从库上。 在这个交易平台上， 买家来逛商铺页面，就算晚几秒看到最新发布的商品， 也是可以接受的。 那么， 这类请求就可以走从库。</li>
</ol>
<h3 id="Sleep-方案"><a href="#Sleep-方案" class="headerlink" title="Sleep 方案"></a>Sleep 方案</h3><p>主库更新后， 读从库之前先sleep一下。 具体的方案就是， 类似于执行一条select sleep(1)命令。<br>这个方案的假设是， 大多数情况下主备延迟在1秒之内， 做一个sleep可以有很大概率拿到最新的数据  </p>
<p>也可以直接用前端数据，比如卖家发布商品，确保发布请求是调用成功的前提下，在卖家查看商品信息时不调用接口，直接使用用户在客户端输入的内容。</p>
<p>这个sleep方案确实解决了类似场景下的过期读问题。 但， 从严格意义上来说， 这个方案存在的问题就是不精确。 这个不精确包含了两层意思：</p>
<ol>
<li>如果这个查询请求本来0.5秒就可以在从库上拿到正确结果， 也会等1秒；</li>
<li>如果延迟超过1秒， 还是会出现过期读。</li>
</ol>
<h3 id="判断主备无延迟方案"><a href="#判断主备无延迟方案" class="headerlink" title="判断主备无延迟方案"></a>判断主备无延迟方案</h3><p>第一种确保主备无延迟的方法是， 每次从库执行查询请求前， 先判断seconds_behind_master是否已经等于0。 如果还不等于0 ， 那就必须等到这个参数变为0才能执行查询请求。</p>
<p>第二种方法， 对比位点确保主备无延迟：</p>
<ul>
<li>Master_Log_File和Read_Master_Log_Pos， 表示的是读到的主库的最新位点；</li>
<li>Relay_Master_Log_File和Exec_Master_Log_Pos， 表示的是备库执行的最新位点。</li>
</ul>
<p>如果Master_Log_File和Relay_Master_Log_File、 Read_Master_Log_Pos和Exec_Master_Log_Pos这两组值完全相同， 就表示接收到的日志已经同步完成。  </p>
<p>第三种方法， 对比GTID集合确保主备无延迟：</p>
<ul>
<li>Auto_Position&#x3D;1 ， 表示这对主备关系使用了GTID协议。</li>
<li>Retrieved_Gtid_Set， 是备库收到的所有日志的GTID集合；</li>
<li>Executed_Gtid_Set， 是备库所有已经执行完成的GTID集合；</li>
</ul>
<p>如果这两个集合相同， 也表示备库接收到的日志都已经同步完成。  </p>
<p>但是这种方式还是会遗漏了客户端已经收到提交确认， 而备库还没收到日志的状态。</p>
<h3 id="配合semi-sync"><a href="#配合semi-sync" class="headerlink" title="配合semi-sync"></a>配合semi-sync</h3><p>要解决这个问题， 就要引入半同步复制， 也就是semi-sync replication。</p>
<p>semi-sync做了这样的设计：</p>
<ol>
<li>事务提交的时候， 主库把binlog发给从库；</li>
<li>从库收到binlog以后， 发回给主库一个ack， 表示收到了；</li>
<li>主库收到这个ack以后， 才能给客户端返回“事务完成”的确认。也就是说， 如果启用了semi-sync， 就表示所有给客户端发送过确认的事务， 都确保了备库已经收到了这个日志。</li>
</ol>
<p>也就是说， 如果启用了semi-sync， 就表示所有给客户端发送过确认的事务， 都确保了备库已经收到了这个日志。  </p>
<p><strong>但是， semi-sync+位点判断的方案， 只对一主一备的场景是成立的。</strong>     </p>
<p>在一主多从场景中， 主库只要等到一个从库的ack， 就开始给客户端返回确认。 这时， 在从库上执行查询请求， 就有两种情况：</p>
<ol>
<li>如果查询是落在这个响应了ack的从库上， 是能够确保读到最新数据；</li>
<li>但如果是查询落到其他从库上， 它们可能还没有收到最新的日志， 就会产生过期读的问题。</li>
</ol>
<p>其实， 判断同步位点的方案还有另外一个潜在的问题， 即： 如果在业务更新的高峰期， 主库的位点或者GTID集合更新很快， 那么上面的两个位点等值判断就会一直不成立， 很可能出现从库上迟迟无法响应查询请求的情况。  </p>
<p>semi-sync配合判断主备无延迟的方案， 存在两个问题：</p>
<ol>
<li>一主多从的时候， 在某些从库执行查询请求会存在过期读的现象；</li>
<li>在持续延迟的情况下， 可能出现过度等待的问题。</li>
</ol>
<p>等主库位点方案， 就可以解决这两个问题。  </p>
<h3 id="等主库位点方案"><a href="#等主库位点方案" class="headerlink" title="等主库位点方案"></a>等主库位点方案</h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> master_pos_wait(file, pos[, timeout]);  </span><br></pre></td></tr></table></figure>

<p>这条命令的逻辑如下：</p>
<ol>
<li>它是在从库执行的；</li>
<li>参数file和pos指的是主库上的文件名和位置；</li>
<li>timeout可选， 设置为正整数N表示这个函数最多等待N秒。</li>
</ol>
<p>这个命令正常返回的结果是一个正整数M， 表示从命令开始执行， 到应用完file和pos表示的binlog位置， 执行了多少事务。<br>当然， 除了正常返回一个正整数M外， 这条命令还会返回一些其他结果， 包括：</p>
<ol>
<li>如果执行期间， 备库同步线程发生异常， 则返回NULL；</li>
<li>如果等待超过N秒， 就返回-1；</li>
<li>如果刚开始执行的时候， 就发现已经执行过这个位置了， 则返回0。</li>
</ol>
<p>先执行trx1， 再执行一个查询请求的逻辑， 要保证能够查到正确的数据， 我们可以使用这个逻辑：</p>
<ol>
<li>trx1事务更新完成后， 马上执行show master status得到当前主库执行到的File和Position；</li>
<li>选定一个从库执行查询语句；</li>
<li>在从库上执行select master_pos_wait(File, Position, 1)；</li>
<li>如果返回值是&gt;&#x3D;0的正整数， 则在这个从库执行查询语句；</li>
<li>否则， 到主库执行查询语句。</li>
</ol>
<h3 id="GTID方案"><a href="#GTID方案" class="headerlink" title="GTID方案"></a>GTID方案</h3><p>如果你的数据库开启了GTID模式， 对应的也有等待GTID的方案。  </p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> wait_for_executed_gtid_set(gtid_set, <span class="number">1</span>);  </span><br></pre></td></tr></table></figure>

<p>这条命令的逻辑是：</p>
<ol>
<li>等待， 直到这个库执行的事务中包含传入的gtid_set， 返回0；</li>
<li>超时返回1。</li>
</ol>
<p>在前面等位点的方案中， 我们执行完事务后， 还要主动去主库执行show master status。 而MySQL 5.7.6版本开始， 允许在执行完更新类事务后， 把这个事务的GTID返回给客户端， 这样等GTID的方案就可以减少一次查询。<br>这时， 等GTID的执行流程就变成了：</p>
<ol>
<li>trx1事务更新完成后， 从返回包直接获取这个事务的GTID， 记为gtid1；</li>
<li>选定一个从库执行查询语句；</li>
<li>在从库上执行 select wait_for_executed_gtid_set(gtid1, 1)；</li>
<li>如果返回值是0， 则在这个从库执行查询语句</li>
<li>否则， 到主库执行查询语句</li>
</ol>
<p>问题是， 怎么能够让MySQL在执行事务后， 返回包中带上GTID呢？<br>你只需要将参数session_track_gtids设置为OWN_GTID， 然后通过API接口mysql_session_track_get_first从返回包解析出GTID的值即可。  </p>
<h2 id="数据库的可用性判断"><a href="#数据库的可用性判断" class="headerlink" title="数据库的可用性判断"></a>数据库的可用性判断</h2><h3 id="select-1判断"><a href="#select-1判断" class="headerlink" title="select 1判断"></a>select 1判断</h3><p>只能判断mysql在不在，不能判断是否可用。</p>
<p>innodb_thread_concurrency ：控制InnoDB的并发线程上限，一旦并发线程数达到这个值， InnoDB在接收到新请求的时候， 就会进入等待状态， 直到有线程退出。</p>
<p>在InnoDB中， innodb_thread_concurrency这个参数的默认值是0， 表示不限制并发线程数量。但是， 不限制并发线程数肯定是不行的。 因为， 一个机器的CPU核数有限， 线程全冲进来， 上下文切换的成本就会太高。  </p>
<p><strong>通常情况下， 我们建议把innodb_thread_concurrency设置为64~128之间的值。</strong> <strong>如果mysql在物理机上，这个参数的值一般为机器核数的2倍。</strong> </p>
<p>在线程进入锁等待以后， 并发线程的计数会减一， 也就是说等行锁（也包括间隙锁） 的线程是不算在128里面的。</p>
<p>在这个并发数满的情况下，使用select 1仍然能返回数据，会误判数据库是否可用。</p>
<h3 id="查表判断"><a href="#查表判断" class="headerlink" title="查表判断"></a>查表判断</h3><p>为了能够检测InnoDB并发线程数过多导致的系统不可用情况， 我们需要找一个访问InnoDB的场景。 一般的做法是， 在系统库（mysql库） 里创建一个表， 比如命名为health_check， 里面只放一行数据， 然后定期执行： </p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> mysql.health_check;  </span><br></pre></td></tr></table></figure>

<p>使用这个方法， 我们可以检测出由于并发线程过多导致的数据库不可用的情况。<br>但是， 我们马上还会碰到下一个问题， 即： 空间满了以后， 这种方法又会变得不好使。  </p>
<p><strong>更新事务要写binlog， 而一旦binlog所在磁盘的空间占用率达到100%， 那么所有的更新语句和事务提交的commit语句就都会被堵住。 但是， 系统这时候还是可以正常读数据的。</strong>  </p>
<h3 id="更新判断"><a href="#更新判断" class="headerlink" title="更新判断"></a>更新判断</h3><p>常见做法是放一个timestamp字段， 用来表示最后一次执行检测的时间。 这条更新语句类似于：  </p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">update</span> mysql.health_check <span class="keyword">set</span> t_modified<span class="operator">=</span>now();  </span><br></pre></td></tr></table></figure>

<p>节点可用性的检测都应该包含主库和备库。 如果用更新来检测主库的话， 那么备库也要进行更新检测。<br>但， 备库的检测也是要写binlog的。 由于我们一般会把数据库A和B的主备关系设计为双M结构，所以在备库B上执行的检测命令， 也要发回给主库A。<br>但是， 如果主库A和备库B都用相同的更新命令， 就可能出现行冲突， 也就是可能会导致主备同步停止。 所以， 现在看来mysql.health_check 这个表就不能只有一行数据了。  </p>
<p><strong>为了让主备之间的更新不产生冲突， 我们可以在mysql.health_check表上存入多行数据， 并用A、 B的server_id做主键。主库和备库更新自己所对应的行。</strong></p>
<p>虽然更新判断能判断数据库是否可用，但还是会有“判定慢”的问题。</p>
<p>首先， 所有的检测逻辑都需要一个超时时间N。 执行一条update语句， 超过N秒后还不返回， 就认为系统不可用。<br>你可以设想一个日志盘的IO利用率已经是100%的场景。 这时候， 整个系统响应非常慢， 已经需要做主备切换了。<br>但是你要知道， IO利用率100%表示系统的IO是在工作的， 每个请求都有机会获得IO资源， 执行自己的任务。 而我们的检测使用的update命令， 需要的资源很少， 所以可能在拿到IO资源的时候就可以提交成功， 并且在超时时间N秒未到达之前就返回给了检测系统。<br>检测系统一看， update命令没有超时， 于是就得到了“系统正常”的结论。  其实系统已经执行的非常慢了。</p>
<h3 id="内部统计"><a href="#内部统计" class="headerlink" title="内部统计"></a>内部统计</h3><p>MySQL 5.6版本以后提供的performance_schema库， 就在file_summary_by_event_name表里统计了每次IO请求的时间。  </p>
<p>file_summary_by_event_name表里有很多行数据， 我们先来看看event_name&#x3D;’wait&#x2F;io&#x2F;file&#x2F;innodb&#x2F;innodb_log_file’这一行。  </p>
<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20221212191040.png" style="width: 80%;" />

<p>图中这一行表示统计的是redo log的写入时间， 第一列EVENT_NAME 表示统计的类型。<br>接下来的三组数据， 显示的是redo log操作的时间统计。<br>第一组五列， 是所有IO类型的统计。 其中， COUNT_STAR是所有IO的总次数， 接下来四列是具体的统计项， 单位是皮秒（<em>1 秒 &#x3D; 1 万亿皮秒</em>）； 前缀SUM、 MIN、 AVG、 MAX， 顾名思义指的就是总和、 最小值、平均值和最大值。<br>第二组六列， 是读操作的统计。 最后一列SUM_NUMBER_OF_BYTES_READ统计的是， 总共从redo log里读了多少个字节。<br>第三组六列， 统计的是写操作。最后的第四组数据， 是对其他类型数据的统计。 在redo log里， 你可以认为它们就是对fsync的统<br>计。<br>在performance_schema库的file_summary_by_event_name表里， binlog对应的是event_name &#x3D;”wait&#x2F;io&#x2F;file&#x2F;sql&#x2F;binlog”这一行。 各个字段的统计逻辑， 与redo log的各个字段完全相同。   </p>
<p>因为我们每一次操作数据库， performance_schema都需要额外地统计这些信息， 所以我们打开这个统计功能是有性能损耗的。<br>我的测试结果是， <strong>如果打开所有的performance_schema项， 性能大概会下降10%左右。</strong> 所以，我建议你只打开自己需要的项进行统计。</p>
<h2 id="数据恢复"><a href="#数据恢复" class="headerlink" title="数据恢复"></a>数据恢复</h2><p>误删数据一般来说有以下分类：</p>
<ol>
<li>使用delete语句误删数据行；</li>
<li>使用drop table或者truncate table语句误删数据表；</li>
<li>使用drop database语句误删数据库；</li>
<li>使用rm命令误删整个MySQL实例。</li>
</ol>
<h3 id="误删行"><a href="#误删行" class="headerlink" title="误删行"></a>误删行</h3><p>如果是使用delete语句误删了数据行， 可以用Flashback工具通过闪回把数据恢复回来 。</p>
<p>Flashback恢复数据的原理， 是修改binlog的内容， 拿回原库重放。 <strong>而能够使用这个方案的前提是， 需要确保binlog_format&#x3D;row和 binlog_row_image&#x3D;FULL。</strong>  </p>
<p>具体恢复数据时， 对单个事务做如下处理：</p>
<ol>
<li>对于insert语句， 对应的binlog event类型是Write_rows event， 把它改成Delete_rows event即可；</li>
<li>同理， 对于delete语句， 也是将Delete_rows event改为Write_rows event；</li>
<li>而如果是Update_rows的话， binlog里面记录了数据行修改前和修改后的值， 对调这两行的<br>位置即可。</li>
</ol>
<p><strong>如果误删数据涉及到了多个事务的话， 需要将事务的顺序调过来再执行。</strong>  </p>
<p>比如</p>
<p>(A)delete …<br>(B)insert …<br>(C)update …  </p>
<p>则需要对调成</p>
<p>(reverse C)update …<br>(reverse B)delete …<br>(reverse A)insert …  </p>
<p>恢复数据不建议直接在主库上做。</p>
<p>恢复数据比较安全的做法， 是恢复出一个备份， 或者找一个从库作为临时库， 在这个临时库上执行这些操作， 然后再将确认过的临时库的数据， 恢复回主库 。</p>
<p><strong>防止误删预防</strong>：</p>
<ol>
<li>把sql_safe_updates参数设置为on。 这样一来， 如果我们忘记在delete或者update语句中写where条件， 或者where条件里面没有包含索引字段的话， 这条语句的执行就会报错。</li>
<li>代码上线前， 必须经过SQL审计。</li>
</ol>
<p>如果需要删除全表数据，带条件可用where id&gt;0。但是delete全表是很慢的， 需要生成回滚日志、 写redo、 写binlog。 所以， 从性能角度考虑，你应该优先考虑使用truncate table或者drop table命令。  </p>
<p><em><em>使用truncate &#x2F;drop table和drop database命令删除的数据， 就没办法通过Flashback来恢复了。 为什么呢？</em><br>这是因为， 即使我们配置了binlog_format&#x3D;row， 执行这三个命令时， 记录的binlog还是statement格式。 binlog里面就只有一个truncate&#x2F;drop 语句， 这些信息是恢复不出数据的。</em>*</p>
<h3 id="误删库-x2F-表"><a href="#误删库-x2F-表" class="headerlink" title="误删库&#x2F;表"></a>误删库&#x2F;表</h3><p>这种情况下， 要想恢复数据， 就需要使用全量备份， 加增量日志的方式了。 这个方案要求线上有定期的全量备份， 并且实时备份binlog  。</p>
<p>在这两个条件都具备的情况下， 假如有人中午12点误删了一个库， 恢复数据的流程如下：</p>
<ol>
<li>取最近一次全量备份， 假设这个库是一天一备， 上次备份是当天0点；</li>
<li>用备份恢复出一个临时库；</li>
<li>从日志备份里面， 取出凌晨0点之后的日志；</li>
<li>把这些日志， 除了误删除数据的语句外， 全部应用到临时库。</li>
</ol>
<p>关于这个过程， 我需要和你说明如下几点：</p>
<ol>
<li>为了加速数据恢复， 如果这个临时库上有多个数据库， 你可以在使用mysqlbinlog命令时， 加上一个–database参数， 用来指定误删表所在的库。 这样， 就避免了在恢复数据时还要应用其他库日志的情况 </li>
<li>在应用日志的时候， 需要跳过12点误操作的那个语句的binlog：<ul>
<li>如果原实例没有使用GTID模式， 只能在应用到包含12点的binlog文件的时候， 先用–stop-position参数执行到误操作之前的日志， 然后再用–start-position从误操作之后的日志继续执行；</li>
<li>如果实例使用了GTID模式， 就方便多了。 假设误操作命令的GTID是gtid1， 那么只需要执行set gtid_next&#x3D;gtid1;begin;commit; 先把这个GTID加到临时实例的GTID集合， 之后按顺序执行binlog的时候， 就会自动跳过误操作的语句。</li>
</ul>
</li>
</ol>
<p>不过， 即使这样， 使用mysqlbinlog方法恢复数据还是不够快， 主要原因有两个：</p>
<ol>
<li>如果是误删表， 最好就是只恢复出这张表， 也就是只重放这张表的操作， 但是mysqlbinlog工具并不能指定只解析一个表的日志；</li>
<li>用mysqlbinlog解析出日志应用， 应用日志的过程就只能是单线程。</li>
</ol>
<p><strong>一种加速的方法是</strong>， 在用备份恢复出临时实例之后， 将这个临时实例设置成线上备库的从库，<br>这样：</p>
<ol>
<li>在start slave之前， 先通过执行change replication filter replicate_do_table &#x3D; (tbl_name) 命令， 就可以让临时库只同步误操<br>作的表；</li>
<li>这样做也可以用上并行复制技术， 来加速整个数据恢复过程。</li>
</ol>
<h4 id="延迟复制备库"><a href="#延迟复制备库" class="headerlink" title="延迟复制备库"></a>延迟复制备库</h4><p>虽然我们可以通过利用并行复制来加速恢复数据的过程， 但是这个方案仍然存在“恢复时间不可控”的问题。  </p>
<p>那么， 我们有什么方法可以缩短恢复数据需要的时间呢？  </p>
<p>如果有非常核心的业务， 不允许太长的恢复时间， 我们可以考虑搭建延迟复制的备库。 这个功能是MySQL 5.6版本引入的。  </p>
<p>一般的主备复制结构存在的问题是， 如果主库上有个表被误删了， 这个命令很快也会被发给所有从库， 进而导致所有从库的数据表也都一起被误删了。<br>延迟复制的备库是一种特殊的备库， 通过 CHANGE MASTER TO MASTER_DELAY &#x3D; N命令，可以指定这个备库持续保持跟主库有N秒的延迟。<br>比如你把N设置为3600， 这就代表了如果主库上有数据被误删了， 并且在1小时内发现了这个误操作命令， 这个命令就还没有在这个延迟复制的备库执行。 这时候到这个备库上执行stop slave， 再通过之前介绍的方法， 跳过误操作命令， 就可以恢复出需要的数据。<br>这样的话， 你就随时可以得到一个， 只需要最多再追1小时， 就可以恢复出数据的临时实例， 也就缩短了整个数据恢复需要的时间  </p>
<h4 id="预防误删库-x2F-表的方法"><a href="#预防误删库-x2F-表的方法" class="headerlink" title="预防误删库&#x2F;表的方法"></a>预防误删库&#x2F;表的方法</h4><p>第一条建议是， 账号分离。 这样做的目的是， 避免写错命令。 比如：</p>
<ul>
<li>我们只给业务开发同学DML权限， 而不给truncate&#x2F;drop权限。 而如果业务开发人员有DDL需求的话， 也可以通过开发管理系统得到支持。</li>
<li>即使是DBA团队成员， 日常也都规定只使用只读账号， 必要的时候才使用有更新权限的账号。</li>
</ul>
<p>第二条建议是， 制定操作规范。 这样做的目的， 是避免写错要删除的表名。 比如：</p>
<ul>
<li>在删除数据表之前， 必须先对表做改名操作。 然后， 观察一段时间， 确保对业务无影响以后再删除这张表。</li>
<li>改表名的时候， 要求给表名加固定的后缀（比如加_to_be_deleted)， 然后删除表的动作必须通过管理系统执行。 并且， 管理系删除表的时候， 只能删除固定后缀的表</li>
</ul>
<h3 id="rm删除数据"><a href="#rm删除数据" class="headerlink" title="rm删除数据"></a>rm删除数据</h3><p>其实， 对于一个有高可用机制的MySQL集群来说， 最不怕的就是rm删除数据了。 只要不是恶意地把整个集群删除， 而只是删掉了其中某一个节点的数据的话， HA系统就会开始工作， 选出一个新的主库， 从而保证整个集群的正常工作。<br>这时， 你要做的就是在这个节点上把数据恢复回来， 再接入整个集群。  </p>
<h2 id="MySQL里的Kill"><a href="#MySQL里的Kill" class="headerlink" title="MySQL里的Kill"></a>MySQL里的Kill</h2><p>在MySQL中有两个kill命令： </p>
<p>一个是kill query+线程id， 表示终止这个线程中正在执行的语句；</p>
<p>一个是kill connection +线程id， 这里connection可缺省， 表示断开这个线程的连接， 当然如果这个线程有语句正在执行， 也是要先停止正在执行的语句的。  </p>
<p>大多数情况下kill query&#x2F;connection命令是有效的。 比如， 执行一个查询的过程中， 发现执行时间太久， 要放弃继续查询， 这时我们就可以用kill query命令， 终止这条查询语句。<br>还有一种情况是， 语句处于锁等待的时候， 直接使用kill命令也是有效的。   </p>
<h3 id="收到kill以后，-线程做什么？"><a href="#收到kill以后，-线程做什么？" class="headerlink" title="收到kill以后， 线程做什么？"></a>收到kill以后， 线程做什么？</h3><p>当对一个表做增删改查操作时， 会在表上加MDL读锁。 所以， 哪怕语句在等待锁处于blocked状态， 但还是拿着一个MDL读锁的。 如果线程被kill的时候， 就直接终止， 那之后这个MDL读锁就没机会被释放了。<br>这样看来， kill并不是马上停止的意思， 而是告诉执行线程说， 这条语句已经不需要继续执行了，可以开始“执行停止的逻辑了”  （与linux的kill -15 pid类似，并不是马上停止进程，而只是给进程发送一个终止信号，进入终止逻辑）</p>
<p><strong>实现上， 当用户执行kill query thread_id_B时， MySQL里处理kill命令的线程做了两件事：</strong>  </p>
<ol>
<li>把id_B运行状态改成THD::KILL_QUERY(将变量killed赋值为THD::KILL_QUERY)；</li>
<li>给id_B的执行线程发一个信号。</li>
</ol>
<p>为什么要发信号呢？<br>因为当语句处于blocked状态的时候， 如果只是把线程状态设置THD::KILL_QUERY， 线程并不知道这个状态变化， 还是会继续等待。 发一个信号的目的， 就是让线程退出等待， 来处理这个THD::KILL_QUERY状态。  </p>
<p>上面的分析中， 隐含了这么三层意思：</p>
<ol>
<li>一个语句执行过程中有多处“埋点”， 在这些“埋点”的地方判断线程状态， 如果发现线程状态是THD::KILL_QUERY， 才开始进入语句终止逻辑；</li>
<li>如果处于等待状态， 必须是一个可以被唤醒的等待， 否则根本不会执行到“埋点”处；</li>
<li>语句从开始进入终止逻辑， 到终止逻辑完全完成， 是有一个过程的。</li>
</ol>
<p><strong>kill命令有时候也会无效：</strong></p>
<p>1.线程没有执行到判断线程状态的逻辑 ,跟这种情况相同的， 还有由于IO压力过大， 读写IO的函数一直无法返回， 导致不能及时判断线程的状态。  </p>
<p>2.终止逻辑耗时较长。 这时候， 从show processlist结果上看也是Command&#x3D;Killed， 需要等到终止逻辑完成， 语句才算真正完成。 这类情况， 比较常见的场景有以下几种：  </p>
<ul>
<li>超大事务执行期间被kill。 这时候， 回滚操作需要对事务执行期间生成的所有新数据版本做回收操作， 耗时很长  </li>
<li>大查询回滚。 如果查询过程中生成了比较大的临时文件， 加上此时文件系统压力大， 删除临时文件可能需要等待IO资源， 导致耗时较长  </li>
<li>DDL命令执行到最后阶段， 如果被kill， 需要删除中间过程的临时文件， 也可能受IO资源影响耗时较久</li>
</ul>
<h3 id="关于客户端的误解"><a href="#关于客户端的误解" class="headerlink" title="关于客户端的误解"></a>关于客户端的误解</h3><p><strong>1.如果直接在客户端通过Ctrl+C命令， 是不是就可以直接终止线程呢？</strong>  </p>
<p>不可以。  这里有一个误解， 其实在客户端的操作只能操作到客户端的线程， 客户端和服务端只能通过网络交互， 是不可能直接操作服务端线程的。  </p>
<p>而由于MySQL是停等协议， 所以这个线程执行的语句还没有返回的时候， 再往这个连接里面继续发命令也是没有用的。 实际上， 执行Ctrl+C的时候， 是MySQL客户端另外启动一个连接， 然后发送一个kill query命令。<br>所以， 你可别以为在客户端执行完Ctrl+C就万事大吉了。 因为， 要kill掉一个线程， 还涉及到后端的很多操作  </p>
<p><strong>2.如果库里面的表特别多， 连接就会很慢。</strong>  </p>
<p>比如使用命令：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql -h127.0.0.1 -uu1 -pp1 db1</span><br></pre></td></tr></table></figure>

<p>当db1里的表特别多时，会一直卡在连接界面。</p>
<p>其实当使用默认参数连接的时候， MySQL客户端会提供一个本地库名和表名补全的功能。 为了实现这个功能， 客户端在连接成功后， 需要多做一些操作：</p>
<ol>
<li>执行show databases；</li>
<li>切到db1库， 执行show tables；</li>
<li>把这两个命令的结果用于构建一个本地的哈希表。</li>
</ol>
<p><strong>在这些操作中， 最花时间的就是第三步在本地构建哈希表的操作。 所以， 当一个库中的表个数非常多的时候， 这一步就会花比较长的时间。  也就是说我们感知到的连接过程慢， 其实并不是连接慢， 也不是服务端慢， 而是客户端慢。</strong>  </p>
<p><strong>在mysql连接串里加入-A，可以关闭该功能，使得连接变快。</strong></p>
<p>除了加-A以外， 加–quick(或者简写为-q)参数， 也可以跳过这个阶段。 但是， <strong>这个–quick是一个更容易引起误会的参数， 也是关于客户端常见的一个误解。</strong>  </p>
<p><strong>3.–quick参数 其实是加速客户端并不是加速服务端，该参数有以下三个作用：</strong></p>
<ul>
<li>跳过自动补全功能</li>
<li>关闭本地内存缓存查询结果功能</li>
<li>不会把执行命令记录到本地的命令历史文件</li>
</ul>
<h2 id="全表扫描的影响"><a href="#全表扫描的影响" class="headerlink" title="全表扫描的影响"></a>全表扫描的影响</h2><h3 id="全表扫描对server层的影响"><a href="#全表扫描对server层的影响" class="headerlink" title="全表扫描对server层的影响"></a>全表扫描对server层的影响</h3><p>MySQL服务端对查询到的结果集，并不需要完整保存。</p>
<p>取数据和发数据的流程是这样的：  </p>
<ol>
<li>获取一行， 写到net_buffer中。 这块内存的大小是由参数net_buffer_length定义的， 默认是16k。</li>
<li>重复获取行， 直到net_buffer写满， 调用网络接口发出去。</li>
<li>如果发送成功， 就清空net_buffer， 然后继续取下一行， 并写入net_buffer。</li>
<li>如果发送函数返回EAGAIN或WSAEWOULDBLOCK， 就表示本地网络栈（socket send buffer） 写满了， 进入等待。 直到网络栈重新可写， 再继续发送。</li>
</ol>
<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20230103203554.png" style="width: 80%;" />

<p>从这个流程中， 你可以看到：</p>
<ol>
<li>一个查询在发送过程中， 占用的MySQL内部的内存最大就是net_buffer_length这么大， 并不会达到200G；</li>
<li>socket send buffer 也不可能达到200G（默认定义&#x2F;proc&#x2F;sys&#x2F;net&#x2F;core&#x2F;wmem_default） ， 如果socket send buffer被写满， 就会暂停读数据的流程。</li>
</ol>
<p><strong>也就是说， MySQL是“边读边发的”，</strong> 这个概念很重要。 这就意味着， <strong>如果客户端接收得慢， 会导致MySQL服务端由于结果发不出去， 这个事务的执行时间变长。</strong>  </p>
<p><strong>查询的结果是分段发给客户端的， 因此扫描全表， 查询返回大量的数据， 并不会把内存打爆。</strong>  </p>
<h3 id="全表扫描对InnoDB的影响"><a href="#全表扫描对InnoDB的影响" class="headerlink" title="全表扫描对InnoDB的影响"></a>全表扫描对InnoDB的影响</h3><p>InnoDB内存的一个作用， 是保存更新的结果， 再配合redo log， 就避免了随机写盘。<br>内存的数据页是在Buffer Pool (BP)中管理的， 在WAL里Buffer Pool 起到了加速更新的作用。 而实际上， Buffer Pool 还有一个更重要的作用， 就是加速查询：<strong>因为当数据在Buffer Pool中时，如果有查询需要返回该数据页，则可以直接从内存拿结果，不需要访问磁盘。</strong></p>
<p>Buffer Pool对查询的加速效果， 依赖于一个重要的指标， 即： 内存命中率。  </p>
<p><strong>可以使用show engine innodb status 命令查看内存命中率。其中的Buffer pool hit rate项，显示的就是当前的内存命中率。</strong></p>
<p><strong>InnoDB Buffer Pool的大小是由参数 innodb_buffer_pool_size确定的， 一般建议设置成可用物理内存的60%~80%。</strong>  </p>
<p>一般机器的内存都是小于磁盘空间，因此innodb_buffer_pool_size小于磁盘的数据量是很常见的。 如果一个 Buffer Pool满了， 而又要从磁盘读入一个数据页， 那肯定是要淘汰一个旧数据页的。<br>InnoDB内存管理用的是最近最少使用 (Least RecentlyUsed, LRU)算法， 这个算法的核心就是淘汰最久未使用的数据。</p>
<p><strong>InnoDB管理Buffer Pool的LRU算法， 是用链表来实现的。</strong>  </p>
<p>这个算法乍一看上去没什么问题， 但是如果考虑到要做一个全表扫描， 会不会有问题呢？<br>假设按照这个算法， 我们要扫描一个200G的表， 而这个表是一个历史数据表， 平时没有业务访问它。<br>那么， 按照这个算法扫描的话， 就会把当前的Buffer Pool里的数据全部淘汰掉， 存入扫描过程中访问到的数据页的内容。 也就是说Buffer Pool里面主要放的是这个历史数据表的数据。<br>对于一个正在做业务服务的库， 这可不妙。 你会看到， Buffer Pool的内存命中率急剧下降， 磁盘压力增加， SQL语句响应变慢。<br>所以， InnoDB不能直接使用这个LRU算法。 实际上， InnoDB对LRU算法做了改进。</p>
<p>InnoDB LRU算法示意图：</p>
<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20230104104208.png" style="width: 60%;" />

<p>在InnoDB实现上， 按照5:3的比例把整个LRU链表分成了young区域和old区域。 图中LRU_old指向的就是old区域的第一个位置， 是整个链表的5&#x2F;8处。 也就是说， 靠近链表头部的5&#x2F;8是young区域， 靠近链表尾部的3&#x2F;8是old区域。<br>改进后的LRU算法执行流程变成了下面这样。</p>
<ol>
<li><p>图中状态1， 要访问数据页P3， 由于P3在young区域， 因此和优化前的LRU算法一样， 将其移到链表头部， 变成状态2。</p>
</li>
<li><p>之后要访问一个新的不存在于当前链表的数据页， 这时候依然是淘汰掉数据页Pm， 但是新插入的数据页Px， 是放在LRU_old处。  </p>
</li>
<li><p>处于old区域的数据页， 每次被访问的时候都要做下面这个判断：</p>
<p>若这个数据页在LRU链表中存在的时间超过了1秒， 就把它移动到链表头部；<br>如果这个数据页在LRU链表中存在的时间短于1秒， 位置保持不变。 1秒这个时间， 是由参数innodb_old_blocks_time控制的。 其默认值是1000， 单位毫秒。</p>
</li>
</ol>
<p>这个策略， 就是为了处理类似全表扫描的操作量身定制的。 还是以刚刚的扫描200G的历史数据表为例， 我们看看改进后的LRU算法的操作逻辑：</p>
<ol>
<li>扫描过程中， 需要新插入的数据页， 都被放到old区域;</li>
<li>一个数据页里面有多条记录， 这个数据页会被多次访问到， 但由于是顺序扫描， 这个数据页第一次被访问和最后一次被访问的时间间隔不会超过1秒， 因此还是会被保留在old区域；</li>
<li>再继续扫描后续的数据， 之前的这个数据页之后也不会再被访问到， 于是始终没有机会移到链表头部（也就是young区域） ， 很快就会被淘汰出去。可以看到， 这个策略最大的收益， 就是在扫描这个大表的过程中， 虽然也用到了Buffer Pool， 但是对young区域完全没有影响， 从而保证了Buffer Pool响应正常业务的查询命中率。</li>
</ol>
<h2 id="Join的使用"><a href="#Join的使用" class="headerlink" title="Join的使用"></a>Join的使用</h2><p>假如有两张表：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">CREATE TABLE `t2` (</span><br><span class="line">`id` int(11) NOT NULL,</span><br><span class="line">`a` int(11) DEFAULT NULL,</span><br><span class="line">`b` int(11) DEFAULT NULL,</span><br><span class="line">PRIMARY KEY (`id`),</span><br><span class="line">KEY `a` (`a`)</span><br><span class="line">) ENGINE=InnoDB;</span><br><span class="line">create table t1 like t2;</span><br></pre></td></tr></table></figure>

<p>t1有100条数据，t2有1000条数据。</p>
<h3 id="Index-Nested-Loop-Join（NLJ）"><a href="#Index-Nested-Loop-Join（NLJ）" class="headerlink" title="Index Nested-Loop Join（NLJ）"></a>Index Nested-Loop Join（NLJ）</h3><p>如果直接使用join语句， MySQL优化器可能会选择表t1或t2作为驱动表。而使用straight_join可以让MySQL使用固定的连接方式执行查询  。例如以下语句，就是t1 是驱动表， t2是被驱动表。（驱动表是取该表的全量数据，拿出指定列，去被驱动表里关联查询）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">select * from t1 straight_join t2 on (t1.a=t2.a);</span><br></pre></td></tr></table></figure>

<p>对该语句执行explain，得到：</p>
<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20230104105149.png" style="width: 80%;" />

<p>在这条语句里， 被驱动表t2的字段a上有索引， join过程用上了这个索引， 因此这个语句的执行流程是这样的：</p>
<ol>
<li>从表t1中读入一行数据 R；</li>
<li>从数据行R中， 取出a字段到表t2里去查找；</li>
<li>取出表t2中满足条件的行， 跟R组成一行， 作为结果集的一部分；</li>
<li>重复执行步骤1到3， 直到表t1的末尾循环结束。</li>
</ol>
<p><strong>这个过程是先遍历表t1， 然后根据从表t1中取出的每行数据中的a值， 去表t2中查找满足条件的记录。 在形式上， 这个过程就跟我们写程序时的嵌套查询类似， 并且可以用上被驱动表的索引，所以我们称之为“IndexNested-Loop Join”， 简称NLJ。</strong>  </p>
<p>在这个流程里：</p>
<ol>
<li>对驱动表t1做了全表扫描， 这个过程需要扫描100行；</li>
<li>而对于每一行R， 根据a字段去表t2查找， 走的是树搜索过程。 由于我们构造的数据都是一一对应的， 因此每次的搜索过程都只扫描一行， 也是总共扫描100行；</li>
<li>所以， 整个执行流程， 总扫描行数是200。</li>
</ol>
<p><strong>在前提是“可以使用被驱动表的索引”的情况下：</strong></p>
<ol>
<li><strong>使用join语句， 性能比强行拆成多个单表执行SQL语句的性能要好；</strong></li>
<li><strong>如果使用join语句的话， 需要让小表做驱动表。</strong></li>
</ol>
<h3 id="Simple-Nested-Loop-Join"><a href="#Simple-Nested-Loop-Join" class="headerlink" title="Simple Nested-Loop Join"></a>Simple Nested-Loop Join</h3><p>假如有以下SQL：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">select * from t1 straight_join t2 on (t1.a=t2.b);</span><br></pre></td></tr></table></figure>

<p>在这种情况下，t2的b字段没有索引。如果还是使用上面的算法的话，每次拿到t1 a的值都要去t2表做一次全表扫描获取数据，因此就需要扫描t2表100次。</p>
<p>只看结果的话是对的，但是执行效率上不可描述。因此MySQL并没有采用这种算法。而是采用了Block Nested-Loop Join（简称BNL  ）。</p>
<h3 id="Block-Nested-Loop-Join（BNL）"><a href="#Block-Nested-Loop-Join（BNL）" class="headerlink" title="Block Nested-Loop Join（BNL）"></a>Block Nested-Loop Join（BNL）</h3><p>这时候， 被驱动表上没有可用的索引， 算法的流程是这样的：</p>
<ol>
<li>把表t1的数据读入线程内存join_buffer中， 由于我们这个语句中写的是select *， 因此是把整个表t1放入了内存；</li>
<li>扫描表t2， 把表t2中的每一行取出来， 跟join_buffer中的数据做对比， 满足join条件的， 作为结果集的一部分返回。</li>
</ol>
<p>执行流程图：</p>
<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20230104110822.png" alt="image-20230104110822838" style="zoom:60%;" />

<p>该语句对应的explain结果：</p>
<p><img src="C:/Users/ZhouHJ/AppData/Roaming/Typora/typora-user-images/image-20230104110957350.png" alt="image-20230104110957350"></p>
<p>在这个过程中， 对表t1和t2都做了一次全表扫描， 因此总的扫描行数是1100。 由于join_buffer是以无序数组的方式组织的， 因此对表t2中的每一行， 都要做100次判断， 总共需要在内存中做的判断次数是： 100*1000&#x3D;10万次。</p>
<p>如果使用Simple Nested-Loop Join算法进行查询， 扫描行数也是10万行。 因此， 从时间复杂度上来说， 这两个算法是一样的。 但是， Block Nested-Loop Join算法的这10万次判断是内存操作， 速度上会快很多， 性能也更好。  </p>
<p><strong>这种情况下驱动表无论是大表还是小表，时间复杂度都是一样的。</strong></p>
<p>这个例子里表t1才100行， 要是表t1是一个大表， join_buffer放不下怎么办呢？<br>join_buffer的大小是由参数join_buffer_size设定的， 默认值是256k。 如果放不下表t1的所有数据话， 策略很简单， 就是分段放。   </p>
<ol>
<li>先将join_buffer放满，然后去匹配内存中获取到的t2里的数据</li>
<li>将结果先存储到结果集</li>
<li>清空join_buffer</li>
<li>重复1,2,3的步骤直到t1的数据全部被处理完</li>
</ol>
<p>但是分段处理之后，虽然在内存中的判断次数还是一样的。但是需要扫描t2的次数变多了，因此分段数越少越好。这种情况下采用小表作为驱动表比较好，并且可以适当的调大join_buffer_size 大小，可以让每段存入更多的数据，让分段数减少。</p>
<h3 id="能不能使用join语句？"><a href="#能不能使用join语句？" class="headerlink" title="能不能使用join语句？"></a>能不能使用join语句？</h3><ol>
<li>如果可以使用IndexNested-Loop Join算法， 也就是说可以用上被驱动表上的索引， 其实是没问题的；</li>
<li>如果使用Block Nested-Loop Join算法， 扫描行数就会过多。 尤其是在大表上的join操作， 这样可能要扫描被驱动表很多次， 会占用大量的系统资源。 所以这种join尽量不要用</li>
</ol>
<p>在判断要不要使用join语句时， 就是看explain结果里面， Extra字段里面有没有出现“Block Nested Loop”字样。</p>
<h3 id="如果要使用join，-应该选择大表做驱动表还是选择小表做驱动表？"><a href="#如果要使用join，-应该选择大表做驱动表还是选择小表做驱动表？" class="headerlink" title="如果要使用join， 应该选择大表做驱动表还是选择小表做驱动表？"></a>如果要使用join， 应该选择大表做驱动表还是选择小表做驱动表？</h3><ol>
<li><strong>如果是IndexNested-Loop Join算法， 应该选择小表做驱动表；</strong></li>
<li><strong>如果是Block Nested-Loop Join算法：</strong><br><strong>在join_buffer_size足够大的时候， 是一样的；</strong><br><strong>在join_buffer_size不够大的时候（这种情况更常见） ， 应该选择小表做驱动表。</strong></li>
</ol>
<p><strong>总是应该使用小表做驱动表。</strong>  </p>
<p><strong>小表：在决定哪个表做驱动表的时候， 应该是两个表按照各自的条件过滤， 过滤完成之后， 计算参与join的各个字段的总数据量， 数据量小的那个表， 就是“小表”， 应该作为驱动表</strong>  </p>
<h2 id="Join的优化"><a href="#Join的优化" class="headerlink" title="Join的优化"></a>Join的优化</h2><p>假如有表t1、t2：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">create table t1(id int primary key, a int, b int, index(a));</span><br><span class="line">create table t2 like t1;</span><br></pre></td></tr></table></figure>

<p>t1里1000条数据，每一行的a&#x3D;1001-id的值。 也就是说， 表t1中字段a是逆序的。 表t2中插入了100万行数据。</p>
<h3 id="Multi-Range-Read优化"><a href="#Multi-Range-Read优化" class="headerlink" title="Multi-Range Read优化"></a>Multi-Range Read优化</h3><p>Multi-Range Read优化(MRR)。 这个优化的主要目的是尽量使用顺序读盘 。</p>
<p>比如有查询语句：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">select * from t1 where a&gt;=1 and a&lt;=1000;</span><br></pre></td></tr></table></figure>

<p>该语句使用了a索引，并且查询字段是全部，因此需要回表。如果按照a的顺序去查询到id后，直接回表的话，id的值变成了随机值，那么会出现磁盘的随机访问，性能相对较差。</p>
<p><strong>因为大多数的数据都是按照主键递增顺序插入得到的， 所以我们可以认为， 如果按照主键的递增顺序查询的话， 对磁盘的读比较接近顺序读， 能够提升读性能。</strong></p>
<p>这， 就是MRR优化的设计思路。 此时， 语句的执行流程变成了这样：  </p>
<ol>
<li>根据索引a， 定位到满足条件的记录， 将id值放入read_rnd_buffer中;</li>
<li>将read_rnd_buffer中的id进行递增排序；</li>
<li>排序后的id数组， 依次到主键id索引中查记录， 并作为结果返回。</li>
</ol>
<p><strong>这里， read_rnd_buffer的大小是由read_rnd_buffer_size参数控制的。</strong> <strong>如果步骤1中， read_rnd_buffer放满了， 就会先执行完步骤2和3， 然后清空read_rnd_buffer。 之后继续找索引a的下个记录， 并继续循环。</strong></p>
<p>如果你想要稳定地使用MRR优化的话， 需要设置set optimizer_switch&#x3D;”mrr_cost_based&#x3D;off”。 （官方文档的说法， 是现在的优化器策略， 判断消耗的时候， 会更倾向于不使用MRR， 把mrr_cost_based设置为off， 就是固定使用MRR了。 ）  </p>
<p>使用MRR后的查询流程图和explain的结果：</p>
<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20230105195230.png" alt="image-20230105195223538" style="zoom:50%;" />

<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20230105195309.png" alt="image-20230105195309607" style="zoom:70%;" />

<p>Extra字段多了Using MRR， 表示的是用上了MRR优化 。而且， 由于我们在read_rnd_buffer中按照id做了排序， 所以最后得到的结果集也是按照主键id递增顺序的。</p>
<p><strong>MRR能够提升性能的核心在于， 这条查询语句在索引a上做的是一个范围查询（也就是说， 这是一个多值查询） ， 可以得到足够多的主键id。 这样通过排序以后， 再去主键索引查数据， 才能体现出“顺序性”的优势。</strong></p>
<h3 id="Batched-Key-Access"><a href="#Batched-Key-Access" class="headerlink" title="Batched Key Access"></a>Batched Key Access</h3><p>MySQL在5.6版本后开始引入的Batched Key Acess(BKA)算法了。 这个BKA算法， 其实就是对NLJ算法的优化。  </p>
<p>NLJ算法执行的逻辑是： 从驱动表t1， 一行行地取出a的值， 再到被驱动表t2去做join。 也就是说， 对于表t2来说， 每次都是匹配一个值。 这时， MRR的优势就用不上了。  </p>
<p><strong>而从表t1里一次性地多拿些行出来， 一起传给表t2 ，这样就可以使用上MRR优化。将表t1的数据取出来一部分， 先放到一个临时内存。 这个临时内存不是别人，就是join_buffer。</strong>   </p>
<p>NLJ算法优化后的BKA算法的流程：</p>
<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20230105195947.png" alt="image-20230105195947715" style="zoom:50%;" />

<p>在join_buffer中放入的数据是P1<del>P100， 表示的是只会取查询需要的字段。 当然， 如果join buffer放不下P1</del>P100的所有数据， 就会把这100行数据分成多段执行上图的流程。  </p>
<p><strong>启用BKA算法：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">set</span> optimizer_switch<span class="operator">=</span><span class="string">&#x27;mrr=on,mrr_cost_based=off,batched_key_access=on&#x27;</span>;  </span><br></pre></td></tr></table></figure>

<p>前两个参数的作用是要启用MRR。 这么做的原因是， BKA算法的优化要依赖于MRR。  </p>
<h3 id="BNL算法的性能问题"><a href="#BNL算法的性能问题" class="headerlink" title="BNL算法的性能问题"></a>BNL算法的性能问题</h3><p>在采用BNL算法的join里，假如被驱动表是大表，且是冷数据表。会使得Buffer Pool在这段时间内， young区域的数据页没有被合理地淘汰。</p>
<p><strong>大表join操作虽然对IO有影响， 但是在语句执行结束后， 对IO的影响也就结束了。 但是，对Buffer Pool的影响就是持续性的， 需要依靠后续的查询请求慢慢恢复内存命中率。</strong>  </p>
<p>为了减少这种影响， 你可以考虑增大join_buffer_size的值， 减少对被驱动表的扫描次数。  </p>
<p><strong>BNL算法对系统的影响主要包括三个方面：</strong></p>
<ol>
<li>可能会多次扫描被驱动表， 占用磁盘IO资源；</li>
<li>判断join条件需要执行M*N次对比（M、 N分别是两张表的行数） ， 如果是大表就会占用非常多的CPU资源；</li>
<li>可能会导致Buffer Pool的热数据被淘汰， 影响内存命中率。</li>
</ol>
<p><strong>执行语句之前， 需要通过理论分析和查看explain结果的方式， 确认是否要使用BNL算法。 如果确认优化器会使用BNL算法， 就需要做优化。 优化的常见做法是， 给被驱动表的join字段加上索引， 把BNL算法转成BKA算法。</strong> </p>
<h3 id="BNL转BKA"><a href="#BNL转BKA" class="headerlink" title="BNL转BKA"></a>BNL转BKA</h3><p>一些情况下， 我们可以直接在被驱动表上建索引， 这时就可以直接转成BKA算法了。<br>但是， 有时候你确实会碰到一些不适合在被驱动表上建索引的情况。 比如下面这个语句：  </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">select * from t1 join t2 on (t1.b=t2.b) where t2.b&gt;=1 and t2.b&lt;=2000;  </span><br></pre></td></tr></table></figure>

<p>在表t2中插入了100万行数据， 但是经过where条件过滤后， 需要参与join的只有2000行数据。 如果这条语句同时是一个低频的SQL语句， 那么再为这个语句在表t2的字段b上创建一个索引就很浪费了。</p>
<p>但是， 如果使用BNL算法来join的话， 这个语句的执行流程是这样的：</p>
<ol>
<li>把表t1的所有字段取出来， 存入join_buffer中。 这个表只有1000行， join_buffer_size默认值是256k， 可以完全存入。</li>
<li>扫描表t2， 取出每一行数据跟join_buffer中的数据进行对比，<br>如果不满足t1.b&#x3D;t2.b， 则跳过；<br>如果满足t1.b&#x3D;t2.b, 再判断其他条件， 也就是是否满足t2.b处于[1,2000]的条件， 如果<br>是， 就作为结果集的一部分返回， 否则跳过</li>
</ol>
<p>对于表t2的每一行， 判断join是否满足的时候， 都需要遍历join_buffer中的所有行。 因此判断等值条件的次数是1000*100万&#x3D;10亿次， 这个判断的工作量很大。  </p>
<p>explain查询结果：</p>
<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20230105201624.png" alt="image-20230105201624632" style="zoom:80%;" />

<p>查询时间：</p>
<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20230105201646.png" alt="image-20230105201646247" style="zoom:80%;" />

<p>在表t2的字段b上创建索引会浪费资源， 但是不创建索引的话这个语句的等值条件要判断10亿次， 想想也是浪费。 那么， 有没有两全其美的办法呢？  </p>
<p>这时候， 我们可以考虑使用临时表。 使用临时表的大致思路是：</p>
<ol>
<li>把表t2中满足条件的数据放在临时表tmp_t中；</li>
<li>为了让join使用BKA算法， 给临时表tmp_t的字段b加上索引；</li>
<li>让表t1和tmp_t做join操作。此时， 对应的SQL语句的写法如下：</li>
</ol>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> temporary <span class="keyword">table</span> temp_t(id <span class="type">int</span> <span class="keyword">primary</span> key, a <span class="type">int</span>, b <span class="type">int</span>, index(b))engine<span class="operator">=</span>innodb;</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> temp_t <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t2 <span class="keyword">where</span> b<span class="operator">&gt;=</span><span class="number">1</span> <span class="keyword">and</span> b<span class="operator">&lt;=</span><span class="number">2000</span>;</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t1 <span class="keyword">join</span> temp_t <span class="keyword">on</span> (t1.b<span class="operator">=</span>temp_t.b);</span><br></pre></td></tr></table></figure>

<p>执行效果：</p>
<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20230105202120.png" alt="image-20230105202120641" style="zoom: 50%;" />

<p>总耗时还不到1秒，比起前面的1分11秒，性能得到了极大的提高。</p>
<p>执行过程：</p>
<ol>
<li>执行insert语句构造temp_t表并插入数据的过程中， 对表t2做了全表扫描， 这里扫描行数是100万。<br>create temporary table temp_t(id int primary key, a int, b int, index(b))engine&#x3D;innodb;<br>insert into temp_t select * from t2 where b&gt;&#x3D;1 and b&lt;&#x3D;2000;<br>select * from t1 join temp_t on (t1.b&#x3D;temp_t.b);</li>
<li>之后的join语句， 扫描表t1， 这里的扫描行数是1000； join比较过程中， 做了1000次带索引的查询。 相比于优化前的join语句需要做10亿次条件判断来说， 这个优化效果还是很明显的。</li>
</ol>
<p><strong>总体来看， 不论是在原表上加索引， 还是用有索引的临时表， 我们的思路都是让join语句能够用上被驱动表上的索引， 来触发BKA算法， 提升查询性能。</strong>  </p>
<h3 id="扩展-hash-join"><a href="#扩展-hash-join" class="headerlink" title="扩展-hash join"></a>扩展-hash join</h3><p>如果join_buffer里面维护的不是一个无序数组， 而是一个哈希表的话， 那么就不是10亿次判断， 而是100万次hash查<br>找。 这样的话， 整条语句的执行速度就快多了吧。<br>但是MySQL的优化器和执行器： 不支持哈希join。 并且， MySQL官方的roadmap， 也是迟迟没有把这个优化排上议程。  </p>
<p>实际上， 这个优化思路， 我们可以自己实现在业务端。 实现流程大致如下：</p>
<ol>
<li>select * from t1;取得表t1的全部1000行数据， 在业务端存入一个hash结构， 比如C++里的set、 PHP的dict这样的数据结构。</li>
<li>select * from t2 where b&gt;&#x3D;1 and b&lt;&#x3D;2000; 获取表t2中满足条件的2000行数据。</li>
<li>把这2000行数据， 一行一行地取到业务端， 到hash结构的数据表中寻找匹配的数据。 满足匹配的条件的这行数据， 就作为结果集的一行。理论上， 这个过程会比临时表方案的执行速度还要快一些。</li>
</ol>
<h2 id="临时表"><a href="#临时表" class="headerlink" title="临时表"></a>临时表</h2><h3 id="临时表的特性"><a href="#临时表的特性" class="headerlink" title="临时表的特性"></a>临时表的特性</h3><p>临时表在使用上有以下几个特点：</p>
<ol>
<li>建表语法是create temporarytable …。</li>
<li>一个临时表只能被创建它的session访问， 对其他线程不可见。 所以， 图中session A创建的临时表t， 对于session B就是不可见的。</li>
<li>临时表可以与普通表同名。</li>
<li>session A内有同名的临时表和普通表的时候， show create语句， 以及增删改查语句访问的是临时表。</li>
<li>show tables命令不显示临时表。由于临时表只能被创建它的session访问， 所以在这个session结束的时候， 会自动删除临时表。</li>
</ol>
<p>  <strong>也正是由于这个特性， 临时表就特别适合join优化这种场景。</strong>   </p>
<p>原因主要包括以下两个方面：</p>
<ol>
<li>不同session的临时表是可以重名的， 如果有多个session同时执行join优化， 不需要担心表名重复导致建表失败的问题。</li>
<li>不需要担心数据删除问题。 如果使用普通表， 在流程执行过程中客户端发生了异常断开， 或者数据库发生异常重启， 还需要专门来清理中间过程中生成的数据表。 而临时表由于会自动回收， 所以不需要这个额外的操作。</li>
</ol>
<h3 id="临时表的应用"><a href="#临时表的应用" class="headerlink" title="临时表的应用"></a>临时表的应用</h3><p>由于不用担心线程之间的重名冲突， 临时表经常会被用在复杂查询的优化过程中。 其中， 分库分表系统的跨库查询就是一个典型的使用场景。  </p>
<p>在分库分表的场景中，比如需要对多个表查询出来的数据做group by、join、或排序的时候，可以先将每一张表里查询出来的数据插入到一张临时表里，然后对这张临时表做操作。</p>
<h3 id="为什么临时表可以重名？"><a href="#为什么临时表可以重名？" class="headerlink" title="为什么临时表可以重名？"></a>为什么临时表可以重名？</h3><p>语句：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> temporary <span class="keyword">table</span> temp_t(id <span class="type">int</span> <span class="keyword">primary</span> key)engine<span class="operator">=</span>innodb;</span><br></pre></td></tr></table></figure>

<p>MySQL要给这个InnoDB表创建一个frm文件保存表结构定义， 还要有地方保存表数据。<br>这个frm文件放在临时文件目录下， 文件名的后缀是.frm， 前缀是“#sql{进程id}_{线程id}_序列号”。 你可以使用select @@tmpdir命令， 来显示实例的临时文件目录。  </p>
<ul>
<li><p>而关于表中数据的存放方式， 在不同的MySQL版本中有着不同的处理方式：</p>
<p>在5.6以及之前的版本里， MySQL会在临时文件目录下创建一个相同前缀、 以.ibd为后缀的文件， 用来存放数据文件；</p>
</li>
<li><p>而从 5.7版本开始， MySQL引入了一个临时文件表空间， 专门用来存放临时文件的数据。 因此， 我们就不需要再创建ibd文件了。</p>
</li>
</ul>
<p>MySQL维护数据表， 除了物理上要有文件外， 内存里面也有一套机制区别不同的表， 每个表都对应一个table_def_key。<br>一个普通表的table_def_key的值是由“库名+表名”得到的， 所以如果你要在同一个库下创建两个同名的普通表， 创建第二个表的过程中就会发现table_def_key已经存在了。<br>而对于临时表， table_def_key在“库名+表名”基础上， 又加入了“server_id+thread_id”。create temporary table temp_t(id int primary key)engine&#x3D;innodb;也就是说， session A和sessionB创建的两个临时表t1， 它们的table_def_key不同， 磁盘文件名也不同， 因此可以并存。<br>在实现上， 每个线程都维护了自己的临时表链表。 这样每次session内操作表的时候， 先遍历链表， 检查是否有这个名字的临时表， 如果有就优先操作临时表， 如果没有再操作普通表； 在session结束的时候， 对链表里的每个临时表， 执行 “DROPTEMPORARY TABLE +表名”操作。<br>这时候你会发现， binlog中也记录了DROPTEMPORARY TABLE这条命令。 你一定会觉得奇怪， 临时表只在线程内自己可以访问， 为什么需要写到binlog里面？<br>这， 就需要说到主备复制了   </p>
<h3 id="临时表和主备复制"><a href="#临时表和主备复制" class="headerlink" title="临时表和主备复制"></a>临时表和主备复制</h3><p>在主库上执行下面这个语句序列：  </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">create table t_normal(id int primary key, c int)engine=innodb;/*Q1*/</span><br><span class="line">create temporary table temp_t like t_normal;/*Q2*/</span><br><span class="line">insert into temp_t values(1,1);/*Q3*/</span><br><span class="line">insert into t_normal select * from temp_t;/*Q4*/</span><br></pre></td></tr></table></figure>

<p>如果关于临时表的操作都不记录， 那么在备库就只有create table t_normal表和insert into t_normal select * from temp_t这两个语句的binlog日志， 备库在执行到insert into t_normal的时候， 就会报错“表temp_t不存在”。  </p>
<p><strong>如果当前的binlog_format&#x3D;row， 那么跟临时表有关的语句， 就不会记录到binlog里。 也就是说， 只binlog_format&#x3D;statment&#x2F;mixed 的时候， binlog中才会记录临时表的操作。</strong>  </p>
<p>这种情况下， 创建临时表的语句会传到备库执行， 因此备库的同步线程就会创建这个临时表。 主库在线程退出的时候， 会自动删除临时表， 但是备库同步线程是持续在运行的。 所以， 这时候我们就需要在主库上再写一个DROP TEMPORARY TABLE传给备库执行。  </p>
<p>drop table命令是可以一次删除多个表的。 比如， 在上面的例子中， 设置binlog_format&#x3D;row， 如果主库上执行 “drop table t_normal, temp_t”这个命令， 那么binlog中就只能记录：  </p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">DROP</span> <span class="keyword">TABLE</span> `t_normal` <span class="comment">/* generated by server */</span></span><br></pre></td></tr></table></figure>

<p>因为备库上并没有表temp_t， 将这个命令重写后再传到备库执行， 才不会导致备库同步线程停止。<br>所以， drop table命令记录binlog的时候， 就必须对语句做改写。 “&#x2F;* generated byserver *&#x2F;”说明了这是一个被服务端改写过的命令  </p>
<p>备库同一个线程创建主库两个线程的临时表：</p>
<p>MySQL在记录binlog的时候， 会把主库执行这个语句的线程id写到binlog中。 这样， 在备库的应用线程就能够知道执行每个语句的主库线程id， 并利用这个线程id来构造临时表的<br>table_def_key：</p>
<ol>
<li>session A的临时表t1， 在备库的table_def_key就是： 库名+t1+“M的serverid”+“session A的thread_id”;</li>
<li>session B的临时表t1， 在备库的table_def_key就是 ： 库名+t1+“M的serverid”+“session B的thread_id”。<br>由于table_def_key不同， 所以这两个表在备库的应用线程里面是不会冲突的。</li>
</ol>
<h3 id="什么时候会用到临时表"><a href="#什么时候会用到临时表" class="headerlink" title="什么时候会用到临时表"></a>什么时候会用到临时表</h3><ol>
<li>如果语句执行过程可以一边读数据， 一边直接得到结果， 是不需要额外内存的， 否则就需要额外的内存， 来保存中间结果；</li>
<li>join_buffer是无序数组， sort_buffer是有序数组， 临时表是二维表结构；</li>
<li>如果执行逻辑需要用到二维表特性， 就会优先考虑使用临时表。 比如我们的例子中， union需要用到唯一索引约束， group by还需要用到另外一个字段来存累积计数。</li>
</ol>
<h2 id="Union执行流程"><a href="#Union执行流程" class="headerlink" title="Union执行流程"></a>Union执行流程</h2><p>假如有如下表：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">create table t1(id int primary key, a int, b int, index(a));  </span><br></pre></td></tr></table></figure>

<p>执行如下查询：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(select 1000 as f) union (select id from t1 order by id desc limit 2);</span><br></pre></td></tr></table></figure>

<p>该语句使用了union，表示取结果的并集，重复的行只保留一行。</p>
<p>explain结果：</p>
<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20230203151325.png" alt="image-20230203151318026" style="zoom:80%;" />

<p>可以看到该查询在union阶段使用了临时表。</p>
<p>其实该语句的执行流程是：</p>
<p>1.创建临时表，并且临时表只有一个整型字段并且是主键</p>
<p>2.查询数据试图插入临时表，若存在则丢弃，不存在则插入</p>
<p>最后从临时表查询结果返回。</p>
<p>如果union 换成union all的话就不需要用到临时表，因为不需要去重，只需要将查询结果直接返回给客户端。</p>
<h2 id="Group-by-执行流程"><a href="#Group-by-执行流程" class="headerlink" title="Group by 执行流程"></a>Group by 执行流程</h2><p>有如下查询语句：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">select id%10 as m, count(*) as c from t1 group by m;  </span><br></pre></td></tr></table></figure>

<p>explain结果：</p>
<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20230203151931.png" alt="image-20230203151931238" style="zoom:80%;" />

<p>这个语句的执行流程是这样的：</p>
<ol>
<li>创建内存临时表， 表里有两个字段m和c， 主键是m；</li>
<li>扫描表t1的索引a， 依次取出叶子节点上的id值， 计算id%10的结果， 记为x；<br>如果临时表中没有主键为x的行， 就插入一个记录(x,1);<br>如果表中有主键为x的行， 就将x这一行的c值加1；</li>
<li>遍历完成后， 再根据字段m做排序， 得到结果集返回给客户端</li>
</ol>
<p>group by默认会进行排序，按升序。如果不需要排序的话，在后面加order by null。</p>
<p>内存临时表的大小是有限制的， 参数tmp_table_size就是控制这个内存大小的， 默认是16M。  </p>
<p>但如果表t1的数据量比较大，内存临时表转成磁盘临时表， 磁盘临时表默认使用的引擎是InnoDB。如果这个表t1的数据量很大， 很可能这个查询需要的磁盘临时表就会占用大量的磁盘空间。</p>
<h3 id="为什么group-by需要临时表"><a href="#为什么group-by需要临时表" class="headerlink" title="为什么group by需要临时表"></a>为什么group by需要临时表</h3><p>在 group by的过程中，因为是对数据按唯一键进行 去重汇总计算。因此需要临时表来记录每一个唯一键以及汇总值。但是有一种情况，就是group by的列有序的时候。如下：</p>
<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20230203153446.png" alt="image-20230203153446169" style="zoom:80%;" />

<p>那么计算group by的时候， 就只需要从左到右，顺序扫描， 依次累加得到结果，因此不需要临时表。   </p>
<p>如果扫描过程中可以保证出现的数据是有序的，那么group by就可以不需要临时表。</p>
<h3 id="group-by-优化方法-–索引"><a href="#group-by-优化方法-–索引" class="headerlink" title="group by 优化方法 –索引"></a>group by 优化方法 –索引</h3><p>在MySQL 5.7版本支持了generated column机制， 用来实现列数据的关联更新。 可以用下面的方法创建一个列z， 然后在z列上创建一个索引（如果是MySQL 5.6及之前的版本， 也可以创建普通列和索引， 来解决这个问题） 。  </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">alter table t1 add column z int generated always as(id % 100), add index(z);  </span><br></pre></td></tr></table></figure>

<p>这样， 索引z上的数据就是类似图10这样有序的了。 上面的group by语句就可以改成：  </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">select z, count(*) as c from t1 group by z;</span><br></pre></td></tr></table></figure>

<p>explain结果：</p>
<p><img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20230203153759.png" alt="image-20230203153759556"></p>
<p>从Extra字段可以看到， 这个语句的执行不再需要临时表， 也不需要排序了。  </p>
<h3 id="group-by优化方法-–直接排序"><a href="#group-by优化方法-–直接排序" class="headerlink" title="group by优化方法 –直接排序"></a>group by优化方法 –直接排序</h3><p>所以， 如果可以通过加索引来完成group by逻辑就再好不过了。 但是， 如果碰上不适合创建索引的场景， 我们还是要老老实实做排序的。 那么， 这时候的group by要怎么优化呢？  </p>
<p>如果我们明明知道， 一个group by语句中需要放到临时表上的数据量特别大， 却还是要按照“先放到内存临时表， 插入一部分数据后， 发现内存临时表不够用了再转成磁盘临时表”， 看上去就有点儿傻。  </p>
<p><strong>在group by语句中加入SQL_BIG_RESULT这个提示（hint） ， 就可以告诉优化器： 这个语句涉及的数据量很大， 请直接用磁盘临时表。</strong><br><strong>MySQL的优化器一看， 磁盘临时表是B+树存储， 存储效率不如数组来得高。 所以， 既然你告诉我数据量很大， 那从磁盘空间考虑， 还是直接用数组来存吧。</strong>  </p>
<p>因此该语句：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">select SQL_BIG_RESULT id%100 as m, count(*) as c from t1 group by m;</span><br></pre></td></tr></table></figure>

<p>有如下执行流程：</p>
<ol>
<li>初始化sort_buffer， 确定放入一个整型字段， 记为m；</li>
<li>扫描表t1的索引a， 依次取出里面的id值, 将 id%100的值存入sort_buffer中；</li>
<li>扫描完成后， 对sort_buffer的字段m做排序（如果sort_buffer内存不够用， 就会利用磁盘临时文件辅助排序） ；  </li>
<li>排序完成后， 就得到了一个有序数组。</li>
</ol>
<p>执行流程：</p>
<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20230203154628.png" alt="image-20230203154627915" style="zoom:50%;" />

<p> explain执行结果：</p>
<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20230203154521.png" alt="image-20230203154521824" style="zoom:80%;" />

<p>可以看到并没有使用内存临时表，而是直接使用排序算法进行了排序。</p>
<h3 id="group-by使用注意事项："><a href="#group-by使用注意事项：" class="headerlink" title="group by使用注意事项："></a>group by使用注意事项：</h3><ol>
<li>如果对group by语句的结果没有排序要求， 要在语句后面加 order bynull；</li>
<li>尽量让group by过程用上表的索引， 确认方法是explain结果里没有Using temporary和 Usingfilesort；</li>
<li>如果group by需要统计的数据量不大， 尽量只使用内存临时表； 也可以通过适当调大tmp_table_size参数， 来避免用到磁盘临时表；</li>
<li>如果数据量实在太大， 使用SQL_BIG_RESULT这个提示， 来告诉优化器直接使用排序算法得到group by的结果。  </li>
<li>distinct  和group by都只用于去重时，在没有limit的情况下，两者性能差不多，在有limit的情况下，distant性能更好</li>
</ol>
<h2 id="InnoDB-引擎和Memory引擎"><a href="#InnoDB-引擎和Memory引擎" class="headerlink" title="InnoDB 引擎和Memory引擎"></a>InnoDB 引擎和Memory引擎</h2><h3 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h3><p>这两个引擎的一些典型不同：</p>
<ol>
<li>InnoDB表的数据总是有序存放的， 而内存表的数据就是按照写入顺序存放的；</li>
<li>当数据文件有空洞的时候， InnoDB表在插入新数据的时候， 为了保证数据有序性， 只能在固定的位置写入新值， 而内存表找到空位就可以插入新值，比如顺序插入1、2、3、4，当3被删除之后，如果插入了10，使用select *返回的顺序会是1、2、10、4；</li>
<li>数据位置发生变化的时候， InnoDB表只需要修改主键索引， 而内存表需要修改所有索引；</li>
<li>InnoDB表用主键索引查询时需要走一次索引查找， 用普通索引查询的时候， 需要走两次索引查找。 而内存表没有这个区别， 所有索引的“地位”都是相同的。</li>
<li>InnoDB支持变长数据类型， 不同记录的长度可能不同； 内存表不支持Blob 和 Text字段， 并且即使定义了varchar(N)， 实际也当作char(N)， 也就是固定长度字符串来存储， 因此内存表的每行数据长度相同。</li>
</ol>
<p>实际上， 内存表也是支B-Tree索引的。 在id列上创建一个B-Tree索引， SQL语句可以这么写  </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">alter table t1 add index a_btree_index using btree (id);</span><br></pre></td></tr></table></figure>

<p>内存表的优势是速度快， 其中的一个原因就是Memory引擎支持hash索引。 当然， 更重要的原因是， 内存表的所有数据都保存在内存， 而内存的读写速度总是比磁盘快。  </p>
<p><strong>不建议生产上使用内存表。</strong></p>
<p>这里的原因主要包括<br>两个方面：<br>1.锁粒度问题；</p>
<p>2.数据持久化问题  </p>
<h3 id="内存表的锁"><a href="#内存表的锁" class="headerlink" title="内存表的锁"></a>内存表的锁</h3><p>内存表不支持行锁， 只支持表锁。 因此， 一张表只要有更新， 就会堵住其他所有在这个表上的读写操作 。</p>
<p>跟行锁比起来， 表锁对并发访问的支持不够好。 所以， 内存表的锁粒度问题， 决定了它在处理并发事务的时候， 性能也不会太好。  </p>
<h3 id="数据持久性问题"><a href="#数据持久性问题" class="headerlink" title="数据持久性问题"></a>数据持久性问题</h3><p>数据放在内存中， 是内存表的优势， 但也是一个劣势。 因为， 数据库重启的时候， 所有的内存表都会被清空。  </p>
<p>由于重启会丢数据， 如果一个备库重启， 会导致主备同步线程停止； 如果主库跟这个备库是双M架构， 还可能导致主库的内存表数据被删掉 。</p>
<h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>建议你把普通内存表都用InnoDB表来代替 ：</p>
<ol>
<li>如果你的表更新量大， 那么并发度是一个很重要的参考指标， InnoDB支持行锁， 并发度比内存表好；</li>
<li>能放到内存表的数据量都不大。 如果你考虑的是读的性能， 一个读QPS很高并且数据量不大的表， 即使是使用InnoDB， 数据也是都会缓存在InnoDB Buffer Pool里的。 因此， 使用InnoDB表的读性能也不会差。</li>
</ol>
<p>内存临时表是例外，内存临时表刚好可以无视内存表的两个不足， 主要是下面的三个原因：</p>
<ol>
<li>临时表不会被其他线程访问， 没有并发性的问题；</li>
<li>临时表重启后也是需要删除的， 清空数据这个问题不存在；</li>
<li>备库的临时表也不会影响主库的用户线程。</li>
</ol>
<h2 id="自增主键空洞"><a href="#自增主键空洞" class="headerlink" title="自增主键空洞"></a>自增主键空洞</h2><p>假设有以下表：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">CREATE TABLE `t` (</span><br><span class="line">`id` int(11) NOT NULL AUTO_INCREMENT,</span><br><span class="line">`c` int(11) DEFAULT NULL,</span><br><span class="line">`d` int(11) DEFAULT NULL,</span><br><span class="line">PRIMARY KEY (`id`),</span><br><span class="line">UNIQUE KEY `c` (`c`)</span><br><span class="line">) ENGINE=InnoDB;</span><br></pre></td></tr></table></figure>

<h3 id="自增值存储位置"><a href="#自增值存储位置" class="headerlink" title="自增值存储位置"></a>自增值存储位置</h3><p>不同的引擎对于自增值的保存策略不同。</p>
<ul>
<li><p>MyISAM引擎的自增值保存在数据文件中。</p>
</li>
<li><p>InnoDB引擎的自增值， 其实是保存在了内存里， 并且到了MySQL 8.0版本后， 才有了“自增值持久化”的能力， 也就是才实现了“如果发生重启， 表的自增值可以恢复为MySQL重启前的值”， 具体情况是：</p>
<ol>
<li><p>在MySQL 5.7及之前的版本， 自增值保存在内存里， 并没有持久化。 每次重启后， 第一次打开表的时候， 都会去找自增值的最大值max(id)， 然后将max(id)+1作为这个表当前的自增值。</p>
<p>举例来说， 如果一个表当前数据行里最大的id是10， AUTO_INCREMENT&#x3D;11。 这时候，我们删除id&#x3D;10的行， AUTO_INCREMENT还是11。 但如果马上重启实例， 重启后这个表的AUTO_INCREMENT就会变成10。</p>
<p>也就是说， MySQL重启可能会修改一个表的AUTO_INCREMENT的值。</p>
<p>2.在MySQL 8.0版本， 将自增值的变更记录在了redo log中， 重启的时候依靠redo log恢复重启之前的值。</p>
</li>
</ol>
</li>
</ul>
<h3 id="自增值修改机制"><a href="#自增值修改机制" class="headerlink" title="自增值修改机制"></a>自增值修改机制</h3><p>在MySQL里面， 如果字段id被定义为AUTO_INCREMENT， 在插入一行数据的时候， 自增值的<br>行为如下：</p>
<ol>
<li>如果插入数据时id字段指定为0、 null 或未指定值， 那么就把这个表当前的AUTO_INCREMENT值填到自增字段；  </li>
<li>如果插入数据时id字段指定了具体的值， 就直接使用语句里指定的值。</li>
</ol>
<p>根据要插入的值和当前自增值的大小关系， 自增值的变更结果也会有所不同。 假设， 某次要插入<br>的值是X， 当前的自增值是Y。</p>
<ol>
<li>如果X&lt;Y， 那么这个表的自增值不变；</li>
<li>如果X≥Y， 就需要把当前自增值修改为新的自增值。</li>
</ol>
<p><strong>新的自增值生成算法是： 从auto_increment_offset开始， 以auto_increment_increment为步长， 持续叠加， 直到找到第一个大于X的值， 作为新的自增值。</strong>    </p>
<p>其中， auto_increment_offset 和 auto_increment_increment是两个系统参数， 分别用来表示自增的初始值和步长， 默认值都是1。 </p>
<h3 id="自增值的修改时机"><a href="#自增值的修改时机" class="headerlink" title="自增值的修改时机"></a>自增值的修改时机</h3><p>假设， 表t里面已经有了(1,1,1)这条记录， 这时我再执行一条插入数据命令：  </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">insert into t values(null, 1, 1);  </span><br></pre></td></tr></table></figure>

<p>这个语句的执行流程就是：  </p>
<ol>
<li>执行器调用InnoDB引擎接口写入一行， 传入的这一行的值是(0,1,1);</li>
<li>InnoDB发现用户没有指定自增id的值， 获取表t当前的自增值2；</li>
<li>将传入的行的值改成(2,1,1);</li>
<li>将表的自增值改成3；</li>
<li>继续执行插入数据操作， 由于已经存在c&#x3D;1的记录， 所以报Duplicate keyerror， 语句返回。</li>
</ol>
<p>可以看到， 这个表的自增值改成3， 是在真正执行插入数据的操作之前。 这个语句真正执行的时候， 因为碰到唯一键c冲突， 所以id&#x3D;2这一行并没有插入成功， 但也没有将自增值再改回去。  </p>
<p>所以， 在这之后， 再插入新的数据行时， 拿到的自增id就是3。 也就是说， 出现了自增主键不连续的情况 。</p>
<p>因此InnoDB 语句执行失败也不回退自增id。 也正是因为这样， 所以才只保证了自增id是递增的， 但不保证是连续的。  </p>
<h3 id="自增锁的优化"><a href="#自增锁的优化" class="headerlink" title="自增锁的优化"></a>自增锁的优化</h3><p>自增id锁并不是一个事务锁， 而是每次申请完就马上释放， 以便允许别的事务再申请。   </p>
<p>其实， 在MySQL 5.1版本之前， 并不是这样的。  </p>
<p>在MySQL 5.0版本的时候， 自增锁的范围是语句级别。 也就是说， 如果一个语句申请了一个表自<br>增锁， 这个锁会等语句执行结束以后才释放。 显然， 这样设计会影响并发度。<br><strong>MySQL 5.1.22版本引入了一个新策略， 新增参数innodb_autoinc_lock_mode， 默认值是1。</strong></p>
<ol>
<li>这个参数的值被设置为0时， 表示采用之前MySQL 5.0版本的策略， 即语句执行结束后才释放锁；</li>
<li>这个参数的值被设置为1时：<br>普通insert语句， 自增锁在申请之后就马上释放；<br>类似insert …select这样的批量插入数据的语句， 自增锁还是要等语句结束后才被释放；</li>
<li>这个参数的值被设置为2时， 所有的申请自增主键的动作都是申请后就释放锁</li>
</ol>
<p><strong>默认使用2的形式可以防止主备或者主从数据不一致的情况。而如果使用3这种形式，则需要将binlog设置为row的形式，才能防止数据不一致的情况。</strong></p>
<h2 id="分区表"><a href="#分区表" class="headerlink" title="分区表"></a>分区表</h2><h3 id="分区表是什么"><a href="#分区表是什么" class="headerlink" title="分区表是什么"></a>分区表是什么</h3><p>假如有如下分区表：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">CREATE TABLE `t` (</span><br><span class="line">`ftime` datetime NOT NULL,</span><br><span class="line">`c` int(11) DEFAULT NULL,</span><br><span class="line">KEY (`ftime`)</span><br><span class="line">) ENGINE=InnoDB DEFAULT CHARSET=latin1</span><br><span class="line">PARTITION BY RANGE (YEAR(ftime))</span><br><span class="line">(PARTITION p_2017 VALUES LESS THAN (2017) ENGINE = InnoDB,</span><br><span class="line">PARTITION p_2018 VALUES LESS THAN (2018) ENGINE = InnoDB,</span><br><span class="line">PARTITION p_2019 VALUES LESS THAN (2019) ENGINE = InnoDB,</span><br><span class="line">PARTITION p_others VALUES LESS THAN MAXVALUE ENGINE = InnoDB);</span><br><span class="line">insert into t values(&#x27;2017-4-1&#x27;,1),(&#x27;2018-4-1&#x27;,1);</span><br></pre></td></tr></table></figure>

<p>这个表在物理层面上包含了1个.frm文件和4个.ibd文件， 每个分区对应一个.ibd文件。 也就是说：</p>
<ul>
<li>对于引擎层来说， 这是4个表；</li>
<li>对于Server层来说， 这是1个表。</li>
</ul>
<h3 id="分区表的引擎层行为"><a href="#分区表的引擎层行为" class="headerlink" title="分区表的引擎层行为"></a>分区表的引擎层行为</h3><p>对于InnoDB和MyISAM  来说，分区表其实都是一个分区相当于一个表。</p>
<h3 id="分区策略"><a href="#分区策略" class="headerlink" title="分区策略"></a>分区策略</h3><p>每当第一次访问一个分区表的时候， MySQL需要把所有的分区都访问一遍。 一个典型的报错情况是这样的： 如果一个分区表的分区很多， 比如超过了1000个， 而MySQL启动的时候， open_files_limit参数使用的是默认值1024， 那么就会在访问这个表的时候， 由于需要打开所有的文件， 导致打开表文件的个数超过了上限而报错。  </p>
<p><strong>MyISAM分区表使用的分区策略， 我们称为通用分区策略（generic partitioning）</strong> ， 每次访问分区都由server层控制。 通用分区策略， 是MySQL一开始支持分区表的时候就存在的代码， 在文件管理、 表管理的实现上很粗糙， 因此有比较严重的性能问题。  </p>
<p><strong>从MySQL 5.7.9开始， InnoDB引擎引入了本地分区策略（native partitioning） 。 这个策略是在InnoDB内部自己管理打开分区的行为。</strong><br><strong>MySQL从5.7.17开始， 将MyISAM分区表标记为即将弃用(deprecated)， 意思是“从这个版本开始不建议这么使用， 请使用替代方案。 在将来的版本中会废弃这个功能”。</strong><br><strong>从MySQL 8.0版本开始， 就不允许创建MyISAM分区表了， 只允许创建已经实现了本地分区策略的引擎。 目前来看， 只有InnoDB和NDB这两个引擎支持了本地分区策略。</strong></p>
<h3 id="分区表的server层行为"><a href="#分区表的server层行为" class="headerlink" title="分区表的server层行为"></a>分区表的server层行为</h3><p><strong>如果从server层看的话， 一个分区表就只是一个表</strong>  </p>
<p>比如当查询时，获取的mdl锁，会加在整张表上。</p>
<h3 id="分区表特性"><a href="#分区表特性" class="headerlink" title="分区表特性"></a>分区表特性</h3><ol>
<li>MySQL在第一次打开分区表的时候， 需要访问所有的分区；</li>
<li>在server层， 认为这是同一张表， 因此所有分区共用同一个MDL锁；</li>
<li>在引擎层， 认为这是不同的表， 因此MDL锁之后的执行过程， 会根据分区表规则， 只访问必要的分区。</li>
</ol>
<h3 id="分区表的应用场景"><a href="#分区表的应用场景" class="headerlink" title="分区表的应用场景"></a>分区表的应用场景</h3><p>分区表的一个显而易见的优势是对业务透明， 相对于用户分表来说， 使用分区表的业务代码更简洁。 还有， 分区表可以很方便的清理历史数据。  </p>
<p>如果一项业务跑的时间足够长， 往往就会有根据时间删除历史数据的需求。 这时候， 按照时间分区的分区表， 就可以直接通过alter table t drop partition …这个语法删掉分区， 从而删掉过期的历史数据。<br>这个alter table t drop partition …操作是直接删除分区文件， 效果跟drop普通表类似。 与使用delete语句删除数据相比， 优势是速度快、 对系统影响小。</p>
<h2 id="自增id"><a href="#自增id" class="headerlink" title="自增id"></a>自增id</h2><p>每种自增id有各自的应用场景， 在达到上限后的表现也不同：</p>
<ol>
<li>表的自增id达到上限后， 再申请时它的值就不会改变， 进而导致继续插入数据时报主键冲突的错误。</li>
<li>row_id达到上限后， 则会归0再重新递增， 如果出现相同的row_id， 后写的数据会覆盖之前的数据。</li>
<li>Xid只需要不在同一个binlog文件中出现重复值即可。 虽然理论上会出现重复值， 但是概率极小， 可以忽略不计。</li>
<li>InnoDB的max_trx_id 递增值每次MySQL重启都会被保存起来， 所以我们文章中提到的脏读的例子就是一个必现的bug， 好在留给我们的时间还很充裕。</li>
<li>thread_id是我们使用中最常见的， 而且也是处理得最好的一个自增id逻辑了。</li>
</ol>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL的SQL优化</title>
    <url>/2021/MySQL/MySQL%E7%9A%84SQL%E4%BC%98%E5%8C%96/</url>
    <content><![CDATA[<h2 id="如果你的MySQL现在出现了性能瓶颈，-而且瓶颈在IO上，-可以通过哪些方法来提升性能呢？"><a href="#如果你的MySQL现在出现了性能瓶颈，-而且瓶颈在IO上，-可以通过哪些方法来提升性能呢？" class="headerlink" title="如果你的MySQL现在出现了性能瓶颈， 而且瓶颈在IO上， 可以通过哪些方法来提升性能呢？"></a>如果你的MySQL现在出现了性能瓶颈， 而且瓶颈在IO上， 可以通过哪些方法来提升性能呢？</h2><p>针对这个问题， 可以考虑以下三种方法：</p>
<ol>
<li>设置 binlog_group_commit_sync_delay和 binlog_group_commit_sync_no_delay_count参数， 减少binlog的写盘次数。 这个方法是基于“额外的故意等待”来实现的， 因此可能会增加语句的响应时间， 但没有丢失数据的风险。</li>
<li>将sync_binlog 设置为大于1的值（比较常见是100~1000） 。 这样做的风险是， 主机掉电时会丢binlog日志。</li>
<li>将innodb_flush_log_at_trx_commit设置为2。 这样做的风险是， 主机掉电的时候会丢数据。我不建议你把innodb_flush_log_at_trx_commit 设置成0。 因为把这个参数设置成0， 表示redolog只保存在内存中， 这样的话MySQL本身异常重启也会丢数据， 风险太大。 而redo log写到文件系统的page cache的速度也是很快的， 所以将这个参数设置成2跟设置成0其实性能差不多，但这样做MySQL异常重启时就不会丢数据了， 相比之下风险会更小。</li>
</ol>
<h2 id="索引优化"><a href="#索引优化" class="headerlink" title="索引优化"></a>索引优化</h2><p>1.使用自增主键防止造成页分裂，使用逻辑删除防止造成页合并，以及减少数据空洞</p>
<p>2.覆盖索引，减少回表次数</p>
<p>3.利用索引的最左前缀原则，建立联合索引时。一：调整索引顺序，适当的减少索引的个数，二：比如当需要同时维护(a,b)、(b) 这两个索引的时候，将占用空间比较大的字段放到联合索引里，小的字段建立单独的索引，这样可以降低空间占用</p>
<p>4.在业务能保证数据唯一的情况下，尽量优先使用普通索引。在查询上，两种索引性能差不多，在更新上普通索引可以使用change buffer可以优化表的更新操作。但是如果在更新数据后，马上就需要查询该数据，则可以关闭change buffer机制，减少change buffer维护</p>
<p>5.采用force index强行选择一个索引；不改变语义的情况下修改语句；调整索引</p>
<p>6.对于字符串字段可以采用前缀索引的形式，结合区分度适当的取前N位作为索引，可以在节省空间的同时查询也不会增加太多额外的成本。使用select count(distinct left(email,4) from t语句，可查看前N位的区分度</p>
<p>但是使用前缀索引的话，覆盖索引会失效</p>
<p>7.索引失效：</p>
<p>  ①对索引字段做函数操作或计算操作（但是在有的函数操作时，MySQL优化器可能会觉得该索引树比主键索引小，遍历该索引树比较快，因此通过explain命令查看的话，会发现走了索引。但是这里并不是使用了索引树的搜索定位功能，而是遍历索引树）</p>
<p>  ②隐式类型转换：在MySQL中， 字符串和数字做比较的话， 是将字符串转换成数字。 比如字段是字符类型，入参是整型的话，会将字段值转换为整型，这里触发了①</p>
<p>  ③隐式字符编码转换，其实这个也是触发了①，使用了函数转换了数据类型</p>
<h2 id="锁优化"><a href="#锁优化" class="headerlink" title="锁优化"></a>锁优化</h2><p>1.两阶段锁协议：行锁是在需要的时候才加上的， 但并不是不需要了就立刻释放， 而是要等到事务结束时才释放</p>
<p><strong>如果你的事务中需要锁多个行， 要把最可能造成锁冲突、 最可能影响并发度的锁尽量往后放。</strong>   </p>
<h2 id="刷脏页造成的影响"><a href="#刷脏页造成的影响" class="headerlink" title="刷脏页造成的影响"></a>刷脏页造成的影响</h2><ol>
<li><strong>一个查询要淘汰的脏页个数太多， 会导致查询的响应时间明显变长；</strong></li>
<li><strong>日志写满， 更新全部堵住， 写性能跌为0， 这种情况对敏感业务来说， 是不能接受的。</strong></li>
</ol>
<p>优化：</p>
<p>1.合理设置innodb_io_capacity参数，告诉innodb主机的io能力，该值设置为主机的IOPS值</p>
<p>2.按百分比刷，innodb_max_dirty_pages_pct是脏页比例上限（默认75%），InnoDB 会根据redo log的写入能力和脏页比例，算出一个值R，之后引擎就可以按照innodb_io_capacity定义的能力乘以R%来控制刷脏页的速度 。</p>
<p>3.开启连坐更新，在准备刷一个脏页的时候， 如果这个数据页旁边的数据页刚好是脏页，则也将该数据页刷到磁盘上。innodb_flush_neighbors 控制这个行为，innodb_flush_neighbors &#x3D; 1的时候开启连坐制度，innodb_flush_neighbors &#x3D; 0的时候表示自己刷自己的。机械硬盘建议设为1，可以减少很多随机IO  ，SSD建议设置为0。在MySQL8.0开始，默认为0；</p>
<h2 id="表空间"><a href="#表空间" class="headerlink" title="表空间"></a>表空间</h2><p>1.表数据最好设置为单独存放一个文件，在drop时，会直接删除该文件，而将表数据放在共享空间的话，即使drop表，空间也不会被回收。</p>
<p>2.使用delete语句删除数据，数据并没有被真正删除，因此数据空间不会被释放，占用大小依旧。使用delete语句删除掉的数据空间，行：范围可复用，页：都可复用。</p>
<p>3.经过大量增删改的表，会存在大量的数据空洞，可以使用alter table A engine&#x3D;InnoDB命令来重建表来达到收缩数据空洞的目的。但是会比较耗时，需要注意。</p>
<h4 id="不同的count用法"><a href="#不同的count用法" class="headerlink" title="不同的count用法"></a>不同的count用法</h4><p>count()是一个聚合函数， 对于返回的结果集， 一行行地判断， 如果count函数的参数不是NULL， 累计值就加1， 否则不加。 最后返回累计值。</p>
<p>count(*)：优化器做了优化，并不会取字段，而是直接按行累加。</p>
<p>count(主键id)：InnoDB引擎会遍历整张表， 把每一行的id值都取出来， 返回给server层。 server层拿到id后， 判断是不可能为空的， 就按行累加  </p>
<p>count(字段)：如果这个“字段”是定义为not null的话， 一行行地从记录里面读出这个字段， 判断不能为null， 按行累加；如果这个“字段”定义允许为null， 那么执行的时候， 判断到有可能是null， 还要把值取出来再判断一下， 不是null才累加。  </p>
<p>count(1) ：InnoDB引擎遍历整张表， 但不取值。 server层对于返回的每一行， 放一个数字“1”进去， 判断是不可能为空的， 按行累加  </p>
<p><strong>所以结论是： 按照效率排序的话， count(字段)&lt;count(主键id)&lt;count(1)≈count(*)， 所以我建议你， 尽量使用count(*)。</strong></p>
<h2 id="主备"><a href="#主备" class="headerlink" title="主备"></a>主备</h2><p>1.不用一次性delete太多数据，容易造成主备长时间延迟</p>
<p>2.表一定要有主键，不然会导致备库没法并行复制，退化为单线程复制，造成严重的主备延迟</p>
<p>3.读写分离时，主备延迟怎么办：</p>
<p>一般解决过期读有以下方案：</p>
<ul>
<li>强制走主库方案；</li>
<li>sleep方案；</li>
<li>判断主备无延迟方案；</li>
<li>配合semi-sync方案；</li>
<li>等主库位点方案；</li>
<li>等GTID方案;</li>
</ul>
<h2 id="Join的优化"><a href="#Join的优化" class="headerlink" title="Join的优化"></a>Join的优化</h2><p>1.使用straight_join指定关联表和被关联表</p>
<p>2.join应该总是以小表作为驱动表，<strong>小表：在决定哪个表做驱动表的时候， 应该是两个表按照各自的条件过滤， 过滤完成之后， 计算参与join的各个字段的总数据量， 数据量小的那个表， 就是“小表”， 应该作为驱动表</strong>  </p>
<p>3.启用BKA算法，可以加速。set optimizer_switch&#x3D;’mrr&#x3D;on,mrr_cost_based&#x3D;off,batched_key_access&#x3D;on’; 该算法依赖MRR机制。</p>
<p>4.通过加索引的形式，尽量使得被驱动表使用索引字段匹配，走BKA算法</p>
<h2 id="group-by-优化"><a href="#group-by-优化" class="headerlink" title="group by 优化"></a>group by 优化</h2><p>1.如果对group by语句的结果没有排序要求， 要在语句后面加 order by null；</p>
<p>2.尽量让group by过程用上表的索引， 确认方法是explain结果里没有Using temporary和 Using filesort；</p>
<p>3.如果group by需要统计的数据量不大， 尽量只使用内存临时表； 也可以通过适当调大tmp_table_size参数， 来避免用到磁盘临时表；</p>
<p>4.如果数据量实在太大， 使用SQL_BIG_RESULT这个提示， 来告诉优化器直接使用磁盘临时表，以数组的形式存储并且用排序算法得到group by的结果。  </p>
<p>5.distinct  和group by都只用于去重时，在没有limit的情况下，两者性能差不多，在有limit的情况下，distant性能更好</p>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>SQL优化</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo博客使用</title>
    <url>/2020/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/Hexo%E5%8D%9A%E5%AE%A2%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<p>1.将文章放到E:\Blog\source_posts下</p>
<p>2.执行</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">生成文件</span><br><span class="line">hexo g</span><br><span class="line">本地预览</span><br><span class="line">hexo s</span><br><span class="line">发布到服务器</span><br><span class="line">hexo d</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>工具使用</tag>
      </tags>
  </entry>
  <entry>
    <title>Idea常用插件</title>
    <url>/2021/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/Idea%E5%B8%B8%E7%94%A8%E6%8F%92%E4%BB%B6/</url>
    <content><![CDATA[<p>idea版本2021.1，有的插件在不同的idea版本下可能没有</p>
<h4 id="Alibaba-Java-Code-Guidelines"><a href="#Alibaba-Java-Code-Guidelines" class="headerlink" title="Alibaba Java Code Guidelines"></a>Alibaba Java Code Guidelines</h4><p>阿里巴巴代码规范检测。不符合代码规范的地方会有波浪线，鼠标移上去就会有相应的提示，有些问题甚至可以快速修复。</p>
<h4 id="Auto-filling-Java-call-arguments"><a href="#Auto-filling-Java-call-arguments" class="headerlink" title="Auto filling Java call arguments"></a>Auto filling Java call arguments</h4><p>调用一个函数，使用 Alt+Enter 组合键，调出 “Auto fill call parameters” 自动使用该函数定义的参数名填充。</p>
<h4 id="BashSupport-Pro"><a href="#BashSupport-Pro" class="headerlink" title="BashSupport Pro"></a>BashSupport Pro</h4><p>在idea里编写、运行shell脚本</p>
<h4 id="CamelCase"><a href="#CamelCase" class="headerlink" title="CamelCase"></a>CamelCase</h4><p>使用快捷键shift+alt+u，进行多种格式转换</p>
<img src="https://gcore.jsdelivr.net/gh/ccssbxf/img/blog/20220430143410.png" style="width: 80%;" />



<h4 id="CodeGlance"><a href="#CodeGlance" class="headerlink" title="CodeGlance"></a>CodeGlance</h4><p>代码缩略图</p>
<img src="https://gcore.jsdelivr.net/gh/ccssbxf/img/blog/20220430143448.png" style="width: 80%;" />



<h4 id="Codota"><a href="#Codota" class="headerlink" title="Codota"></a>Codota</h4><p>代码智能提示</p>
<img src="https://gcore.jsdelivr.net/gh/ccssbxf/img/blog/20220430143510.png" style="width: 80%;" />

<p>并且可查看代码的例子</p>
<img src="https://gcore.jsdelivr.net/gh/ccssbxf/img/blog/20220430143550.png" style="width: 80%;" />

<h4 id="GenerateAllSetter"><a href="#GenerateAllSetter" class="headerlink" title="GenerateAllSetter"></a>GenerateAllSetter</h4><p>通过快捷键alt+enter，自动调用所有 Setter 函数（可填充默认值）</p>
<h4 id="GenerateSerialVersionUID"><a href="#GenerateSerialVersionUID" class="headerlink" title="GenerateSerialVersionUID"></a>GenerateSerialVersionUID</h4><p>使用快捷键alt+insert，自动生成序列化 ID</p>
<img src="https://gcore.jsdelivr.net/gh/ccssbxf/img/blog/20220430143623.png" style="width: 80%;" />

<h4 id="GsonFormatPlus"><a href="#GsonFormatPlus" class="headerlink" title="GsonFormatPlus"></a>GsonFormatPlus</h4><p>JSON字符串转实体类。新建一个实体类，使用快捷键alt+s调出插件画面</p>
<img src="https://gcore.jsdelivr.net/gh/ccssbxf/img/blog/20220430143642.png" style="width: 80%;" />

<h4 id="IDE-Eval-Reset"><a href="#IDE-Eval-Reset" class="headerlink" title="IDE Eval Reset"></a>IDE Eval Reset</h4><p>idea以及其他可试用插件的破解工具，一直刷新试用期。先要在File-&gt;Settings-&gt;Plugins-&gt;设置的图标-&gt;Manage Plugin Repositories中添加仓库地址 <a href="https://plugins.zhile.io/">https://plugins.zhile.io</a></p>
<img src="https://gcore.jsdelivr.net/gh/ccssbxf/img/blog/20220430143704.png" style="width: 80%;" />

<h4 id="JRebel-and-XRebel-for-Intellij"><a href="#JRebel-and-XRebel-for-Intellij" class="headerlink" title="JRebel and XRebel for Intellij"></a>JRebel and XRebel for Intellij</h4><p>热部署插件，代码修改后按快捷键ctrl+f9编译一下代码即可生效</p>
<h4 id="LeetCode-Editor-Pro"><a href="#LeetCode-Editor-Pro" class="headerlink" title="LeetCode Editor Pro"></a>LeetCode Editor Pro</h4><p>leetcode刷题插件</p>
<h4 id="Maven-Helper"><a href="#Maven-Helper" class="headerlink" title="Maven Helper"></a>Maven Helper</h4><p>方便 maven 项目解决 jar 冲突，打开pom.xml文件，点击下方的</p>
<img src="https://gcore.jsdelivr.net/gh/ccssbxf/img/blog/20220430143732.png" style="width: 80%;" />

<p>切换到此视图即可进行相应操作：</p>
<ol>
<li><p>Conflicts（查看冲突）</p>
</li>
<li><p>All Dependencies as List（列表形式查看所有依赖）</p>
</li>
<li><p>All Dependencies as Tree（树形式查看所有依赖）</p>
<img src="https://gcore.jsdelivr.net/gh/ccssbxf/img/blog/20220430143752.png" style="width: 80%;" /></li>
</ol>
<h4 id="MyBatis-Log-Plugin"><a href="#MyBatis-Log-Plugin" class="headerlink" title="MyBatis Log Plugin"></a>MyBatis Log Plugin</h4><p>查看执行的sql语句</p>
<p>在配置文件中添加如下配置：</p>
<p>#org.apache.ibatis.logging.stdout.StdOutImpl 控制台打印 sql 语句方便调试 sql 语句执行错误<br>#org.apache.ibatis.logging.log4j2.Log4j2Impl 这个不在控制台打印查询结果，但是在 log4j 中打印<br># log-impl: org.apache.ibatis.logging.stdout.StdOutImpl<br>log-impl: org.apache.ibatis.logging.log4j2.Log4j2Impl</p>
<p>mybatis.configuration.log-impl&#x3D;org.apache.ibatis.logging.stdout.StdOutImpl</p>
<p>启动项目，只要控制台有sql语句打印，该插件都会将sql自动拼装打印出来，并且可以根据mapper.xml文件中定义的id来搜索</p>
<img src="https://gcore.jsdelivr.net/gh/ccssbxf/img/blog/20220430143816.png" style="width: 80%;" />

<h4 id="MyBatisCodeHelperPro-Marketplace-Edition"><a href="#MyBatisCodeHelperPro-Marketplace-Edition" class="headerlink" title="MyBatisCodeHelperPro(Marketplace Edition)"></a>MyBatisCodeHelperPro(Marketplace Edition)</h4><p>使用教程：<a href="https://gejun123456.github.io/MyBatisCodeHelper-Pro">https://gejun123456.github.io/MyBatisCodeHelper-Pro</a></p>
<ul>
<li><strong>通过方法名 (不需要方法的返回值和参数 会自动推导出来) 来生成 sql 可以生成大部分单表操作的 sql 只需要一个方法的名字即可 会自动补全好方法的参数和返回值 和 springdatajpa 的语句基本一致</strong></li>
<li><strong>xml sql 几乎所有地方都有自动提示，sql 正确性检测，插件会识别 mybatis 的一系列标签 如 include trim set where，在这些标签之后的 sql 可以自动提示数据库的字段，检测 sql 的正确性，从此不用担心 sql 写错</strong></li>
<li><strong>直接从 Intellij 自带的数据库或者配置一个数据库生成 crud 代码 自动检测好 useGeneratedkey 自动配置好模块的文件夹 只用添加包名就可以生成代码了</strong></li>
<li><strong>xml 代码格式化</strong></li>
<li>从 java 类生成建表语句</li>
<li>数据库添加字段后可以继续生成，不会修改之前已经在接口或 xml 添加的自定义的方法 无需再去进行手动的添加</li>
<li>mybatis 接口和 xml 的互相跳转 支持一个 mybatis 接口对应多个 xml</li>
<li>mybatis 接口中的方法名重构支持</li>
<li>xml 中的 param 的自动提示 if test 的自动提示 resultMap refid 等的自动提示</li>
<li>resultMap 中的 property 的自动提示，检测，重构</li>
<li>resultMap 中 column 自动提示，检测</li>
<li>xml 中 refid，resultMap 等的跳转到定义</li>
<li>检测没有使用的 xml 可一键删除</li>
<li>检测 mybatis 接口中方法是否有实现，没有则报红 可创建一个空的 xml</li>
<li>mybatis 接口中一键添加 param 注解</li>
<li>mybatis 接口一键生成 xml</li>
<li>完整的 typeAlias 支持</li>
<li>param 检测 检测 #{ 中的内容是否有误</li>
<li>ognl 支持 if test when test foreach bind 中的自动补全，跳转和检测</li>
<li>支持 spring 将 mapper 注入到 spring 中 intellij 的 spring 注入不再报错 支持 springboot</li>
<li>一键生成 mybatis 接口的 testcase 无需启动 spring，复杂 sql 可进行快速测试</li>
<li>一键生成表关联的 join</li>
<li>一键从 sql 语句中 导出 resultMap</li>
</ul>
<h4 id="POJO-to-JSON"><a href="#POJO-to-JSON" class="headerlink" title="POJO to JSON"></a>POJO to JSON</h4><p>实体类转json，在类里右键</p>
<img src="https://gcore.jsdelivr.net/gh/ccssbxf/img/blog/20220430143920.png" style="width: 80%;" />

<h4 id="RestfulTool"><a href="#RestfulTool" class="headerlink" title="RestfulTool"></a>RestfulTool</h4><p>找到项目里的接口，使用快捷键ctrl+alt+&#x2F;快速搜索接口</p>
<img src="https://gcore.jsdelivr.net/gh/ccssbxf/img/blog/20220430143938.png" style="width: 80%;" />

<h4 id="Translation"><a href="#Translation" class="headerlink" title="Translation"></a>Translation</h4><p>翻译</p>
<h4 id="Vue-js"><a href="#Vue-js" class="headerlink" title="Vue.js"></a>Vue.js</h4><p>开发前端vue使用</p>
<h4 id="Private-Notes"><a href="#Private-Notes" class="headerlink" title="Private Notes"></a>Private Notes</h4><p>添加注释， 按下Alt + Enter鼠标移出点击即可保存<br>已有私人注释 按下Alt + Enter即可快速编辑<br>Alt + p 可快速添加或者编辑私人注释<br>Alt + o 展示私人注释的其它操作<br>右键菜单私人注释查看操作</p>
]]></content>
      <categories>
        <category>IDE</category>
      </categories>
      <tags>
        <tag>Idea</tag>
        <tag>工具使用</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop常用命令</title>
    <url>/2021/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/Hadoop%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<h5 id="整体启动-x2F-停止-HDFS"><a href="#整体启动-x2F-停止-HDFS" class="headerlink" title="整体启动&#x2F;停止 HDFS"></a>整体启动&#x2F;停止 HDFS</h5><p>start-dfs.sh&#x2F;stop-dfs.sh </p>
<h5 id="整体启动-x2F-停止-YARN"><a href="#整体启动-x2F-停止-YARN" class="headerlink" title="整体启动&#x2F;停止 YARN"></a>整体启动&#x2F;停止 YARN</h5><p>start-yarn.sh&#x2F;stop-yarn.sh  </p>
<h5 id="分别启动-x2F-停止-HDFS-组件"><a href="#分别启动-x2F-停止-HDFS-组件" class="headerlink" title="分别启动&#x2F;停止 HDFS 组件"></a>分别启动&#x2F;停止 HDFS 组件</h5><p>hdfs –daemon start&#x2F;stop namenode&#x2F;datanode&#x2F;secondarynamenode&#x2F;zkfc&#x2F;journalnode</p>
<h5 id="启动-x2F-停止-YARN"><a href="#启动-x2F-停止-YARN" class="headerlink" title="启动&#x2F;停止 YARN"></a>启动&#x2F;停止 YARN</h5><p>yarn –daemon start&#x2F;stop resourcemanager&#x2F;nodemanager&#x2F;timelineserver&#x2F;historyserver</p>
<h5 id="查看集群可用空间，datanode存活，健康状态等"><a href="#查看集群可用空间，datanode存活，健康状态等" class="headerlink" title="查看集群可用空间，datanode存活，健康状态等"></a>查看集群可用空间，datanode存活，健康状态等</h5><p>hdfs fsck &#x2F;</p>
<p>hdfs dfsadmin -report  </p>
<h5 id="查看yarn日志"><a href="#查看yarn日志" class="headerlink" title="查看yarn日志"></a>查看yarn日志</h5><p>yarn logs -applicationId xxxxxx</p>
<h5 id="查询-Container-日志"><a href="#查询-Container-日志" class="headerlink" title="查询 Container 日志"></a>查询 Container 日志</h5><p>yarn logs -applicationId <ApplicationId> -containerId <ContainerId> </p>
<p>yarn logs -applicationId application_1665325770064_0003 -containerId container_1665325770064_0003_01_000001</p>
<h5 id="yarn-applicationattempt-查看尝试运行的任务"><a href="#yarn-applicationattempt-查看尝试运行的任务" class="headerlink" title="yarn applicationattempt 查看尝试运行的任务"></a>yarn applicationattempt 查看尝试运行的任务</h5><p>yarn applicationattempt -list <ApplicationId></p>
<h5 id="打印-ApplicationAttemp-状态"><a href="#打印-ApplicationAttemp-状态" class="headerlink" title="打印 ApplicationAttemp 状态"></a>打印 ApplicationAttemp 状态</h5><p>yarn application attempt -status <ApplicationAttemptId></p>
<h5 id="查看任务状态"><a href="#查看任务状态" class="headerlink" title="查看任务状态"></a>查看任务状态</h5><p>yarn application -status <ApplicationId></p>
<h5 id="列出所有-Application-尝试的列表"><a href="#列出所有-Application-尝试的列表" class="headerlink" title="列出所有 Application 尝试的列表"></a>列出所有 Application 尝试的列表</h5><p>yarn container -list <ApplicationAttemptId></p>
<p>只有在任务跑的途中才能看到 container 的状态，因为这个任务运行完之后，container 容器会立即释放</p>
<h5 id="打印container状态"><a href="#打印container状态" class="headerlink" title="打印container状态"></a>打印container状态</h5><p>yarn container -status <ContainerId></p>
<p>只有在任务跑的途中才能看到 container 的状态</p>
<h5 id="查看yarn节点列表"><a href="#查看yarn节点列表" class="headerlink" title="查看yarn节点列表"></a>查看yarn节点列表</h5><p>yarn node -list -all</p>
<h5 id="刷新队列配置"><a href="#刷新队列配置" class="headerlink" title="刷新队列配置"></a>刷新队列配置</h5><p>yarn rmadmin -refreshQueues</p>
<h5 id="查看队列信息"><a href="#查看队列信息" class="headerlink" title="查看队列信息"></a>查看队列信息</h5><p>yarn queue -status 队列名</p>
<h5 id="查看主备情况"><a href="#查看主备情况" class="headerlink" title="查看主备情况"></a>查看主备情况</h5><p>hdfs haadmin -getAllServiceState</p>
<p>hdfs haadmin -getServiceState nn1</p>
<h5 id="查看空间"><a href="#查看空间" class="headerlink" title="查看空间"></a>查看空间</h5><p>hdfs dfsadmin -report</p>
<h5 id="查看hbase表文件碎片数"><a href="#查看hbase表文件碎片数" class="headerlink" title="查看hbase表文件碎片数"></a>查看hbase表文件碎片数</h5><p>hadoop fs -du -h &#x2F;tablepath&#x2F;*&#x2F;F&#x2F;* | awk -F ‘&#x2F;‘ ‘{print $6}’ | uniq -c | sort -r -n -k1 | head</p>
<h5 id="yarn-application-查看任务-列出所有-Application"><a href="#yarn-application-查看任务-列出所有-Application" class="headerlink" title="yarn application 查看任务,列出所有 Application"></a>yarn application 查看任务,列出所有 Application</h5><p>yarn application -list</p>
<h5 id="yarn-application-根据状态过滤"><a href="#yarn-application-根据状态过滤" class="headerlink" title="yarn application 根据状态过滤"></a>yarn application 根据状态过滤</h5><p>yarn application -list -appStates  ALL所有状态：ALL、NEW、NEW_SAVING、SUBMITTED、ACCEPTED、RUNNING、FINISHED、FAILED、KILLED）</p>
<h5 id="kill-yarn任务"><a href="#kill-yarn任务" class="headerlink" title="kill yarn任务"></a>kill yarn任务</h5><p> yarn application -kill application_1698222012539_0002</p>
<h5 id="清空回收站"><a href="#清空回收站" class="headerlink" title="清空回收站"></a>清空回收站</h5><p>hdfs dfs -expunge</p>
<h5 id="主备切换命令"><a href="#主备切换命令" class="headerlink" title="主备切换命令"></a>主备切换命令</h5><p>hdfs haadmin -failover <active-namenode> <standby-namenode></p>
<h5 id="是否处于安全模式"><a href="#是否处于安全模式" class="headerlink" title="是否处于安全模式"></a>是否处于安全模式</h5><p>hdfs dfsadmin -safemode get</p>
<h5 id="进入安全模式"><a href="#进入安全模式" class="headerlink" title="进入安全模式"></a>进入安全模式</h5><p>hdfs dfsadmin -safemode enter</p>
<h5 id="离开安全模式"><a href="#离开安全模式" class="headerlink" title="离开安全模式"></a>离开安全模式</h5><p>hdfs dfsadmin -safemode leave</p>
<h5 id="保存元数据"><a href="#保存元数据" class="headerlink" title="保存元数据"></a>保存元数据</h5><p>hdfs dfsadmin -saveNamespace</p>
<h5 id="resourcemanager查看主备"><a href="#resourcemanager查看主备" class="headerlink" title="resourcemanager查看主备"></a>resourcemanager查看主备</h5><p>yarn rmadmin -getAllServiceState</p>
<p>yarn rmadmin -getServiceState rm1</p>
<h5 id="resourcemanager切换主备"><a href="#resourcemanager切换主备" class="headerlink" title="resourcemanager切换主备"></a>resourcemanager切换主备</h5><p> yarn rmadmin -transitionToStandby rm1</p>
<h5 id="修改hadoop-ssh端口"><a href="#修改hadoop-ssh端口" class="headerlink" title="修改hadoop ssh端口"></a>修改hadoop ssh端口</h5><p>hadoop-env.sh文件里</p>
<p>export HADOOP_SSH_OPTS&#x3D;”-p xxx”</p>
<h5 id="删除文件跳过回收站"><a href="#删除文件跳过回收站" class="headerlink" title="删除文件跳过回收站"></a>删除文件跳过回收站</h5><p>hdfs dfs -rm -r -skipTrash &#x2F;test2 </p>
<h5 id="修改副本数-w是后台进行"><a href="#修改副本数-w是后台进行" class="headerlink" title="修改副本数(-w是后台进行)"></a>修改副本数(-w是后台进行)</h5><p>hdfs dfs -setrep -R -W 3 &#x2F;test2</p>
<h5 id="查看文件的块信息"><a href="#查看文件的块信息" class="headerlink" title="查看文件的块信息"></a>查看文件的块信息</h5><p>hdfs fsck &#x2F;testdata&#x2F;a.txt -files -blocks -locations -racks</p>
<h5 id="yarn查看队列使用情况"><a href="#yarn查看队列使用情况" class="headerlink" title="yarn查看队列使用情况"></a>yarn查看队列使用情况</h5><p>yarn queue -status 队列名</p>
<h5 id="yarn查看正在执⾏的任务的容器信息"><a href="#yarn查看正在执⾏的任务的容器信息" class="headerlink" title="yarn查看正在执⾏的任务的容器信息"></a>yarn查看正在执⾏的任务的容器信息</h5><p>yarn container -list application_xxxxxx_xxx  </p>
<h5 id="查看指定容器信息"><a href="#查看指定容器信息" class="headerlink" title="查看指定容器信息"></a>查看指定容器信息</h5><p>yarn container -status container_xxxxx  </p>
<h5 id="提交任务到YARN执行"><a href="#提交任务到YARN执行" class="headerlink" title="提交任务到YARN执行"></a>提交任务到YARN执行</h5><p>yarn jar  xxxxx</p>
<h5 id="yarn查看所有节点信息"><a href="#yarn查看所有节点信息" class="headerlink" title="yarn查看所有节点信息"></a>yarn查看所有节点信息</h5><p>yarn node -all -list  </p>
<h5 id="yarn刷新队列配置"><a href="#yarn刷新队列配置" class="headerlink" title="yarn刷新队列配置"></a>yarn刷新队列配置</h5><p>yarn rmadmin -refreshQueues  </p>
<h5 id="批量删除大文件目录"><a href="#批量删除大文件目录" class="headerlink" title="批量删除大文件目录"></a>批量删除大文件目录</h5><p>hdfs dfs -find &#x2F;path&#x2F;  | xargs -n 1000 hdfs dfs -rm -skipTrash</p>
<h5 id="移动大目录文件"><a href="#移动大目录文件" class="headerlink" title="移动大目录文件"></a>移动大目录文件</h5><p>hdfs dfs -find &#x2F;zhouhj_bak&#x2F;* | xargs -t -i hdfs dfs -mv {} &#x2F;zhouhj&#x2F;</p>
<p>hdfs dfs -find &#x2F;zhouhj&#x2F; | grep -v -E “*zhouhj$” | head -n 2 | xargs -t -i -P 10 hdfs dfs -mv {} &#x2F;zhouhj_bak&#x2F;</p>
<p>date +”%Y-%m-%d %H:%M:%S” &amp;&amp; hdfs dfs -find &#x2F;zhouhj&#x2F; | grep -v -E “*zhouhj$” | head -n 100 | xargs -i -P 20 hdfs dfs -mv {} &#x2F;zhouhj_bak&#x2F; &amp;&amp; date +”%Y-%m-%d %H:%M:%S”</p>
<h5 id="HDFS文件按时间倒序排序"><a href="#HDFS文件按时间倒序排序" class="headerlink" title="HDFS文件按时间倒序排序"></a>HDFS文件按时间倒序排序</h5><p>hdfs dfs -ls &#x2F;path|sort -k6r</p>
<h5 id="命令提示"><a href="#命令提示" class="headerlink" title="命令提示"></a>命令提示</h5><p>例如hdfs dfs -find怎么使用</p>
<p>hdfs dfs -help find</p>
<h5 id="刷新节点信息"><a href="#刷新节点信息" class="headerlink" title="刷新节点信息"></a>刷新节点信息</h5><p>如节点上线 下线使用 namenode执行</p>
<p>hdfs dfsadmin -refreshNodes</p>
<p>yarn rmadmin -refreshNodes</p>
<h5 id="数据平衡"><a href="#数据平衡" class="headerlink" title="数据平衡"></a>数据平衡</h5><p>#对hdfs负载设置均衡，因为默认的数据传输带宽比较低，可以设置为64M<br>hdfs dfsadmin -setBalancerBandwidth 67108864 </p>
<p>#默认balancer的threshold为10%，即各个节点与集群总的存储使用率相差不超过10%，我们可将其设置为5%<br>start-balancer.sh -threshold 5</p>
<p>1）如果不 balance，那么 cluster 会把新的数据都存放在新的 node 上，这样会降低 mapred 的工作效率<br>2）设置平衡阈值，默认是 10%，值越低各节点越平衡，但消耗时间也更长<br>3）设置 balance 的带宽，默认只有 1M&#x2F;s</p>
<h5 id="备namenode同步主namenode操作"><a href="#备namenode同步主namenode操作" class="headerlink" title="备namenode同步主namenode操作"></a>备namenode同步主namenode操作</h5><p>hdfs namenode -bootstrapStandby</p>
<h5 id="修改运行中的yarn任务的优先级"><a href="#修改运行中的yarn任务的优先级" class="headerlink" title="修改运行中的yarn任务的优先级"></a>修改运行中的yarn任务的优先级</h5><p>yarn application -appID -updatePriority &lt;优先级&gt;</p>
]]></content>
      <categories>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>常用命令</tag>
      </tags>
  </entry>
  <entry>
    <title>Git常用命令</title>
    <url>/2021/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/Git%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<h2 id="一、git-强制提交本地分支覆盖远程分支"><a href="#一、git-强制提交本地分支覆盖远程分支" class="headerlink" title="一、git 强制提交本地分支覆盖远程分支"></a>一、git 强制提交本地分支覆盖远程分支</h2><p>git push origin 分支名 –force<br>git push origin master –force</p>
<h2 id="二、git-删除远程端文件"><a href="#二、git-删除远程端文件" class="headerlink" title="二、git 删除远程端文件"></a>二、git 删除远程端文件</h2><p>下面以删除.idea 文件为例<br>git rm –cached -r .idea</p>
<h2 id="三、git-提交代码到远程端"><a href="#三、git-提交代码到远程端" class="headerlink" title="三、git 提交代码到远程端"></a>三、git 提交代码到远程端</h2><p>git commit -m ‘提交测试’<br>git push origin master</p>
<h2 id="四、git-临时保存和恢复"><a href="#四、git-临时保存和恢复" class="headerlink" title="四、git 临时保存和恢复"></a>四、git 临时保存和恢复</h2><p>git stash<br>git stash pop</p>
<h2 id="五、git-版本合并"><a href="#五、git-版本合并" class="headerlink" title="五、git 版本合并"></a>五、git 版本合并</h2><p>git rebase –abort 会放弃合并，回到 rebase 操作之前的状态，之前的提交的不会丢弃<br>git rebase –skip 则会将引起冲突的 commits 丢弃掉（慎用！！）<br>git rebase –continue 一般情况下，修改后检查没问题，使用 rebase continue 来处理合并冲突</p>
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>常用命令</tag>
      </tags>
  </entry>
  <entry>
    <title>Hive常用命令</title>
    <url>/2022/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/Hive%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<h5 id="强制删除数据库，包括里面的表"><a href="#强制删除数据库，包括里面的表" class="headerlink" title="强制删除数据库，包括里面的表"></a>强制删除数据库，包括里面的表</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">drop</span> database database_name  cascade;  </span><br></pre></td></tr></table></figure>



<h5 id="清空表数据"><a href="#清空表数据" class="headerlink" title="清空表数据"></a>清空表数据</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">truncate</span> <span class="keyword">table</span> 表名；</span><br></pre></td></tr></table></figure>



<h5 id="beeline连接"><a href="#beeline连接" class="headerlink" title="beeline连接"></a>beeline连接</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">beeline</span><br><span class="line"></span><br><span class="line">!connect jdbc:hive2://hadoop102:10000</span><br></pre></td></tr></table></figure>



<h5 id="关闭输出压缩"><a href="#关闭输出压缩" class="headerlink" title="关闭输出压缩"></a>关闭输出压缩</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">set</span> mapreduce.output.fileoutputformat.compress<span class="operator">=</span><span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">set</span> hive.exec.compress.output<span class="operator">=</span><span class="literal">false</span>;</span><br></pre></td></tr></table></figure>



<h5 id="添加jar"><a href="#添加jar" class="headerlink" title="添加jar"></a>添加jar</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">add</span> jar hdfs:<span class="operator">/</span><span class="operator">/</span>bcdp<span class="operator">/</span>hive_udf<span class="operator">/</span>ST4<span class="number">-4.0</span><span class="number">.4</span>.jar;</span><br></pre></td></tr></table></figure>



<h5 id="删除jar"><a href="#删除jar" class="headerlink" title="删除jar"></a>删除jar</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">delete</span> jar hdfs:<span class="operator">/</span><span class="operator">/</span>bcdp<span class="operator">/</span>hive_udf<span class="operator">/</span>ST4<span class="number">-4.0</span><span class="number">.4</span>.jar;</span><br></pre></td></tr></table></figure>



<h5 id="导出数据成文件"><a href="#导出数据成文件" class="headerlink" title="导出数据成文件"></a>导出数据成文件</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">insert</span> overwrite [<span class="keyword">local</span>] directory <span class="string">&#x27;~/zhouhj/export/&#x27;</span> <span class="type">ROW</span> FORMAT DELIMITED FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;,&#x27;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> test limit <span class="number">10</span>;</span><br></pre></td></tr></table></figure>



<h5 id="查看执行计划"><a href="#查看执行计划" class="headerlink" title="查看执行计划"></a>查看执行计划</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">explain <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> course;</span><br></pre></td></tr></table></figure>



<h5 id="查看详细执行计划"><a href="#查看详细执行计划" class="headerlink" title="查看详细执行计划"></a>查看详细执行计划</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">explain extended <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> course;</span><br></pre></td></tr></table></figure>



<h5 id="hive进程jvm参数修改"><a href="#hive进程jvm参数修改" class="headerlink" title="hive进程jvm参数修改"></a>hive进程jvm参数修改</h5><p>hive-env.sh</p>
<p>export HIVE_METASTORE_HADOOP_OPTS&#x3D;”-Xmx16g”<br>export HADOOP_CLIENT_OPTS&#x3D;”-Xmx16g”<br>export HIVE_SERVER2_HADOOP_OPTS&#x3D;”-Xmx16g”</p>
<p>或者</p>
<p>hadoop-env.sh</p>
<p>export HADOOP_CLIENT_OPTS&#x3D;”xxxx”</p>
<p>该属性优先级低于hive-env.sh</p>
<h5 id="count-DISTINCT-优化"><a href="#count-DISTINCT-优化" class="headerlink" title="count(DISTINCT )优化"></a>count(DISTINCT )优化</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">day</span>,</span><br><span class="line"><span class="built_in">COUNT</span>(<span class="keyword">DISTINCT</span> id) <span class="keyword">AS</span> uv</span><br><span class="line"><span class="keyword">FROM</span> users;</span><br><span class="line"></span><br><span class="line">可以转换成：</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">day</span>,</span><br><span class="line"><span class="built_in">COUNT</span>(id) <span class="keyword">AS</span> uv</span><br><span class="line"><span class="keyword">FROM</span> (<span class="keyword">SELECT</span> <span class="keyword">day</span>,id <span class="keyword">FROM</span> users <span class="keyword">GROUP</span> <span class="keyword">BY</span> <span class="keyword">day</span>,id) a;</span><br></pre></td></tr></table></figure>



<p>– 优化前</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">Select</span> a,<span class="built_in">sum</span>(b),<span class="built_in">count</span>(<span class="keyword">distinct</span> c),<span class="built_in">count</span>(<span class="keyword">distinct</span> d) <span class="keyword">from</span> test <span class="keyword">group</span> <span class="keyword">by</span> a</span><br></pre></td></tr></table></figure>

<p>– 优化后的语句</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">Select</span> a ,<span class="built_in">sum</span>(b),count（c）,<span class="built_in">count</span>(d) <span class="keyword">from</span> (</span><br><span class="line">				<span class="keyword">Select</span> a,b,<span class="keyword">null</span> c,<span class="keyword">null</span> d <span class="keyword">from</span> test</span><br><span class="line">				<span class="keyword">Union</span> <span class="keyword">all</span></span><br><span class="line">				<span class="keyword">Select</span> a,<span class="number">0</span> b,c,<span class="keyword">null</span> d <span class="keyword">from</span> test <span class="keyword">group</span> <span class="keyword">by</span> a,c</span><br><span class="line">				<span class="keyword">Union</span> <span class="keyword">all</span></span><br><span class="line">				<span class="keyword">Select</span> a,<span class="number">0</span>,<span class="keyword">null</span> c,d <span class="keyword">from</span> test <span class="keyword">group</span> <span class="keyword">by</span> a,d</span><br><span class="line">)</span><br></pre></td></tr></table></figure>



<h5 id="关闭压缩并导出"><a href="#关闭压缩并导出" class="headerlink" title="关闭压缩并导出"></a>关闭压缩并导出</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">hive <span class="operator">-</span>e &quot;set mapreduce.output.fileoutputformat.compress=false;set hive.exec.compress.output=false;insert overwrite local directory &#x27;/home/zhouhj/test/&#x27; ROW FORMAT DELIMITED FIELDS TERMINATED BY &#x27;;&#x27; select * from test;&quot;;</span><br></pre></td></tr></table></figure>



<h5 id="建文本表"><a href="#建文本表" class="headerlink" title="建文本表"></a>建文本表</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> TEST_CREATE (</span><br><span class="line">  ID string,</span><br><span class="line">NAME string,</span><br><span class="line">AGE string</span><br><span class="line">)</span><br><span class="line"><span class="type">ROW</span> FORMAT DELIMITED</span><br><span class="line">FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;,&#x27;</span> STORED <span class="keyword">AS</span> TEXTFILE; </span><br></pre></td></tr></table></figure>



<h5 id="分组排序取topn（可用于唯一键去重）"><a href="#分组排序取topn（可用于唯一键去重）" class="headerlink" title="分组排序取topn（可用于唯一键去重）"></a>分组排序取topn（可用于唯一键去重）</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> a, b, c, e</span><br><span class="line"><span class="keyword">from</span> (<span class="keyword">select</span> a, b, c,e, <span class="built_in">row_number</span>() <span class="keyword">over</span> ( <span class="keyword">partition</span> <span class="keyword">by</span> a,b,c <span class="keyword">order</span> <span class="keyword">by</span> d <span class="keyword">desc</span> ) num</span><br><span class="line">      <span class="keyword">from</span> test) rs</span><br><span class="line"><span class="keyword">where</span> rs.num <span class="operator">=</span> <span class="number">1</span>;</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Hive</category>
      </categories>
      <tags>
        <tag>Hive</tag>
        <tag>常用命令</tag>
      </tags>
  </entry>
  <entry>
    <title>Jvm常用命令</title>
    <url>/2023/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/Jvm%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<h5 id="查看gc情况"><a href="#查看gc情况" class="headerlink" title="查看gc情况"></a>查看gc情况</h5><p>jstat [option] LVMID [interval] [count]</p>
<p>其中LVMID是进程id，interval是打印间隔时间（毫秒），count是打印次数（默认一直打印）</p>
<p>option参数解释：</p>
<p>-gc 垃圾回收堆的行为统计</p>
<p>-gccapacity 各个垃圾回收代容量(young,old,perm)和他们相应的空间统计</p>
<p>-gcutil 垃圾回收统计概述</p>
<p>-gcnew 新生代行为统计</p>
<p>-gcold 年老代和永生代行为统计</p>
<p>比如：jstat -gcutil pid 1000 1000</p>
<h5 id="查看内存使用情况"><a href="#查看内存使用情况" class="headerlink" title="查看内存使用情况"></a>查看内存使用情况</h5><p>jmap -heap pid</p>
<p>jmap -dump:format&#x3D;b,file&#x3D;&lt;文件名&gt; &lt;进程ID&gt;</p>
<p>jamp在jdk9就被取消（改为jhsdb，像以下方法使用）</p>
<p>jhsdb jmap  –heap –pid  37340</p>
<p>jhsdb jmap  –pid  37288</p>
<p>jhsdb jmap  –histo –pid  37340</p>
<p>jhsdb jmap  –binaryheap –pid  37340</p>
<h5 id="堆栈信息（jvm线程快照）"><a href="#堆栈信息（jvm线程快照）" class="headerlink" title="堆栈信息（jvm线程快照）"></a>堆栈信息（jvm线程快照）</h5><p>jstack [-l] pid</p>
<p>option参数解释：</p>
<p>-F 当使用jstack pid无响应时，强制输出线程堆栈。</p>
<p>-m 同时输出java和本地堆栈(混合模式)</p>
<p>-l 额外显示锁信息</p>
<p>比如：jstack -l pid</p>
<h5 id="查看jvm参数"><a href="#查看jvm参数" class="headerlink" title="查看jvm参数"></a>查看jvm参数</h5><p>jinfo pid</p>
<p>jinfo -flags pid</p>
<h5 id="输出jar包路径，类全名"><a href="#输出jar包路径，类全名" class="headerlink" title="输出jar包路径，类全名"></a>输出jar包路径，类全名</h5><p>jps -l</p>
<h5 id="输出main参数"><a href="#输出main参数" class="headerlink" title="输出main参数"></a>输出main参数</h5><p>jps -m</p>
<h5 id="输出相关进程启动参数"><a href="#输出相关进程启动参数" class="headerlink" title="输出相关进程启动参数"></a>输出相关进程启动参数</h5><p>jps -v</p>
<h5 id="查看内存使用情况-1"><a href="#查看内存使用情况-1" class="headerlink" title="查看内存使用情况"></a>查看内存使用情况</h5><p>jcmd 51716 GC.heap_info</p>
]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
        <tag>常用命令</tag>
      </tags>
  </entry>
  <entry>
    <title>KDC常用命令</title>
    <url>/2024/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/KDC%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<h3 id="非kadmin模式"><a href="#非kadmin模式" class="headerlink" title="非kadmin模式"></a>非kadmin模式</h3><p>进入kadmin</p>
<h6 id="kdc服务端如果有sudo权限或者root用户"><a href="#kdc服务端如果有sudo权限或者root用户" class="headerlink" title="kdc服务端如果有sudo权限或者root用户"></a>kdc服务端如果有sudo权限或者root用户</h6><p>kadmin.local</p>
<h6 id="kdc客户端"><a href="#kdc客户端" class="headerlink" title="kdc客户端"></a>kdc客户端</h6><p>kadmin -p admin&#x2F;<a href="mailto:&#97;&#100;&#x6d;&#105;&#x6e;&#x40;&#x48;&#65;&#x44;&#79;&#x4f;&#80;&#46;&#x43;&#x4f;&#x4d;">&#97;&#100;&#x6d;&#105;&#x6e;&#x40;&#x48;&#65;&#x44;&#79;&#x4f;&#80;&#46;&#x43;&#x4f;&#x4d;</a></p>
<h5 id="查看当前登录用户信息"><a href="#查看当前登录用户信息" class="headerlink" title="查看当前登录用户信息"></a>查看当前登录用户信息</h5><p>klist</p>
<h5 id="非kadmin模式直接执行admin模式命令"><a href="#非kadmin模式直接执行admin模式命令" class="headerlink" title="非kadmin模式直接执行admin模式命令"></a>非kadmin模式直接执行admin模式命令</h5><p>需要在kdc服务端并且有sudo权限或者root用户</p>
<p>kadmin.local -q “命令”，比如kadmin.local -q “listprincs”</p>
<h5 id="kdc认证"><a href="#kdc认证" class="headerlink" title="kdc认证"></a>kdc认证</h5><p>kinit -kt &#x2F;etc&#x2F;security&#x2F;keytab&#x2F;hadoop.keytab  用户名</p>
<h5 id="查看keytab文件有哪些用户"><a href="#查看keytab文件有哪些用户" class="headerlink" title="查看keytab文件有哪些用户"></a>查看keytab文件有哪些用户</h5><p>klist -kte &#x2F;etc&#x2F;security&#x2F;keytab&#x2F;hadoop.keytab</p>
<h5 id="销毁认证"><a href="#销毁认证" class="headerlink" title="销毁认证"></a>销毁认证</h5><p>kdestroy</p>
<h5 id="创建KDC数据库"><a href="#创建KDC数据库" class="headerlink" title="创建KDC数据库"></a>创建KDC数据库</h5><p>kdb5_util create -r HADOOP.COM -s</p>
<p>如果需要重建数据库，将 &#x2F;var&#x2F;kerberos&#x2F;krb5kdc 目录下的 principal 相关的文件删除即可</p>
<h5 id="销毁KDC数据库"><a href="#销毁KDC数据库" class="headerlink" title="销毁KDC数据库"></a>销毁KDC数据库</h5><p>kdbutil destroy -f</p>
<h5 id="启动-x2F-停止kdc-服务"><a href="#启动-x2F-停止kdc-服务" class="headerlink" title="启动 &#x2F;停止kdc 服务"></a>启动 &#x2F;停止kdc 服务</h5><p>systemctl start&#x2F;stop&#x2F;status krb5kdc</p>
<p>systemctl enable krb5kdc</p>
<h5 id="启动-x2F-停止-kadmin-服务"><a href="#启动-x2F-停止-kadmin-服务" class="headerlink" title="启动 &#x2F;停止 kadmin 服务"></a>启动 &#x2F;停止 kadmin 服务</h5><p>systemctl start&#x2F;stop&#x2F;status kadmin</p>
<p>systemctl enable kadmin</p>
<h5 id="修改当前登录用户密码"><a href="#修改当前登录用户密码" class="headerlink" title="修改当前登录用户密码"></a>修改当前登录用户密码</h5><p>kpasswd</p>
<h3 id="admin模式"><a href="#admin模式" class="headerlink" title="admin模式"></a>admin模式</h3><h5 id="查看所有用户"><a href="#查看所有用户" class="headerlink" title="查看所有用户"></a>查看所有用户</h5><p>listprincs</p>
<h5 id="创建用户user1并输入密码"><a href="#创建用户user1并输入密码" class="headerlink" title="创建用户user1并输入密码"></a>创建用户user1并输入密码</h5><p>addprinc user1</p>
<h5 id="创建用户user1随机密码"><a href="#创建用户user1随机密码" class="headerlink" title="创建用户user1随机密码"></a>创建用户user1随机密码</h5><p>addprinc -randkey user1</p>
<h5 id="修改指定用户的密码"><a href="#修改指定用户的密码" class="headerlink" title="修改指定用户的密码"></a>修改指定用户的密码</h5><h6 id="指定密码"><a href="#指定密码" class="headerlink" title="指定密码"></a>指定密码</h6><p>cpw -pw 新密码 user1</p>
<h6 id="随机密码"><a href="#随机密码" class="headerlink" title="随机密码"></a>随机密码</h6><p>cpw -randkey user1</p>
<h5 id="删除用户"><a href="#删除用户" class="headerlink" title="删除用户"></a>删除用户</h5><p>delprinc user1</p>
<h5 id="将对应用户添加到keytab文件"><a href="#将对应用户添加到keytab文件" class="headerlink" title="将对应用户添加到keytab文件"></a>将对应用户添加到keytab文件</h5><p>ktadd -k &#x2F;etc&#x2F;krb5.keytab user1</p>
]]></content>
      <categories>
        <category>KDC</category>
      </categories>
      <tags>
        <tag>KDC</tag>
        <tag>常用命令</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux常用命令</title>
    <url>/2021/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<h5 id="添加用户"><a href="#添加用户" class="headerlink" title="添加用户"></a>添加用户</h5><p>useradd  zhouhj</p>
<h5 id="免交互给用户设置密码"><a href="#免交互给用户设置密码" class="headerlink" title="免交互给用户设置密码"></a>免交互给用户设置密码</h5><p>echo 123456|passwd –stdin zhouhj &#x2F;&#x2F;将zhouhj用户密码设置为123456</p>
<h5 id="将zhouhj用户添加到hadoop组"><a href="#将zhouhj用户添加到hadoop组" class="headerlink" title="将zhouhj用户添加到hadoop组"></a>将zhouhj用户添加到hadoop组</h5><p>usermod -a -G hadoop zhouhj</p>
<h5 id="删除空文件"><a href="#删除空文件" class="headerlink" title="删除空文件"></a>删除空文件</h5><p>find . -type f -empty -delete</p>
<h5 id="合并一个目录下的所有文件"><a href="#合并一个目录下的所有文件" class="headerlink" title="合并一个目录下的所有文件"></a>合并一个目录下的所有文件</h5><p>find . ! -name merged_file.txt |xargs -t -i cat {}&gt;&gt; merged_file.txt</p>
<h5 id="查看网络端口使用情况"><a href="#查看网络端口使用情况" class="headerlink" title="查看网络端口使用情况"></a>查看网络端口使用情况</h5><p>netstat -tunlp</p>
<p>netstat -anp</p>
<h5 id="文本替换"><a href="#文本替换" class="headerlink" title="文本替换"></a>文本替换</h5><p>sed -i ‘s&#x2F;cdn.jsdelivr.net&#x2F;gcore.jsdelivr.net&#x2F;g’ *</p>
<h5 id="close-wait排查"><a href="#close-wait排查" class="headerlink" title="close_wait排查"></a>close_wait排查</h5><p>netstat -ans | grep -v unix | grep CLOSE_WAIT |  wc -l</p>
<h5 id="文件按大到小排序"><a href="#文件按大到小排序" class="headerlink" title="文件按大到小排序"></a>文件按大到小排序</h5><p>ll -Sh</p>
<h5 id="只显示目录"><a href="#只显示目录" class="headerlink" title="只显示目录"></a>只显示目录</h5><p> ls -d *&#x2F;</p>
<h5 id="排序时反转顺序"><a href="#排序时反转顺序" class="headerlink" title="排序时反转顺序"></a>排序时反转顺序</h5><p>ls -r</p>
<h5 id="递归列出子目录"><a href="#递归列出子目录" class="headerlink" title="递归列出子目录"></a>递归列出子目录</h5><p>ls -R</p>
<h5 id="扩展名排序"><a href="#扩展名排序" class="headerlink" title="扩展名排序"></a>扩展名排序</h5><p>ls -lX</p>
<h5 id="按修改时间排序"><a href="#按修改时间排序" class="headerlink" title="按修改时间排序"></a>按修改时间排序</h5><p>ls -lt</p>
<h5 id="grep或查找"><a href="#grep或查找" class="headerlink" title="grep或查找"></a>grep或查找</h5><p>查找error或者warn的日志</p>
<p>grep -e “error” -e “warn” log.txt</p>
<h5 id="grep正则"><a href="#grep正则" class="headerlink" title="grep正则"></a>grep正则</h5><p>grep -E </p>
<h5 id="grep忽略大小写"><a href="#grep忽略大小写" class="headerlink" title="grep忽略大小写"></a>grep忽略大小写</h5><p>grep -i</p>
<h5 id="grep包含某个字符的文件名"><a href="#grep包含某个字符的文件名" class="headerlink" title="grep包含某个字符的文件名"></a>grep包含某个字符的文件名</h5><p>grep -l </p>
<h5 id="grep搜索匹配值的附近行"><a href="#grep搜索匹配值的附近行" class="headerlink" title="grep搜索匹配值的附近行"></a>grep搜索匹配值的附近行</h5><p>后三行</p>
<p>grep -A3 hello a.txt</p>
<p>前三行</p>
<p>grep -B3 hello a.txt</p>
<p>前后三行</p>
<p>grep -C3 hello a.txt</p>
<h5 id="统计进程打开了多少个文件"><a href="#统计进程打开了多少个文件" class="headerlink" title="统计进程打开了多少个文件"></a>统计进程打开了多少个文件</h5><p>lsof -p 4671 |wc -l</p>
<p><strong>系统当前网络连接</strong></p>
<p>ss -antp &gt; $DUMP_DIR&#x2F;ss.dump 2&gt;&amp;1</p>
<p>使用 ss 命令而不是 netstat 的原因，是因为 netstat 在网络连接非常多的情况下，执行非常缓慢。</p>
<p>后续的处理，可通过查看各种网络连接状态的梳理，来排查 TIME_WAIT 或者 CLOSE_WAIT，或者其他连接过高的问题，非常有用。</p>
<p><strong>网络状态统计</strong></p>
<p>netstat -s &gt; $DUMP_DIR&#x2F;netstat-s.dump 2&gt;&amp;1</p>
<p>它能够按照各个协议进行统计输出，对把握当时整个网络状态，有非常大的作用。</p>
<p>sar -n DEV 1 2 &gt; $DUMP_DIR&#x2F;sar-traffic.dump 2&gt;&amp;1</p>
<p>在一些速度非常高的模块上，比如 Redis、Kafka，就经常发生跑满网卡的情况。表现形式就是网络通信非常缓慢。</p>
<p><strong>进程资源</strong></p>
<p>lsof -p $PID &gt; $DUMP_DIR&#x2F;lsof-$PID.dump</p>
<p>通过查看进程，能看到打开了哪些文件，可以以进程的维度来查看整个资源的使用情况，包括每条网络连接、每个打开的文件句柄。同时，也可以很容易的看到连接到了哪些服务器、使用了哪些资源。这个命令在资源非常多的情况下，输出稍慢，请耐心等待。</p>
<p><strong>CPU 资源</strong></p>
<p>mpstat &gt; $DUMP_DIR&#x2F;mpstat.dump 2&gt;&amp;1vmstat 1 3 &gt; $DUMP_DIR&#x2F;vmstat.dump 2&gt;&amp;1sar -p ALL  &gt; $DUMP_DIR&#x2F;sar-cpu.dump  2&gt;&amp;1uptime &gt; $DUMP_DIR&#x2F;uptime.dump 2&gt;&amp;1</p>
<p>主要用于输出当前系统的 CPU 和负载，便于事后排查。</p>
<p><strong>I&#x2F;O 资源</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">iostat -x &gt; $DUMP_DIR/iostat.dump 2&gt;&amp;1</span><br></pre></td></tr></table></figure>

<p>一般，以计算为主的服务节点，I&#x2F;O 资源会比较正常，但有时也会发生问题，比如日志输出过多，或者磁盘问题等。此命令可以输出每块磁盘的基本性能信息，用来排查 I&#x2F;O 问题。</p>
<h5 id="查看进程里的线程信息"><a href="#查看进程里的线程信息" class="headerlink" title="查看进程里的线程信息"></a>查看进程里的线程信息</h5><p>top -Hp $PID -b -n 1 -c</p>
<p>查看某个进程中使用 CPU 最多的某个线程，记录线程的 ID。</p>
<p>top -Hp $pid</p>
<h5 id="查看物理CPU个数"><a href="#查看物理CPU个数" class="headerlink" title="查看物理CPU个数"></a>查看物理CPU个数</h5><p>cat &#x2F;proc&#x2F;cpuinfo| grep “physical id”| sort| uniq| wc -l</p>
<h5 id="查看每个物理CPU中core的个数-即核数"><a href="#查看每个物理CPU中core的个数-即核数" class="headerlink" title="查看每个物理CPU中core的个数(即核数)"></a>查看每个物理CPU中core的个数(即核数)</h5><p>cat &#x2F;proc&#x2F;cpuinfo| grep “cpu cores”| uniq</p>
<h5 id="查看逻辑CPU的个数"><a href="#查看逻辑CPU的个数" class="headerlink" title="查看逻辑CPU的个数"></a>查看逻辑CPU的个数</h5><p>cat &#x2F;proc&#x2F;cpuinfo| grep “processor”| wc -l</p>
<h5 id="修改路径颜色和显示完整路径"><a href="#修改路径颜色和显示完整路径" class="headerlink" title="修改路径颜色和显示完整路径"></a>修改路径颜色和显示完整路径</h5><p>两边框有背景色</p>
<p>export PS1&#x3D;”[\e[40;40m][[\e[32;40m]\u[\e[37;40m]@\h [\e[36;40m]\w[\e[0m][\e[40;40m]][\e[0m]\$ “</p>
<p>两边框无背景色</p>
<p>export PS1&#x3D;”[[\e[32;40m]\u[\e[37;40m]@\h [\e[36;40m]\w[\e[0m]]$ “</p>
<h5 id="查看一级目录大小"><a href="#查看一级目录大小" class="headerlink" title="查看一级目录大小"></a>查看一级目录大小</h5><p>du -h –max-depth&#x3D;1 | sort -hr</p>
<h5 id="修改主机名"><a href="#修改主机名" class="headerlink" title="修改主机名"></a>修改主机名</h5><p>hostnamectl set-hostname hdp01</p>
<p>不需要重启主机，退出当前窗口，重新登录即可</p>
<h5 id="切换用户执行命令"><a href="#切换用户执行命令" class="headerlink" title="切换用户执行命令"></a>切换用户执行命令</h5><p>sudo su zhouhj -l -c ‘hdfs dfsadmin -safemode enter’</p>
<h5 id="shell编码转换"><a href="#shell编码转换" class="headerlink" title="shell编码转换"></a>shell编码转换</h5><p>dos2unix your_script_or_file</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>常用命令</tag>
      </tags>
  </entry>
  <entry>
    <title>Kafka常用命令</title>
    <url>/2023/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/Kafka%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<h5 id="创建主题"><a href="#创建主题" class="headerlink" title="创建主题"></a>创建主题</h5><p>kafka-topics.sh –bootstrap-server hadoop101:9092,hadoop102:9092,hadoop103:9092 –create –topic topic01 –partitions 3 –replication-factor 3</p>
<h5 id="列出主题"><a href="#列出主题" class="headerlink" title="列出主题"></a>列出主题</h5><p>kafka-topics.sh –bootstrap-server hadoop101:9092,hadoop102:9092,hadoop103:9092 –list</p>
<h5 id="查看主题信息"><a href="#查看主题信息" class="headerlink" title="查看主题信息"></a>查看主题信息</h5><p>kafka-topics.sh –bootstrap-server hadoop101:9092,hadoop102:9092,hadoop103:9092 –describe –topic topic02</p>
<h5 id="修改分区数（只能加不能减）"><a href="#修改分区数（只能加不能减）" class="headerlink" title="修改分区数（只能加不能减）"></a>修改分区数（只能加不能减）</h5><p>kafka-topics.sh –bootstrap-server hadoop101:9092,hadoop102:9092,hadoop103:9092 –alter –topic topic01 –partitions 4</p>
<h5 id="删除主题"><a href="#删除主题" class="headerlink" title="删除主题"></a>删除主题</h5><p>kafka-topics.sh –bootstrap-server hadoop101:9092,hadoop102:9092,hadoop103:9092 –delete –topic topic01</p>
<h5 id="消费"><a href="#消费" class="headerlink" title="消费"></a>消费</h5><p>kafka-console-consumer.sh –bootstrap-server hadoop101:9092,hadoop102:9092,hadoop103:9092 –topic topic01 –group g1 –property print.key&#x3D;true –property print.value&#x3D;true –property key.separator&#x3D;,</p>
<h5 id="从begin开始消费"><a href="#从begin开始消费" class="headerlink" title="从begin开始消费"></a>从begin开始消费</h5><p>kafka-console-consumer.sh –bootstrap-server hadoop101:9092,hadoop102:9092,hadoop103:9092 –topic topic01 –group g1 –from-beginning</p>
<h5 id="生产"><a href="#生产" class="headerlink" title="生产"></a>生产</h5><p>kafka-console-producer.sh –bootstrap-server hadoop101:9092,hadoop102:9092,hadoop103:9092 –topic topic01</p>
<h5 id="查看组列表"><a href="#查看组列表" class="headerlink" title="查看组列表"></a>查看组列表</h5><p>kafka-consumer-groups.sh –bootstrap-server hadoop101:9092,hadoop102:9092,hadoop103:9092 –list</p>
<h5 id="查看组信息"><a href="#查看组信息" class="headerlink" title="查看组信息"></a>查看组信息</h5><p>kafka-consumer-groups.sh –bootstrap-server hadoop101:9092,hadoop102:9092,hadoop103:9092 –describe –group g1</p>
<h5 id="查看和集群不一样配置的主题"><a href="#查看和集群不一样配置的主题" class="headerlink" title="查看和集群不一样配置的主题"></a>查看和集群不一样配置的主题</h5><p>kafka-topics.sh –bootstrap-server hadoop101:9092,hadoop102:9092,hadoop103:9092 –describe –topics-with-overrides</p>
<h5 id="找出所有包含失效副本的分区"><a href="#找出所有包含失效副本的分区" class="headerlink" title="找出所有包含失效副本的分区"></a>找出所有包含失效副本的分区</h5><p>kafka-topics.sh –bootstrap-server hadoop101:9092,hadoop102:9092,hadoop103:9092 –describe –topic topic02 –under-replicated-partitions</p>
<h5 id="查看主题中没有-leader-副本的分区"><a href="#查看主题中没有-leader-副本的分区" class="headerlink" title="查看主题中没有 leader 副本的分区"></a>查看主题中没有 leader 副本的分区</h5><p>kafka-topics.sh –bootstrap-server hadoop101:9092,hadoop102:9092,hadoop103:9092 –describe –topic topic02 –unavailable-partitions</p>
]]></content>
      <categories>
        <category>Kafka</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
        <tag>常用命令</tag>
      </tags>
  </entry>
  <entry>
    <title>Phoenix常用命令</title>
    <url>/2023/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/Phoenix%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<h5 id="连接转换属性"><a href="#连接转换属性" class="headerlink" title="连接转换属性"></a>连接转换属性</h5><p>phoenix.schema.isNamespaceMappingEnabled&#x3D;true</p>
<p>phoenix.schema.mapSystemTablesToNamespace&#x3D;true</p>
<h5 id="查看表"><a href="#查看表" class="headerlink" title="查看表"></a>查看表</h5><p>!tables</p>
<h5 id="查看当前连接数"><a href="#查看当前连接数" class="headerlink" title="查看当前连接数"></a>查看当前连接数</h5><p>!list</p>
<h5 id="插入语句"><a href="#插入语句" class="headerlink" title="插入语句"></a>插入语句</h5><p>UPSERT INTO TEST (ID, COUNTER) VALUES (123, 0);</p>
<p>upsert into STUDENT values(‘rowkey’,’field1’,’field2’);</p>
<h5 id="建表语句"><a href="#建表语句" class="headerlink" title="建表语句"></a>建表语句</h5><p>CREATE TABLE IF NOT EXISTS TEST (<br> ID VARCHAR NOT NULL PRIMARY KEY,<br>F.A varchar,<br>F.B varchar,<br>F.C varchar<br>);</p>
]]></content>
      <categories>
        <category>Phoenix</category>
      </categories>
      <tags>
        <tag>Phoenix</tag>
        <tag>常用命令</tag>
      </tags>
  </entry>
  <entry>
    <title>复杂度分析</title>
    <url>/2020/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<h3 id="一：什么是复杂度分析"><a href="#一：什么是复杂度分析" class="headerlink" title="一：什么是复杂度分析"></a>一：什么是复杂度分析</h3><ol>
<li><p>数据结构和算法主要解决的是“如何让代码运行的更快，更省存储空间的问题”</p>
</li>
<li><p>因此需要从时间和空间两个维度来评判算法的执行效率</p>
</li>
<li><p>对此引入了时间复杂度、空间复杂度的概念来衡量算法的执行效率</p>
</li>
</ol>
<h3 id="二：为什么需要复杂度分析"><a href="#二：为什么需要复杂度分析" class="headerlink" title="二：为什么需要复杂度分析"></a>二：为什么需要复杂度分析</h3><ol>
<li>和性能测试相比，复杂度分析有不依赖执行环境、成本低、效率高、易操作、指导性强的特点</li>
<li>掌握复杂度分析，将能编写出性能更优的代码，有利于降低系统开发和维护成本</li>
</ol>
<h3 id="三：怎么进行复杂度分析"><a href="#三：怎么进行复杂度分析" class="headerlink" title="三：怎么进行复杂度分析"></a>三：怎么进行复杂度分析</h3><ol>
<li><p>大 O复杂度表示法</p>
<p>1）来源</p>
<p>算法的执行时间与每行代码的执行次数成正比，用 T (n) &#x3D; O (f (n)) 表示，其中 T (n) 表示算法执行总时间，f (n) 表示每行代码执行总次数，而 n 往往表示数据的规模。 </p>
<p>2）特点 </p>
<p>以时间复杂度为例，由于时间复杂度描述的是算法执行时间与数据规模的增长变化趋势，所以常量阶、低阶以及系数实际上对这种增长趋势不产决定性影响，所以在做时间复杂度分析时忽略这些项。</p>
</li>
<li><p>复杂度分析法则</p>
<p>1）单段代码看高频：比如循环。 </p>
<p>2）多段代码取最大：比如一段代码中有单循环和多重循环，那么取多重循环的复杂度。 </p>
<p>3）嵌套代码求乘积：比如递归、多重循环等 </p>
<p>4）多个规模求加法：比如方法有两个参数控制两个循环的次数，那么这时就取二者复杂度相加。</p>
</li>
</ol>
<h3 id="四：常用的复杂度级别"><a href="#四：常用的复杂度级别" class="headerlink" title="四：常用的复杂度级别"></a>四：常用的复杂度级别</h3><ol>
<li><p>多项式阶</p>
<p>随着数据规模的增长，算法的执行时间和空间占用，按照多项式的比例增长。包括， O (1)（常数阶）、O (logn)（对数阶）、O (n)（线性阶）、O (nlogn)（线性对数阶）、O (n^2)（平方阶）、O (n^3)（立方阶）</p>
</li>
<li><p>非多项式阶</p>
<p>随着数据规模的增长，算法的执行时间和空间占用暴增，这类算法性能极差。包括， O (2^n)（指数阶）、O (n!)（阶乘阶）</p>
</li>
</ol>
<h3 id="五：复杂度分析的-4-个概念"><a href="#五：复杂度分析的-4-个概念" class="headerlink" title="五：复杂度分析的 4 个概念"></a>五：复杂度分析的 4 个概念</h3><ol>
<li><p>四个复杂度概念</p>
<p>1）最坏情况时间复杂度：代码在最理想情况下执行的时间复杂度。 </p>
<p>2）最好情况时间复杂度：代码在最坏情况下执行的时间复杂度。 </p>
<p>3）平均时间复杂度：用代码在所有情况下执行的次数的加权平均值表示。</p>
<p>4）均摊时间复杂度：在代码执行的所有复杂度情况中绝大部分是低级别的复杂度，个别情况是高级别复杂度且发生具有时序关系时，可以将个别高级别复杂度均摊到低级别复杂度上。基本上均摊结果就等于低级别复杂度。</p>
</li>
<li><p>为什么要引入这4个概念</p>
<p>1）同一段代码在不同情况下时间复杂度会出现量级差异，为了更全面，更准确的描述代码的时间复杂度，所以引入这 4 个概念。 </p>
<p>2）代码复杂度在不同情况下出现量级差别时才需要区别这四种复杂度。大多数情况下，是不需要区别分析它们的。</p>
</li>
<li><p>如何分析平均、均摊时间复杂度</p>
<p>1） 平均时间复杂度 </p>
<p>代码在不同情况下复杂度出现量级差别，则用代码所有可能情况下执行次数的加权平均值表示。</p>
<p>2）均摊时间复杂度</p>
<p>两个条件满足时使用：1）代码在绝大多数情况下是低级别复杂度，只有极少数情况是高级别复杂度；2）低级别和高级别复杂度出现具有时序规律。均摊结果一般都等于低级别复杂度。</p>
</li>
</ol>
<h3 id="六：如何掌握好复杂度分析方法"><a href="#六：如何掌握好复杂度分析方法" class="headerlink" title="六：如何掌握好复杂度分析方法"></a>六：如何掌握好复杂度分析方法</h3><p>复杂度分析关键在于多练，所谓孰能生巧。</p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>复杂度</tag>
      </tags>
  </entry>
  <entry>
    <title>Java应用对接Kerberos</title>
    <url>/2024/%E5%A4%A7%E6%95%B0%E6%8D%AE/Java%E5%BA%94%E7%94%A8%E5%AF%B9%E6%8E%A5Kerberos/</url>
    <content><![CDATA[<p>1.首先需要在KDC服务器上建立用户以及生成对应的keytab文件</p>
<p>比如用户：<a href="mailto:&#122;&#x68;&#111;&#117;&#104;&#x6a;&#x2d;&#109;&#x79;&#99;&#108;&#x75;&#x73;&#116;&#101;&#x72;&#x40;&#72;&#65;&#x44;&#x4f;&#79;&#80;&#46;&#x43;&#x4f;&#77;">&#122;&#x68;&#111;&#117;&#104;&#x6a;&#x2d;&#109;&#x79;&#99;&#108;&#x75;&#x73;&#116;&#101;&#x72;&#x40;&#72;&#65;&#x44;&#x4f;&#79;&#80;&#46;&#x43;&#x4f;&#77;</a></p>
<p>keytab文件：smokeuser.headless.keytab</p>
<p>2.将KDC服务器的krb5.conf文件和smokeuser.headless.keytab文件下载到本地</p>
<p>3.在配置文件中配置krb5.conf文件和smokeuser.headless.keytab文件所在路径，以及kerberos认证的用户名</p>
<p>4.kerberos认证代码</p>
<p>读取配置文件中配置的krb5.conf文件和smokeuser.headless.keytab文件所在路径，以及kerberos认证的用户名，传入以下方法即可认证成功</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * kerberos登录</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> config 配置</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> krb5ConfPath krb5.conf文件路径</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> keyTabPath keytab文件路径</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> principal 用户名</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">login</span><span class="params">(Configuration config, String krb5ConfPath, String keyTabPath, String principal)</span> &#123;</span><br><span class="line">    log.info(<span class="string">&quot;start login kerberos ...&quot;</span>);</span><br><span class="line">    log.info(<span class="string">&quot;krb5.conf file path:&quot;</span> + krb5ConfPath);</span><br><span class="line">    log.info(<span class="string">&quot;keytab file path:&quot;</span> + keyTabPath);</span><br><span class="line">    log.info(<span class="string">&quot;principal:&quot;</span> + principal);</span><br><span class="line">    System.setProperty(<span class="string">&quot;java.security.krb5.conf&quot;</span>, krb5ConfPath);</span><br><span class="line">    config.set(<span class="string">&quot;hadoop.security.authentication&quot;</span>, <span class="string">&quot;Kerberos&quot;</span>);</span><br><span class="line">    UserGroupInformation.setConfiguration(config);</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        UserGroupInformation.loginUserFromKeytab(principal, keyTabPath);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        log.error(<span class="string">&quot;kerberos login error...&quot;</span>, e);</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(<span class="string">&quot;kerberos login error...&quot;</span>, e);</span><br><span class="line">    &#125;</span><br><span class="line">    log.info(<span class="string">&quot;login kerberos success!&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>注：在项目启动时就进行kerberos认证，之后在项目中的连接Hdfs、HBase、Hive、Phoenix等相关操作就可以正常进行了</p>
<p>默认kerberos认证24小时过期，由KDC服务器的krb5.conf里的ticket_lifetime配置项决定。如果使用的是Hadoop3.X版本，源码里带有自动续期，只要上述认证通过之后就不用管了。如果使用的是低于Hadoop3.X版本的话，则需要程序进行续期。代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 定时更新kerberos认证凭证</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> initialDelay 第一次执行的延迟</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> delay 后续每次执行的间隔</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> timeUnit 时间单位</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title function_">startCheckKeytabTgtAndReloginJob</span><span class="params">(<span class="type">int</span> initialDelay, <span class="type">int</span> delay, TimeUnit timeUnit)</span> &#123;</span><br><span class="line">    <span class="type">ScheduledExecutorService</span> <span class="variable">scheduleExec</span> <span class="operator">=</span> Executors.newScheduledThreadPool(<span class="number">1</span>);</span><br><span class="line">    <span class="comment">//循环 达到距离到期时间一定范围就会更新凭证</span></span><br><span class="line">    scheduleExec.scheduleWithFixedDelay(() -&gt; &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="type">UserGroupInformation</span> <span class="variable">loginUser</span> <span class="operator">=</span> UserGroupInformation.getLoginUser();</span><br><span class="line">            <span class="type">Method</span> <span class="variable">getTgtMethod</span> <span class="operator">=</span> loginUser.getClass().getDeclaredMethod(<span class="string">&quot;getTGT&quot;</span>);</span><br><span class="line">            getTgtMethod.setAccessible(<span class="literal">true</span>);</span><br><span class="line">            log.info(<span class="string">&quot;tgt before relogin,endTime:&quot;</span> + ((KerberosTicket) getTgtMethod.invoke(loginUser)).getEndTime());</span><br><span class="line">            UserGroupInformation.getLoginUser().checkTGTAndReloginFromKeytab();</span><br><span class="line">            log.info(<span class="string">&quot;tgt after relogin,endTime:&quot;</span> + ((KerberosTicket) getTgtMethod.invoke(loginUser)).getEndTime());</span><br><span class="line">            log.info(<span class="string">&quot;Check Kerberos Tgt And Relogin From Keytab Finish.&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            log.error(<span class="string">&quot;Check Kerberos Tgt And Relogin From Keytab Error&quot;</span>, e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;, initialDelay, delay, timeUnit);</span><br><span class="line">    log.info(<span class="string">&quot;Start Check Keytab TGT And Relogin Job Success.&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>当前时间距离上一次认证时间，超过过期时长（krb5.conf里的ticket_lifetime）80%的时候，会进行续期</p>
<p>注：Java代码进行KDC认证时，默认使用udp协议，如果和KDC服务器的端口tcp通，udp不通的话，需要禁用udp使其使用tcp。在下载下来的krb5.conf里的[libdefaults]下加配置项udp_preference_limit &#x3D; 1</p>
<img src="https://testingcf.jsdelivr.net/gh/ccssbxf/img@master/blog/20240606205146.png" alt="image-20240606205139589" style="zoom:50%;" />]]></content>
      <categories>
        <category>Kerberos</category>
      </categories>
      <tags>
        <tag>Kerberos</tag>
      </tags>
  </entry>
  <entry>
    <title>HBase常用命令</title>
    <url>/2022/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/HBase%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<h5 id="表记录条数"><a href="#表记录条数" class="headerlink" title="表记录条数"></a>表记录条数</h5><p>count “usertable”, INTERVAL &#x3D;&gt; 100000</p>
<h5 id="scan-查询"><a href="#scan-查询" class="headerlink" title="scan 查询"></a>scan 查询</h5><h6 id="根据rowkey范围扫描"><a href="#根据rowkey范围扫描" class="headerlink" title="根据rowkey范围扫描"></a>根据rowkey范围扫描</h6><p>scan ‘tablename’,{STARTROW &#x3D;&gt; ‘1001’,STOPROW&#x3D;&gt;’2001’}</p>
<h6 id="限制条数"><a href="#限制条数" class="headerlink" title="限制条数"></a>限制条数</h6><p>scan ‘test’,{LIMIT &#x3D;&gt; 1}</p>
<h6 id="查某个字段"><a href="#查某个字段" class="headerlink" title="查某个字段"></a>查某个字段</h6><p>scan ‘test’,{COLUMNS &#x3D;&gt; ‘cf:a’,LIMIT &#x3D;&gt; 2}</p>
<h6 id="从指定行开始取几条"><a href="#从指定行开始取几条" class="headerlink" title="从指定行开始取几条"></a>从指定行开始取几条</h6><p>scan ‘test’,{STARTROW &#x3D;&gt; ‘1001’,LIMIT&#x3D;&gt;5}</p>
<h5 id="检测集群监控"><a href="#检测集群监控" class="headerlink" title="检测集群监控"></a>检测集群监控</h5><p>hbase hbck</p>
<h5 id="检测hfile"><a href="#检测hfile" class="headerlink" title="检测hfile"></a>检测hfile</h5><p>hbase hfile -h -f &#x2F;hfile路径</p>
<h5 id="查看hbase参数"><a href="#查看hbase参数" class="headerlink" title="查看hbase参数"></a>查看hbase参数</h5><p>hbase org.apache.hadoop.hbase.HBaseConfiguration get</p>
<h5 id="统计hfile数量"><a href="#统计hfile数量" class="headerlink" title="统计hfile数量"></a>统计hfile数量</h5><h6 id="统计一张表有多少个hfile"><a href="#统计一张表有多少个hfile" class="headerlink" title="统计一张表有多少个hfile"></a>统计一张表有多少个hfile</h6><p>hadoop fs -ls  &#x2F;hbase&#x2F;data&#x2F;default&#x2F;tablename&#x2F;*&#x2F;F&#x2F;* | wc -l &amp;&amp; date +”%Y-%m-%d %H:%M:%S”</p>
<h6 id="按region统计hfile"><a href="#按region统计hfile" class="headerlink" title="按region统计hfile"></a>按region统计hfile</h6><p>hadoop fs -du -h &#x2F;apps&#x2F;hbase&#x2F;data&#x2F;data&#x2F;default&#x2F;tablename&#x2F;*&#x2F;F&#x2F;* |awk -F ‘&#x2F;‘ ‘{print $8}’|sort|uniq -c|awk ‘{print $1}’|sort|uniq -c</p>
<h5 id="节点退役"><a href="#节点退役" class="headerlink" title="节点退役"></a>节点退役</h5><p>graceful_stop.sh node1</p>
<h5 id="查看状态"><a href="#查看状态" class="headerlink" title="查看状态"></a>查看状态</h5><p>hbase shell里执行</p>
<p>status</p>
<p>status ‘detailed’</p>
<h5 id="创建命名空间"><a href="#创建命名空间" class="headerlink" title="创建命名空间"></a>创建命名空间</h5><p>create_namespace ‘UD’</p>
<h5 id="查看有哪些命名空间"><a href="#查看有哪些命名空间" class="headerlink" title="查看有哪些命名空间"></a>查看有哪些命名空间</h5><p>list_namespace</p>
<h5 id="删除命名空间"><a href="#删除命名空间" class="headerlink" title="删除命名空间"></a>删除命名空间</h5><p>命名空间必须为空才能被删除</p>
<p>drop_namespace ‘UD’</p>
<h5 id="查看有哪些表"><a href="#查看有哪些表" class="headerlink" title="查看有哪些表"></a>查看有哪些表</h5><p>查看某个命名空间下的表</p>
<p>list_namespace_tables  ‘ns1’</p>
<p>查看所有表</p>
<p>list</p>
<h5 id="建表语句"><a href="#建表语句" class="headerlink" title="建表语句"></a>建表语句</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="string">&#x27;UD:TEST_CREATE&#x27;</span>,&#123;NAME <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;F&#x27;</span>, VERSIONS <span class="operator">=</span><span class="operator">&gt;</span> <span class="number">1</span>,BLOOMFILTER <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;ROW&#x27;</span>,TTL <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;FOREVER&#x27;</span>, BLOCKSIZE <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;65536&#x27;</span>, DATA_BLOCK_ENCODING <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;FAST_DIFF&#x27;</span>, IN_MEMORY <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;false&#x27;</span>,BLOCKCACHE <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;true&#x27;</span>, COMPRESSION <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;SNAPPY&#x27;</span>,METADATA <span class="operator">=</span><span class="operator">&gt;</span> &#123;<span class="string">&#x27;COMPRESSION_COMPACT&#x27;</span> <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;SNAPPY&#x27;</span>,<span class="string">&#x27;IN_MEMORY_COMPACTION&#x27;</span> <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;BASIC&#x27;</span>&#125;&#125;, &#123;NUMREGIONS <span class="operator">=</span><span class="operator">&gt;</span> <span class="number">10</span>, SPLITALGO <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;HexStringSplit&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">create</span> <span class="string">&#x27;table_name&#x27;</span>, <span class="string">&#x27;column_family&#x27;</span></span><br></pre></td></tr></table></figure>

<h5 id="插入数据"><a href="#插入数据" class="headerlink" title="插入数据"></a>插入数据</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">put <span class="string">&#x27;UD:TEST_CREATE&#x27;</span>, <span class="string">&#x27;row1&#x27;</span>, <span class="string">&#x27;F:NAME&#x27;</span>, <span class="string">&#x27;zs&#x27;</span></span><br></pre></td></tr></table></figure>

<h5 id="禁用表"><a href="#禁用表" class="headerlink" title="禁用表"></a>禁用表</h5><p>disable ‘table_name’</p>
<p>is_disabled ‘tablename’</p>
<h5 id="启用表"><a href="#启用表" class="headerlink" title="启用表"></a>启用表</h5><p>enable ‘table_name’</p>
<p>is_enabled ‘tablename’</p>
<h5 id="查看表结构信息"><a href="#查看表结构信息" class="headerlink" title="查看表结构信息"></a>查看表结构信息</h5><p>describe ‘table_name’</p>
<h5 id="删除表"><a href="#删除表" class="headerlink" title="删除表"></a>删除表</h5><p>需要先禁用表</p>
<p>drop ‘table_name’</p>
<h5 id="根据rowkey获取数据"><a href="#根据rowkey获取数据" class="headerlink" title="根据rowkey获取数据"></a>根据rowkey获取数据</h5><p>get ‘table_name’, ‘row_key’</p>
<p>get ‘table_name’, ‘row_key’,’列族:列名’</p>
<h5 id="表是否存在"><a href="#表是否存在" class="headerlink" title="表是否存在"></a>表是否存在</h5><p>exists ‘tablename’</p>
<h5 id="删除数据"><a href="#删除数据" class="headerlink" title="删除数据"></a>删除数据</h5><p>删除某个rowkey的所有数据</p>
<p>deleteall ‘tablename’,’rowkey’</p>
<p>删除某 rowkey 的某一列数据</p>
<p>delete ‘table_name’, ‘row_key’, ‘column_family:column’</p>
<p>delete ‘test’, ‘row1’,’cf:a’</p>
<h5 id="清空表"><a href="#清空表" class="headerlink" title="清空表"></a>清空表</h5><p>truncate ‘tablename’</p>
<p>先disable，然后再truncate</p>
<h5 id="HMaster单机启停"><a href="#HMaster单机启停" class="headerlink" title="HMaster单机启停"></a>HMaster单机启停</h5><p> hbase-daemon.sh start master<br> hbase-daemon.sh stop master</p>
<p>切记 daemon后没有S，daemons是集群启停</p>
<h5 id="HRegionServer单机启停"><a href="#HRegionServer单机启停" class="headerlink" title="HRegionServer单机启停"></a>HRegionServer单机启停</h5><p>hbase-daemon.sh start regionserver<br>hbase-daemon.sh stop  regionserver </p>
<h5 id="region-均衡balancer"><a href="#region-均衡balancer" class="headerlink" title="region 均衡balancer"></a>region 均衡balancer</h5><p>$ hbase shell<br>  hbase(main):001:0&gt;  balance_switch true<br>  hbase(main):002:0&gt; balancer </p>
<h5 id="HBase表合并"><a href="#HBase表合并" class="headerlink" title="HBase表合并"></a>HBase表合并</h5><p>$ hbase shell</p>
<p>hbase(main):004:0&gt; major_compact “tablename”</p>
<h5 id="查看建表语句"><a href="#查看建表语句" class="headerlink" title="查看建表语句"></a>查看建表语句</h5><p>describe “table_name”</p>
<h5 id="查看有哪些线程（比如compact线程）"><a href="#查看有哪些线程（比如compact线程）" class="headerlink" title="查看有哪些线程（比如compact线程）"></a>查看有哪些线程（比如compact线程）</h5><p>processlist</p>
<h5 id="查看版本"><a href="#查看版本" class="headerlink" title="查看版本"></a>查看版本</h5><p>version</p>
<h5 id="查看Procedure-和-Locks-的列表"><a href="#查看Procedure-和-Locks-的列表" class="headerlink" title="查看Procedure 和 Locks 的列表"></a>查看Procedure 和 Locks 的列表</h5><p>list_procedures</p>
]]></content>
      <categories>
        <category>HBase</category>
      </categories>
      <tags>
        <tag>HBase</tag>
        <tag>常用命令</tag>
      </tags>
  </entry>
  <entry>
    <title>HBase Region分裂策略之SteppingSplitPolicy</title>
    <url>/2023/%E5%A4%A7%E6%95%B0%E6%8D%AE/HBase%20Region%E5%88%86%E8%A3%82%E7%AD%96%E7%95%A5%E4%B9%8BSteppingSplitPolicy/</url>
    <content><![CDATA[<h2 id="参数配置"><a href="#参数配置" class="headerlink" title="参数配置"></a>参数配置</h2><p>HBase分裂策略配置项为：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">HBase2.X版本开始，分裂策略默认为SteppingSplitPolicy，一般也比较推荐设置为SteppingSplitPolicy。</span><br><span class="line">该策略使得小表不会产生过多的Region</span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.regionserver.region.split.policy<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.hbase.regionserver.SteppingSplitPolicy<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="策略说明"><a href="#策略说明" class="headerlink" title="策略说明"></a>策略说明</h2><p>SteppingSplitPolicy策略Region分裂的阈值大小和待分裂Region所属表在当前RegionServer上的Region个数有关系。</p>
<p>如果当前待分裂Region的所属表在当前RegionServer上的个数等于1，则分裂的阈值为flushSize(hbase.hregion.memstore.flush.size)*2,否则为MaxRegionFileSize(hbase.hregion.max.filesize)。</p>
<h2 id="举例"><a href="#举例" class="headerlink" title="举例"></a>举例</h2><p>比如有以下配置</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"> <span class="comment">&lt;!-- region 分裂策略类 --&gt;</span></span><br><span class="line"> <span class="comment">&lt;!-- SteppingSplitPolicy ：2.0版本默认分裂策略 --&gt;</span></span><br><span class="line"> <span class="comment">&lt;!-- 分裂阈值大小和待分裂Region所属表在当前RegionServer上的Region个数有关系，如果Region个数等于1，分裂阈值为flush size * 2，否则为MaxRegionFileSize --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.regionserver.region.split.policy<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.hbase.regionserver.SteppingSplitPolicy<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- MemStore的大小上限，当Region中任意一个MemStore的大小达到了上限（hbase.hregion.memstore.f lush.size，默认128MB），会触发MemStore刷新。 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.hregion.memstore.flush.size<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>268435456<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>default=134217728(128M)<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Region 中最大的 Store 中所有文件大小一旦大于该值，整个 Region 就会执行分裂 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.hregion.max.filesize<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>32212254720<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>default=10G=10737418240;30G=32212254720;40G=42949672960;60G=64424509440<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>由配置可得，flushSize&#x3D;256M，MaxRegionFileSize&#x3D;30G。</p>
<p>假设集群RegionServer个数为100，某TEST表的预分区Region为50个。</p>
<p>理想情况下，根据HBase的负载均衡策略，这50个Region会分配在不同的RegionServer上，此时该表的Region所在的RegionServer上，TEST表的Region只有一个。</p>
<p>当不断往TEST表写入数据时，当50个Region中有一个Region被写满了512M（2*256M）时，该Region会进行分裂，理想情况下两个Region会被分配到不同的RegionServer上。</p>
<p>当TEST的总Region个数为101时（认为其中99台RegionServer上该表的Region个数为1,1台RegionServer上该表的Region个数为2），则那99台还是当Region大小到大512M时进行分裂，那1台上的两个Region则要到30G才会进行分裂</p>
<p>注：根据该分裂特性以及数据量大小，可作为HBase建表预分区个数的依据，尽量避免分裂</p>
]]></content>
      <categories>
        <category>HBase</category>
      </categories>
      <tags>
        <tag>HBase</tag>
        <tag>Region</tag>
        <tag>Split</tag>
      </tags>
  </entry>
  <entry>
    <title>Yarn公平调度器</title>
    <url>/2023/%E5%A4%A7%E6%95%B0%E6%8D%AE/Yarn%E5%85%AC%E5%B9%B3%E8%B0%83%E5%BA%A6%E5%99%A8/</url>
    <content><![CDATA[<h2 id="一：指定调度器"><a href="#一：指定调度器" class="headerlink" title="一：指定调度器"></a>一：指定调度器</h2><p>Yarn一共提供了三种资源调度器，分别是<code>FIFO Scheduler（先进先出调度器）</code> ，<code>Capacity Scheduler（容量调度器）</code>，<code>Fair Scheduler（公平调度器）</code>。</p>
<p>Apache版本的默认调度器是<code>Capacity Scheduler（容量调度器）</code>，指定调度器的配置项在yarn-site.xml中。</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.scheduler.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- Path to allocation file,  the file is searched for on the classpath --&gt;</span></span><br><span class="line"><span class="comment">&lt;!--指定公平调度器配置文件--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.fair.allocation.file<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- 如果不指定全路径，表示在HADOOP_CONF路径下；通常指定全路径 --&gt;</span>  </span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>fair-scheduler.xml<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>若没有 <code>fair-scheduler.xml</code> 这个配置文件，Fair Scheduler 采用的分配策略：<strong>调度器会在用户提交第一个应用时为其自动创建一个队列，队列的名字就是用户名，所有的应用都会被分配到相应的用户队列中。</strong></p>
<h2 id="二：调度器配置"><a href="#二：调度器配置" class="headerlink" title="二：调度器配置"></a>二：调度器配置</h2><h3 id="1-调度器说明"><a href="#1-调度器说明" class="headerlink" title="1.调度器说明"></a>1.调度器说明</h3><p>FairScheduler 将应用组织到队列中，并在这些队列之间公平地共享资源。默认情况下，所有用户共享一个名为 default 的队列。如果应用明确在容器资源请求中指定了队列，则该请求将提交到指定的队列。可以通过配置，根据请求中包含的用户名或组分配队列。在每个队列中，使用调度策略在运行的应用程序之间共享资源。默认设置是基于内存的公平共享，但是也可以配置具有优势资源公平性的 FIFO 和多资源。</p>
<ul>
<li><p>分层队列： 队列可以按层次结构排列以划分资源，并可以配置权重以按特定比例共享集群。</p>
</li>
<li><p>基于用户或组的队列映射： 可以根据提交任务的用户名或组来分配队列。如果任务指定了一个队列，则在该队列中提交任务。</p>
</li>
<li><p>资源抢占： 根据应用的配置，抢占和分配资源可以是友好的或是强制的。默认不启用资源抢占。</p>
</li>
<li><p>保证最小配额： 可以设置队列最小资源，允许将保证的最小份额分配给队列，保证用户可以启动任务。当队列不能满足最小资源时，可以从其它队列抢占。当队列资源使用不完时，可以给其它队列使用。这对于确保某些用户、组或生产应用始终获得足够的资源。</p>
</li>
<li><p>允许资源共享： 即当一个应用运行时，如果其它队列没有任务执行，则可以使用其它队列，当其它队列有应用需要资源时再将占用的队列释放出来。所有的应用都从资源队列中分配资源。</p>
</li>
<li><p>默认不限制每个队列和用户可以同时运行应用的数量。 可以配置来限制队列和用户并行执行的应用数量。限制并行执行应用数量不会导致任务提交失败，超出的应用会在队列中等待。</p>
</li>
</ul>
<p>默认情况下，假如队列权重一样大的话，不同队列间均分整个集群的资源，队列内的不同任务均分队列内的集群资源。</p>
<h3 id="2-调度器配置项含义"><a href="#2-调度器配置项含义" class="headerlink" title="2.调度器配置项含义"></a>2.调度器配置项含义</h3><p>配置可分为调度器级别配置以及队列级别配置。</p>
<p>调度器级别配置在yarn-site.xml里配置，队列级别配置在fair-scheduler.xml里配置。</p>
<h4 id="调度器级别配置"><a href="#调度器级别配置" class="headerlink" title="调度器级别配置"></a>调度器级别配置</h4><ul>
<li><p><strong>yarn.scheduler.fair.user-as-default-queue</strong></p>
<p>是否将与 allocation 有关的 username 作为默认的 queue name，当 queue name 没有指定的时候。如果设置成 false（且没有指定 queue name）或者没有设定，所有的 jobs 将共享 “default” queue。</p>
</li>
<li><p><strong>yarn.scheduler.fair.allow-undeclared-pools</strong></p>
<p>如果设置为 true，application 提交时可以创建新的队列，要么是 application 指定了队列，或者是按照 user-as-default-queue 放置到相应队列。如果设置为 false，任何时间一个 app 要放置到一个未在分配文件中指定的队列，都将被放置到 “default” 队列。默认是 true。如果一个队列放置策略已经在分配文件中指定，本属性将会被忽略。</p>
</li>
<li><p><strong>yarn.scheduler.fair.preemption</strong></p>
<p>是否启用抢占机制，默认值是 false</p>
</li>
<li><p><strong>yarn.scheduler.fair.preemption.cluster-utilization-threshold</strong></p>
<p>启动抢占后的资源利用率阈值。利用率是计算所有资源中容量使用的最大比率。 默认值是 0.8f。</p>
</li>
<li><p><strong>yarn.scheduler.fair.sizebasedweight</strong></p>
<p>在一个队列<strong>内部分配资源</strong>时，默认情况下，采用<strong>公平轮询的方法将资源分配各个应用程序</strong>，而该参数则提供了另外一种资源分配方式：<strong>按照应用程序资源需求数目分配资源，即需求资源数量越多，分配的资源越多</strong>。默认情况下，该参数值为 false。</p>
</li>
<li><p><strong>yarn.scheduler.fair.assignmultiple</strong></p>
<p>是在<strong>允许在一个心跳中，发送多个 container 分配信息</strong>，默认false</p>
</li>
<li><p><strong>yarn.scheduler.fair.max.assign</strong></p>
<p>如果 assignmultuple 为 true，<strong>在一次心跳中，最多发送分配 container 的个数</strong>。默认为 -1，无限制。</p>
</li>
<li><p><strong>yarn.scheduler.fair.locality.threshold.node</strong></p>
<p>在 0~1 之间，表示在等待获取满足 node-local 条件的 containers 时，最多放弃不满足 node-local 的 container 的机会次数，放弃的 nodes 个数为集群的大小的比例。默认值为 -1.0 表示不放弃任何调度的机会。</p>
</li>
<li><p><strong>yarn.scheduler.fair.locality.threshold.rack</strong></p>
<p>对于特定 rack 上请求容器的作业，该属性代表了自从上次容器分配等待调度到其他 rack 上的机会的次数。表示为 0 到 1 之间的一个浮点数，该数字表达了集群规模的比例，代表了向上传递的调度机会数。默认值是 - 1.0，代表不传递任何调度机会。</p>
</li>
<li><p><strong>yarn.scheduler.fair.update-interval-ms</strong></p>
<p>锁定调度器和重新计算资源分配和需求，检查是否有抢占的时间间隔属性。默认是 500ms。</p>
</li>
</ul>
<h4 id="队列级别配置"><a href="#队列级别配置" class="headerlink" title="队列级别配置"></a>队列级别配置</h4><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">allocations</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!--队列的默认调度策略（全局），如果没有配置，默认采用公平调度。每个队列内部仍可以有不同的调度策略。默认fair调度策略只考虑内存资源，配置成drf的话会同时考虑cpu和内存--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">defaultQueueSchedulingPolicy</span>&gt;</span>fair<span class="tag">&lt;/<span class="name">defaultQueueSchedulingPolicy</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!--设置队列的默认 AM 资源限制；在每个队列中的 maxAMShare 元素覆盖该值。--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">queueMaxAMShareDefault</span>&gt;</span>0.5<span class="tag">&lt;/<span class="name">queueMaxAMShareDefault</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!--设置队列的默认最大资源限制；在每个队列中的 maxResources 元素覆盖该值--&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;<span class="name">queueMaxResourcesDefault</span>&gt;</span>102400mb,20vcores<span class="tag">&lt;/<span class="name">queueMaxResourcesDefault</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!--设置没有其他指定限制的用户的默认运行应用程序限制。--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">userMaxAppsDefault</span>&gt;</span>10<span class="tag">&lt;/<span class="name">userMaxAppsDefault</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!--设置队列的默认运行应用程序限制；在每个队列中的 maxRunningApps 元素覆盖该值--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">queueMaxAppsDefault</span>&gt;</span>10<span class="tag">&lt;/<span class="name">queueMaxAppsDefault</span>&gt;</span></span><br><span class="line">  </span><br><span class="line">  <span class="tag">&lt;<span class="name">queue</span> <span class="attr">name</span>=<span class="string">&quot;zhouhj&quot;</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--最多可以使用的资源量，fair scheduler会保证每个队列使用的资源量不会超过该队列的最多可使用资源量--&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--除了写死的值以外，还可以采用百分比的形式，比如50% memory,50% cpu--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">maxResources</span>&gt;</span>512000mb,10vcores<span class="tag">&lt;/<span class="name">maxResources</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--队列最小资源量--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">minResources</span>&gt;</span>204800mb,4vcores<span class="tag">&lt;/<span class="name">minResources</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--队列可以为单个容器分配的最大资源。如果未设置此属性，则其值继承自父队列。默认值是 yarn.scheduler.maximum-allocation-mb 和 yarn.scheduler.maximum-allocation-vcores。不能高于 maxResources。根队列不允许使用此属性。--&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--&lt;maxContainerAllocation&gt;&lt;/maxContainerAllocation&gt;--&gt;</span></span><br><span class="line">      </span><br><span class="line">    <span class="comment">&lt;!--限制队列中同时运行的应用程序数量--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">maxRunningApps</span>&gt;</span>4<span class="tag">&lt;/<span class="name">maxRunningApps</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 限制队列公平份额中可用于运行应用程序管理器的部分比例。此属性只适用于叶子队列。例如，如果设置为 1.0f，则叶子队列中的 AM 可以占用 100％的内存和 CPU 公平份额。值 - 1.0f 将禁用此功能，并且不会检查 amShare。默认值为 0.5f--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">maxAMShare</span>&gt;</span>0.1<span class="tag">&lt;/<span class="name">maxAMShare</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--权重，当集群资源繁忙时，就会按该权重的比值分配资源。用于与其他队列非比例地共享集群。权重默认为 1，权重为 2 的队列应该获得大约是具有默认权重的队列的两倍的资源。--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">weight</span>&gt;</span>25<span class="tag">&lt;/<span class="name">weight</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--队列内的调度策略，默认fair，也可以设置为fifo--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">schedulingPolicy</span>&gt;</span>fair<span class="tag">&lt;/<span class="name">schedulingPolicy</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--队列在其最小份额以下的秒数之后，将尝试从其他队列中抢占容器以获取资源。如果未设置，则队列将继承其父队列的值。默认值为 Long.MAX_VALUE，这意味着在设置有效值之前，它不会抢占容器--&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--&lt;minSharePreemptionTimeout&gt;&lt;/minSharePreemptionTimeout&gt;--&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--队列在其公平份额阈值以下的秒数之后，将尝试从其他队列中抢占容器以获取资源。如果未设置，则队列将继承其父队列的值。默认值为 Long.MAX_VALUE，这意味着在设置有效值之前，它不会抢占容器--&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--&lt;fairSharePreemptionTimeout&gt;&lt;/fairSharePreemptionTimeout&gt;--&gt;</span></span><br><span class="line">    <span class="comment">&lt;!----&gt;</span></span><br><span class="line">    <span class="comment">&lt;!----&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">queue</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">  <span class="tag">&lt;<span class="name">queue</span> <span class="attr">name</span>=<span class="string">&quot;dev&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">maxResources</span>&gt;</span>81920mb,16vcores<span class="tag">&lt;/<span class="name">maxResources</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">maxRunningApps</span>&gt;</span>6<span class="tag">&lt;/<span class="name">maxRunningApps</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">maxAMShare</span>&gt;</span>0.1<span class="tag">&lt;/<span class="name">maxAMShare</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">weight</span>&gt;</span>75<span class="tag">&lt;/<span class="name">weight</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">schedulingPolicy</span>&gt;</span>fair<span class="tag">&lt;/<span class="name">schedulingPolicy</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">queue</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">  <span class="comment">&lt;!--基于用户的配置--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">user</span> <span class="attr">name</span>=<span class="string">&quot;zhouhj&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">maxRunningApps</span>&gt;</span>10<span class="tag">&lt;/<span class="name">maxRunningApps</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">user</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!--队列分配规则，会从上至下匹配规则，直到满足--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">queuePlacementPolicy</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--create项代表是否允许创建新队列--&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--应用是否放到它指定的队列中，如果为true，则会放置在指定队列或创建一个指定名字的队列。如果为false，则该应用没有指定队列或者指定的队列不存在时就是不满足匹配规则，进入下一条--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">rule</span> <span class="attr">name</span>=<span class="string">&quot;specified&quot;</span> <span class="attr">create</span>=<span class="string">&quot;false&quot;</span>/&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--将应用程序放置到以提交者用户名命名的队列中--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">rule</span> <span class="attr">name</span>=<span class="string">&quot;user&quot;</span> <span class="attr">create</span>=<span class="string">&quot;false&quot;</span>/&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--primaryGroup会尝试把应用放在以用户所在的Unix组名命名的队列中，如果没有这个队列，为flase，不创建队列转而尝试下一个规则；为true则创建队列--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">rule</span> <span class="attr">name</span>=<span class="string">&quot;primaryGroup&quot;</span> <span class="attr">create</span>=<span class="string">&quot;false&quot;</span> /&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--将应用程序放置到由嵌套规则建议的队列下，队列的名称与用户名称相同。这类似于 &quot;user&quot; 规则，不同之处在于 &#x27;nestedUserQueue&#x27; 规则下，用户队列可以在任何父队列下创建，而 &#x27;user&#x27; 规则只能在根队列下创建用户队列。请注意，只有在嵌套规则返回父队列时，才会应用 &#x27;nestedUserQueue&#x27; 规则。可以通过将队列的 &quot;type&quot; 属性设置为 &quot;parent&quot; 或配置至少一个子队列来将队列配置为父队列--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">rule</span> <span class="attr">name</span>=<span class="string">&quot;nestedUserQueue&quot;</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--将应用程序放置到与提交者的某个辅助组匹配的队列中。选择第一个与配置的队列匹配的辅助组。--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rule</span> <span class="attr">name</span>=<span class="string">&quot;secondaryGroupExistingQueue&quot;</span> <span class="attr">create</span>=<span class="string">&quot;false&quot;</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">rule</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--当上述规则都不满足时，默认走该规则--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">rule</span> <span class="attr">name</span>=<span class="string">&quot;default&quot;</span> <span class="attr">queue</span>=<span class="string">&quot;zhouhj&quot;</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">queuePlacementPolicy</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">allocations</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>相关连接：</p>
<p><a href="https://blog.csdn.net/weixin_44758876/article/details/122885685">https://blog.csdn.net/weixin_44758876/article/details/122885685</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/660667684">https://zhuanlan.zhihu.com/p/660667684</a></p>
]]></content>
      <categories>
        <category>Yarn</category>
      </categories>
      <tags>
        <tag>Yarn</tag>
        <tag>调度器</tag>
      </tags>
  </entry>
  <entry>
    <title>Yarn容量调度器</title>
    <url>/2024/%E5%A4%A7%E6%95%B0%E6%8D%AE/Yarn%E5%AE%B9%E9%87%8F%E8%B0%83%E5%BA%A6%E5%99%A8/</url>
    <content><![CDATA[<h2 id="一：指定调度器"><a href="#一：指定调度器" class="headerlink" title="一：指定调度器"></a>一：指定调度器</h2><p>Yarn一共提供了三种资源调度器，分别是<code>FIFO Scheduler（先进先出调度器）</code> ，<code>Capacity Scheduler（容量调度器）</code>，<code>Fair Scheduler（公平调度器）</code>。</p>
<p>Apache版本的默认调度器是<code>Capacity Scheduler（容量调度器）</code>，指定调度器的配置项在yarn-site.xml中。</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.scheduler.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br></pre></td></tr></table></figure>

<h2 id="二：调度器配置"><a href="#二：调度器配置" class="headerlink" title="二：调度器配置"></a>二：调度器配置</h2><h3 id="1-调度器说明"><a href="#1-调度器说明" class="headerlink" title="1.调度器说明"></a>1.调度器说明</h3><p>Capacity 调度器可以将整个集群的yarn资源划分为若干个队列，每个队列获得集群的一部分计算能力，可以做到队列间的资源隔离。</p>
<p>Capacity 调度器允许不同队列间的任务并行，相同队列内任务默认先进先出（FIFO），但也可以通过配置使相同队列内的任务以“公平”的形式并行执行。</p>
<p>Capacity调度器不同队列间的资源有空闲时，可以暂时共享给需要资源的队列。比如有两个队列分别为default和dev，原本分配的比例为各50%，但当dev队列繁忙而default队列空闲时，则dev队列使用的资源可以超过50%（根据配置项决定上限到多少）。而此时假如被占用的队列来任务，则会等被占用的资源释放后，再进行任务资源的分配。</p>
<h3 id="2-调度器配置项含义"><a href="#2-调度器配置项含义" class="headerlink" title="2.调度器配置项含义"></a>2.调度器配置项含义</h3><p>容量调度器队列的分配配置在<strong>HADOOP_CONF&#x2F;capacity-scheduler.xml</strong>中，默认有一个<strong>预定义的队列root</strong>，其余队列都是其子队列。</p>
<p>队列的分配支持<strong>层次化</strong>的配置，使用<code>.</code> 来进行分割，比如：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">yarn.scheduler.capacit.<span class="tag">&lt;<span class="name">queue-path</span>&gt;</span>.queues</span><br></pre></td></tr></table></figure>

<h4 id="限制应用程序数目的配置参数"><a href="#限制应用程序数目的配置参数" class="headerlink" title="限制应用程序数目的配置参数"></a>限制应用程序数目的配置参数</h4><ul>
<li><p><strong>yarn.scheduler.capacity.maximum-am-resource-percent</strong></p>
<p>集群中用于运行应用程序 ApplicationMaster 的资源比例上限，该参数通常用于限制处于活动状态的应用程序数目。该参数类型为浮点型，默认是 0.1，表示 10%</p>
</li>
<li><p><strong>yarn.scheduler.capacity.<queue-path>.maximum-am-resource-percent</strong></p>
<p>同上，设置单个队列的运行应用程序 ApplicationMaster 的资源比例上限，如果没配则取<strong>yarn.scheduler.capacity.maximum-am-resource-percent</strong>的值。<strong>一个队列的所有子队列里运行的AM资源的总和与父队列总资源的占比，不允许超过父队列的该值</strong></p>
</li>
<li><p><strong>yarn.scheduler.capacity.maximum-applications</strong></p>
<p>集群或者队列中同时处于等待和运行状态的应用程序数目上限，这是一个强限制，一旦集群中应用程序数目超过该上限，后续提交的应用程序将被拒绝，默认值为 10000。所有队列的数目上限可通过参数 yarn.scheduler.capacity.maximum-applications 设置（可看做默认值）</p>
</li>
<li><p><strong>yarn.scheduler.capacity.<queue-path>.maximum-applications</strong></p>
<p>同上，设置单个队列中同时处于等待和运行状态的应用程序数目上限。一个队列的所有子队列的该参数的和，不允许超过父队列的该值。默认值：yarn.scheduler.capacity.maximum-applications*队列绝对容量</p>
</li>
</ul>
<h4 id="队列访问和权限控制参数"><a href="#队列访问和权限控制参数" class="headerlink" title="队列访问和权限控制参数"></a>队列访问和权限控制参数</h4><ul>
<li><p><strong>yarn.scheduler.capacity.<queue-path>.acl_administer_queue</strong></p>
<p>为队列指定一个管理员，该管理员可控制该队列的所有应用程序，比如杀死任意一个应用程序等。同样，该属性具有继承性，如果一个用户可以向某个队列中提交应用程序，则它可以向它的所有子队列中提交应用程序。</p>
<p>ACL 的设置是 <code>user1,user2 group1,group2</code> 这种格式。如果是 <code>*</code> 则代表任何人。<code>空格</code>表示任何人都不允许。默认是 <code>*</code></p>
</li>
<li><p><strong>yarn.scheduler.capacity.<queue-path>.acl_submit_applications</strong></p>
<p>限定哪些 Linux 用户 &#x2F; 用户组可向给定队列中提交应用程序。需要注意的是，该属性具有继承性，即如果一个用户可以向某个队列中提交应用程序，则它可以向它的所有子队列中提交应用程序。配置规则和默认值同上一个参数</p>
<p>这两个acl的配置，需要在yarn-site.xml中启用acl，配置项为yarn.acl.enable，默认为false。</p>
<p>如果父队列的这两个acl参数值为*，则子队列加限制也没用。</p>
</li>
<li><p><strong>yarn.scheduler.capacity.<queue-path>.state</strong></p>
<p>队列状态。可以为 STOPPED 或者 RUNNING，如果一个队列处于 STOPPED 状态，用户不可以将应用程序提交到该队列或者它的子队列中，类似的，如果 ROOT 队列处于 STOPPED 状态，用户不可以向集群中提交应用程序，但正在运行的应用程序仍可以正常运行结束，以便队列可以优雅地退出。</p>
</li>
</ul>
<h4 id="资源分配相关参数"><a href="#资源分配相关参数" class="headerlink" title="资源分配相关参数"></a>资源分配相关参数</h4><ul>
<li><p><strong>yarn.scheduler.capacity.resource-calculator</strong></p>
<p>资源计算方法，默认是 <code>org.apache.hadoop.yarn.util.resource.DefaultResourseCalculator</code>, 它只会计算内存。<code>DominantResourceCalculator</code> 则会计算内存和 CPU。</p>
</li>
<li><p><strong>yarn.scheduler.capacity.<queue-path>.capacity</strong></p>
<p>队列容量占父队列资源百分比，同一级的队列该参数的和必须等于100。当系统非常繁忙时，应保证每个队列的容量得到满足，而如果每个队列应用程序较少，可将剩余资源共享给其他队列。</p>
</li>
<li><p><strong>yarn.scheduler.capacity.<queue-path>.maximum-capacity</strong></p>
<p>队列的资源使用上限（百分比）。由于存在资源共享，因此一个队列使用的资源量可能超过其容量，而最多使用资源量可通过该参数限制。</p>
</li>
<li><p><strong>yarn.scheduler.capacity.<queue-path>.user-limit-factor</strong></p>
<p>单个用户最多可以使用的资源因子，默认情况为 1，表示单个用户最多可以使用队列的容量。不管集群有空闲，如果该值设为 5，表示这个用户最多可以使用 5*capacity 的容量。实际上单个用户的使用资源为 min (user-limit-factor*capacity，maximum-capacity)。这里需要注意的是，如果队列中有多个用户的任务，那么每个用户的使用量将稀释</p>
</li>
<li><p><strong>yarn.scheduler.capacity.<queue-path>.minimum-user-limit-percent</strong></p>
<p>每个用户最低资源保障（百分比）。任何时刻，一个队列中每个用户可使用的资源量均有一定的限制。当一个队列中同时运行多个用户的应用程序时中，每个用户的使用资源量在一个最小值和最大值之间浮动，其中，最大值取决于正在运行的应用程序数目，而最小值则由 minimum-user-limit-percent 决定。比如，设置成 25%。那么如果有2个任务，那么每个任务资源不超过 50%。如果 3 个任务，那么每个任务资源不超过 33%。如果 4 个任务，那么每个任务资源不超过 25%。如果 5 个任务，那么第5个任务需要等待才能提交。默认是 100，即不去做限制。</p>
</li>
<li><p><strong>yarn.scheduler.capacity.<queue-path>.queues</strong></p>
<p>子队列配置，比如root下有default和dev两个队列，则<queue_path>为root，属性值为default,dev</p>
</li>
<li><p><strong>yarn.scheduler.capacity.</strong><queue-path><strong>.priority</strong></p>
<p>定义队列的优先级，开启优先级调度并且为FIFO的时候有用，默认为0。</p>
<p>yarn.cluster.max-application-priority：设置集群最大优先级</p>
</li>
<li><p><strong>yarn.scheduler.capacity.<queue-path>.default-application-priority</strong></p>
<p>定义队列里任务默认的优先级</p>
</li>
<li><p><strong>yarn.scheduler.capacity.<queue-path>.accessible-node-labels</strong></p>
<p>配置队列可访问的分区，默认*</p>
</li>
<li><p><strong>yarn.scheduler.capacity.<queue-path>.ordering-policy</strong></p>
<p>定义任务的调度策略。如果<queue-path>是非叶子节点，则对该队列的子队列进行排序。可选值有 “utilization” 和 “priority-utilization”，默认是 “utilization” 。</p>
<p>配置项生效优先级：当前队列&gt;父队列&gt;默认</p>
<p>“utilization” 仅考虑资源的使用情况，不考虑优先级，使用相对容量资源少的队列可以得到资源。</p>
<p>“priority-utilization” 考虑优先级。如果各队列使用的资源都低于 capacity，优先级高的队列可以得到资源。如果各队列使用的资源都大于等于 capacity，优先级高的队列可以得到资源。当一个队列使用的资源都低于 capacity，而另一个队列使用的资源都大于等于 capacity，使用的资源都低于 capacity 的队列可以得到资源。</p>
<p>如果<queue-path>是叶子节点，则设置的是队列内任务的调度策略。可配置的值有fifo、fair。如果作业是同一用户的作业，按照比较器比较。如果不同用户的作业，如果提交作业的用户使用的资源（除 AM 外）相同，则先提交的作业优先。如果提交作业的用户使用的资源（除 AM 外）不相同，则使用资源少的用户的作业优先。</p>
</li>
<li><p><strong>yarn.scheduler.capacity.<queue-path>.ordering-policy.fair.enable-size-based-weight</strong></p>
<p>是否启用基于大小的资源分配加权。当此属性设置为时 true，队列资源将根据其大小分配给各个应用程序，而不是为所有应用程序提供均等的队列资源，而不管大小如何。默认设置为 false。当<strong>yarn.scheduler.capacity.<queue-path>.ordering-policy</strong>配置为fair时有效。</p>
</li>
<li><p><strong>yarn.scheduler.capacity.queue-mappings</strong></p>
<p>定义队列映射策略，如果使用默认映射策略，用户提交应用时可不指定队列，使用多个队列映射的时候用逗号分隔，调度器按从左到右顺序处理映射，以确定先使用哪一个。</p>
<p>比如配置用户user1默认提交到队列queueA，组group1默认提交到队列queueB，则该项的值为：u:user1:queueA,g:group1:queueB</p>
</li>
<li><p><strong>yarn.scheduler.capacity.queue-mappings-override.enable</strong></p>
<p>是否启用覆盖默认队列映射，默认false，这意味着该功能被禁用并且放置规则无法覆盖在作业提交时指定的目标队列</p>
</li>
</ul>
<h4 id="其他参数"><a href="#其他参数" class="headerlink" title="其他参数"></a>其他参数</h4><ul>
<li><p><strong>yarn.scheduler.capacity.node-locality-delay</strong></p>
<p>调度器尝试进行调度的次数，默认40次。容量调度器利用延迟调度来满足任务局部性约束。局部约束分为三个级别：节点本地、机架本地和关闭开关。当不能满足局部性时，调度器会计算错过的机会数量，并等待此计数达到阈值，然后再将局部性约束放宽到下一个级别。首先会将任务提交到本地节点，如果本地节点繁忙提交不了，会尝试<strong>yarn.scheduler.capacity.node-locality-delay</strong>次，默认每次间隔1秒。直到尝试次数用完，会将任务采用下一级约束——同一机架。</p>
</li>
</ul>
<h4 id="资源抢占"><a href="#资源抢占" class="headerlink" title="资源抢占"></a>资源抢占</h4><p>以下参数在yarn-site.xml中</p>
<ul>
<li><p><strong>yarn.resourcemanager.scheduler.monitor.enable</strong></p>
<p>是否启用资源抢占，默认false。</p>
</li>
<li><p><strong>yarn.resourcemanager.scheduler.monitor.policies</strong></p>
<p>与调度程序交互的SchedulingEditPolicy类的列表。当前唯一可用于抢占的策略是“ ProportionalCapacityPreemptionPolicy”。值为：org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy</p>
</li>
<li><p><strong>yarn.resourcemanager.monitor.capacity.preemption.monitoring_interval</strong></p>
<p>两次调用该策略之间的时间（以毫秒为单位）。将此值设置为较长的时间间隔将导致容量监视器的运行频率降低。默认值3000</p>
</li>
<li><p><strong>yarn.resourcemanager.monitor.capacity.preemption.max_wait_before_kill</strong></p>
<p>从应用程序请求抢占到终止容器之间的时间（以毫秒为单位）。将此值设置为较高的值将使应用程序有更多时间响应抢占请求并优雅地释放容器。</p>
</li>
<li><p><strong>yarn.resourcemanager.monitor.capacity.preemption.total_preemption_per_round</strong></p>
<p>单回合中可抢占的最大资源百分比。您可以使用此值来限制从群集回收Containers的速度。计算完所需的总抢占后，策略会将其重新扩展到此限制。应将其设置为(memory-of-one-NodeManager)&#x2F;(total-cluster-memory)。例如，如果一个NodeManager拥有32 GB，并且群集总资源为100 GB，则total_preemption_per_round应设置为32&#x2F;100 &#x3D; 0.32。默认值为0.1（10％）。</p>
</li>
<li><p><strong>yarn.resourcemanager.monitor.capacity.preemption.natural_termination_factor</strong></p>
<p>类似于total_preemption_per_round，在为每个队列计算了抢占目标之后，可以应用此因子来减慢资源抢占（例如，“从队列A中退回5 GB”）。例如，如果需要5 GB，则在第一个周期中，抢占将收回1 GB（5 GB的20％），在下一个周期中收回0.8 GB（其余4 GB的20％），在0.64 GB（其余3.2 GB的20％）中抢占。 GB），依此类推。您可以增加此值以加快资源回收。此参数的建议值为1.0，这意味着一个循环中将抢占100％的目标容量。</p>
</li>
<li><p><strong>yarn.resourcemanager.monitor.capacity.preemption.intra-queue-preemption.enabled</strong></p>
<p>是否启用队列内的资源抢占，默认true</p>
</li>
<li><p><strong>yarn.resourcemanager.monitor.capacity.preemption.intra-queue-preemption.preemption-order-policy</strong></p>
<p>指定队列可以抢占资源的顺序。根据您的要求，可以将此属性配置为以下值之一：userlimit-first：以根据配置的用户限制启动队列内抢占。这是默认值。priority-first：以根据应用程序优先级启动队列内抢占。</p>
</li>
</ul>
<h3 id="3-配置实操"><a href="#3-配置实操" class="headerlink" title="3.配置实操"></a>3.配置实操</h3><p>开发环境：配置两个队列，一个为default，一个为dev。default容量为30%，最大容量为80%；dev容量为70%，最大容量为90%。队列内采用公平策略，由于只有一个用户，配置单个用户允许使用队列的所有资源。</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.maximum-am-resource-percent<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>0.2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.maximum-applications<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>10000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.node-locality-delay<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>40<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.resource-calculator<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.queue-mappings-override.enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.acl_administer_queue<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>zhouhj,zhouhj<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.acl_submit_applications<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>zhouhj,zhouhj<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.capacity<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>100<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.queues<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>default,dev<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.priority<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>0<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.accessible-node-labels<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.default.acl_administer_queue<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>zhouhj<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.default.acl_submit_applications<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>zhouhj,zhouhj<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.default.maximum-capacity<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>80<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.default.user-limit-factor<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.default.state<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>RUNNING<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.default.capacity<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>30<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.default.ordering-policy<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>fair<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.default.ordering-policy.fair.enable-size-based-weight<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.default.priority<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>0<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.dev.acl_administer_queue<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.dev.acl_submit_applications<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.dev.minimum-user-limit-percent<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>100<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.dev.maximum-capacity<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>90<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.dev.user-limit-factor<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.dev.state<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>RUNNING<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.dev.capacity<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>70<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.dev.ordering-policy<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>fair<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.dev.ordering-policy.fair.enable-size-based-weight<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.dev.priority<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>0<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="4-刷新配置"><a href="#4-刷新配置" class="headerlink" title="4.刷新配置"></a>4.刷新配置</h3><p>修改了capacity-scheduler.xml配置文件，可以使用<strong>yarn rmadmin -refreshQueues</strong>动态刷新队列配置而不重启集群。 </p>
<p>相关链接：</p>
<p><a href="https://www.cnblogs.com/w-j-q/p/14956922.html">https://www.cnblogs.com/w-j-q/p/14956922.html</a></p>
<p><a href="https://blog.csdn.net/mnasd/article/details/100679389">https://blog.csdn.net/mnasd/article/details/100679389</a></p>
<p><a href="https://blog.csdn.net/weixin_44758876/article/details/122881075">https://blog.csdn.net/weixin_44758876/article/details/122881075</a></p>
]]></content>
      <categories>
        <category>Yarn</category>
      </categories>
      <tags>
        <tag>Yarn</tag>
        <tag>调度器</tag>
      </tags>
  </entry>
  <entry>
    <title>HBCK2常用命令</title>
    <url>/2023/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/HBCK2%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<h5 id="修复region存在但meta表region信息缺失"><a href="#修复region存在但meta表region信息缺失" class="headerlink" title="修复region存在但meta表region信息缺失"></a>修复region存在但meta表region信息缺失</h5><p>hbase hbck -j hbase-hbck2-1.1.0.jar addFsRegionsMissingInMeta namespace|tablename</p>
<p>该命令会扫描hdfs中Region目录的region_info的信息并根据该信息进行region重建，最后在运行该命令输出的assign命令进行重新分配，如果使用的hbase版本小于2.3.0，则在执行assign之前需要滚动重启HMaster进程</p>
<h5 id="修复region不存在但meta表里还有region信息"><a href="#修复region不存在但meta表里还有region信息" class="headerlink" title="修复region不存在但meta表里还有region信息"></a>修复region不存在但meta表里还有region信息</h5><p>hbase hbck -j hbase-hbck2-1.1.0.jar extraRegionsInMeta –fix</p>
<p>在决定是否传入 –fix 参数时，应当检查多余的 Region 是否存在 region overlap(region重叠), 若存在，可以传入 –fix 以删除 meta 表多余的 Region 信息，若不存在，应当调用 assigns 命令，创建一个新的 Region 目录写入 HDFS。</p>
<h5 id="对-hbase-meta-中的错误或不一致状态-重叠或空洞-进行服务端修复"><a href="#对-hbase-meta-中的错误或不一致状态-重叠或空洞-进行服务端修复" class="headerlink" title="对 hbase:meta 中的错误或不一致状态(重叠或空洞)进行服务端修复"></a>对 hbase:meta 中的错误或不一致状态(重叠或空洞)进行服务端修复</h5><p>hbase hbck -j hbase-hbck2-1.1.0.jar fixMeta</p>
<p>在 hbase 2.2.1&#x2F;2.1.6 或更新版本中可用</p>
<h5 id="报告hbase-meta表空洞（hdfs上存在region，hbase-meta表不存在记录）"><a href="#报告hbase-meta表空洞（hdfs上存在region，hbase-meta表不存在记录）" class="headerlink" title="报告hbase:meta表空洞（hdfs上存在region，hbase:meta表不存在记录）"></a>报告hbase:meta表空洞（hdfs上存在region，hbase:meta表不存在记录）</h5><p>hbase hbck -j hbase-hbck2-1.1.0.jar reportMissingRegionsInMeta namespace|tablename</p>
<p>执行该命令仅报告有哪些空洞，修复使用addFsRegionsMissingInMeta </p>
<h5 id="手动释放Procedures-amp-Locks"><a href="#手动释放Procedures-amp-Locks" class="headerlink" title="手动释放Procedures&amp;Locks"></a>手动释放Procedures&amp;Locks</h5><p>hbase hbck -j hbase-hbck2-1.1.0.jar bypass -or PID</p>
<p>PID在hbase管理页面Procedures&amp;Locks获取</p>
<p>该命令会使处于RIT状态的Region停留在中间状态，需要人工干预后执行后续修复过程。</p>
<h5 id="分配region到regionserver上"><a href="#分配region到regionserver上" class="headerlink" title="分配region到regionserver上"></a>分配region到regionserver上</h5><p>hbase hbck -j hbase-hbck2-1.1.0.jar  assigns -o regionname…</p>
<p>可选参数-o：这里的override跟bypass的override不同，因为assign本身就会创建一个新的procedure, 所以肯定是不涉及到拿IdLock的，但是这里涉及到资源锁的问题。因为之前卡住的资源锁即使在bypass后也不会释放(用于fence, 防止更多未知的错误操作)，所以需要加一个-o去手动释放这个资源锁。</p>
<p>返回值是创建的pid则为成功，-1则为失败。</p>
<h5 id="手动解除region分配"><a href="#手动解除region分配" class="headerlink" title="手动解除region分配"></a>手动解除region分配</h5><p>hbase hbck -j hbase-hbck2-1.1.0.jar unassigns -o regionname…</p>
<p>返回值是创建的pid则为成功，-1则为失败。</p>
<h5 id="手动修改region状态"><a href="#手动修改region状态" class="headerlink" title="手动修改region状态"></a>手动修改region状态</h5><p>hbase hbck -j hbase-hbck2-1.1.0.jar setRegionState regionname stateenum</p>
<p>hbase2.3.0之前，修改了该状态只是修改了meta表里的，并不会重新加载到HMaster中，需要滚动重启HMaster</p>
<p>手动设置region 的状态，可选的状态有OFFLINE, OPENING, OPEN, CLOSING, CLOSED, SPLITTING, SPLIT, FAILED_OPEN, FAILED_CLOSE, MERGING, MERGED, SPLITTING_NEW, MERGING_NEW, ABNORMALLY_CLOSED，返回0表示成功，1表示失败。hbase：meta表中可能的表状态和表示形式：ENABLED(\ x08 \ x00)，DISABLED(\ x08 \ x01)，DISABLING(\ x08 \ x02)，ENABLING(\ x08 \ x03)。</p>
<p>使用这个命令前，一定要确认这个region 不在assign 和unassign procedures 中，你可以在hbase shell 中使用命令 list_procedures 进行查看这个region 的状态</p>
<h5 id="RegionServer宕机，但ServerCrashProcedure没有执行成功"><a href="#RegionServer宕机，但ServerCrashProcedure没有执行成功" class="headerlink" title="RegionServer宕机，但ServerCrashProcedure没有执行成功"></a>RegionServer宕机，但ServerCrashProcedure没有执行成功</h5><p>hbase hbck -j hbase-hbck2-1.1.0.jar scheduleRecoveries <regionserverName></p>
<p>该命令的意义是完成RegionServer宕机后的处理工作，包含WAL切分，RegionServer上的Region分配与挂载等操作，而不是让已经宕机的RegionServer复原。</p>
<h5 id="HBase表复制已经取消，但对应复制队列未彻底清除"><a href="#HBase表复制已经取消，但对应复制队列未彻底清除" class="headerlink" title="HBase表复制已经取消，但对应复制队列未彻底清除"></a>HBase表复制已经取消，但对应复制队列未彻底清除</h5><p>hbase hbck -j hbase-hbck2-1.1.0.jar replication [-f] <tablename></p>
<p>检查表复制队列中应清除但未清除的存储信息，若传入-f会删除这些信息并删除meta表中的ReplicationBarrier</p>
<h5 id="手动修改table状态"><a href="#手动修改table状态" class="headerlink" title="手动修改table状态"></a>手动修改table状态</h5><p>hbase hbck -j hbase-hbck2-1.1.0.jar setTableState <tablename> <state></p>
<p>修改hbase:meta表中表示数据表状态的table:state数据列的值并更新Master中缓存的数据表状态。可选的table状态有ENABLED, DISABLED, DISABLING, ENABLING，在table的状态和所有的region状态不一致时可以用这个命令进行修复，使用之前建议使用：desc ‘tablename’ 查看一下当前表的状态。</p>
<h5 id="HBase数据表的-tableinfo文件缺失"><a href="#HBase数据表的-tableinfo文件缺失" class="headerlink" title="HBase数据表的.tableinfo文件缺失"></a>HBase数据表的.tableinfo文件缺失</h5><p>hbase hbck -j hbase-hbck2-1.1.0.jar generateMissingTableDescriptorFile <tablename></p>
<p>执行命令后先检查TableDescriptor是否缓存在hmaster中，如果是，则直接通过缓存生成，如果不在，则通过表名、列族（表目录确定）、默认配置和列族描述符。</p>
<p>当数据表对应文件目录缺失或.tableinfo存在时，该命令不会生效</p>
<h5 id="HBase出现Hfile文件损坏、错误的引用文件、错误的HFile-Link或需要进行完整性检查（比如出现overlap、Orphansi或Hole"><a href="#HBase出现Hfile文件损坏、错误的引用文件、错误的HFile-Link或需要进行完整性检查（比如出现overlap、Orphansi或Hole" class="headerlink" title="HBase出现Hfile文件损坏、错误的引用文件、错误的HFile Link或需要进行完整性检查（比如出现overlap、Orphansi或Hole)"></a>HBase出现Hfile文件损坏、错误的引用文件、错误的HFile Link或需要进行完整性检查（比如出现overlap、Orphansi或Hole)</h5><p>hbase hbck -j hbase-hbck2-1.1.0.jar filesystem [–fix] [<tablename>]</p>
<p>执行完命令后会调用fsck进行文件修复。生产环境中，有的时候会出现hfile 损坏，hfile引用损坏，hbase.version 丢失或者links 损坏等，这个时候可以使用–fix 进行修复。不加表名的话，默认修复所有表。</p>
<h5 id=""><a href="#" class="headerlink" title=""></a></h5>]]></content>
      <categories>
        <category>HBase</category>
      </categories>
      <tags>
        <tag>HBase</tag>
        <tag>常用命令</tag>
        <tag>HBCK</tag>
      </tags>
  </entry>
</search>
